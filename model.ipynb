{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 04:48:14.940511: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-05 04:48:14.963034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-05 04:48:14.963057: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-05 04:48:14.963073: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-05 04:48:14.967544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size, val_size, test_size):\n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=test_size/(test_size+val_size), stratify=y_val_test)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def process_data_for_conv2D(X):\n",
    "    X_conv2D = []\n",
    "    for sample in X:\n",
    "        sample = np.reshape(sample, newshape=(sample.shape[0], sample.shape[1], 1))\n",
    "        X_conv2D.append(sample)\n",
    "    return np.array(X_conv2D, dtype=np.float32)\n",
    "\n",
    "def data_iter(X, y, batch_size):\n",
    "    n_samples = X.shape[0]\n",
    "    idx = list(range(n_samples))\n",
    "    while True:\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            j = idx[i: min(i+batch_size, n_samples)]\n",
    "            yield X[j, :], y[j, : ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some blocks for NN\n",
    "\n",
    "def base_conv_block(n_conv_filters, kernel_size):\n",
    "    def f(input_):\n",
    "        x = tf.keras.layers.Conv2D(n_conv_filters, kernel_size, padding='same')(input_)\n",
    "\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "def base_model_cnn(input_shape, num_conv_filters = [32, 64, 128], kernel_size = (2, 2), max_pool_kernel = (1, 3), num_dense_units=128, num_classes=2):\n",
    "    input_ = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = input_\n",
    "    for n_conv_filters in num_conv_filters:\n",
    "        x = base_conv_block(n_conv_filters, kernel_size)(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(max_pool_kernel)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(num_dense_units, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3855, 188, 257, 1)\n",
      "(3855, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "# X_stft = np.load(\"stft/stft_features.npy\")\n",
    "# y = np.load(\"stft/labels.npy\")\n",
    "\n",
    "# # process data for conv2d\n",
    "# X_stft = process_data_for_conv2D(X_stft)\n",
    "# print(X_stft.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "# load normalized data\n",
    "X_stft_normalized = np.load(\"stft_normalized/stft_features.npy\")\n",
    "y = np.load(\"stft_normalized/labels.npy\")\n",
    "\n",
    "# process data for conv2d\n",
    "X_stft_normalized = process_data_for_conv2D(X_stft_normalized)\n",
    "print(X_stft_normalized.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create directory weights_normalized/\n"
     ]
    }
   ],
   "source": [
    "kernel_size = (3, 3)\n",
    "max_pool_kernel = (1, 4)\n",
    "conv_filters = [32, 64, 128, 256]\n",
    "num_dense_units = 512\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# keep track of best model and log\n",
    "base_file_name = \"cnn_model.hdf5\"\n",
    "path = \"weights_normalized/\"\n",
    "base_csv_name = \"cnn_logs.csv\"\n",
    "\n",
    "# create directory if not exist\n",
    "if not os.path.exists(path):\n",
    "    print(f\"Create directory {path}\")\n",
    "    os.makedirs(path)\n",
    "\n",
    "train_loss_record = []\n",
    "train_acc_record = []\n",
    "val_loss_record = []\n",
    "val_acc_record = []\n",
    "test_loss_record = []\n",
    "test_acc_record = []\n",
    "\n",
    "# prepare for k-fold cross validation\n",
    "k_fold = 5\n",
    "\n",
    "\n",
    "def kfold_training(X, y, k_fold, train_size, val_size, test_size, base_model_cnn, base_file_name, base_csv_name, path, learning_rate, epochs, batch_size, num_dense_units, num_classes, kernel_size, max_pool_kernel, conv_filters):\n",
    "    train_loss_record = []\n",
    "    train_acc_record = []\n",
    "    val_loss_record = []\n",
    "    val_acc_record = []\n",
    "    test_loss_record = []\n",
    "    test_acc_record = []\n",
    "    train_auc_record = []\n",
    "    val_auc_record = []\n",
    "    test_auc_record = []\n",
    "    train_precision_record = []\n",
    "    val_precision_record = []\n",
    "    test_precision_record = []\n",
    "    train_recall_record = []\n",
    "    val_recall_record = []\n",
    "    test_recall_record = []\n",
    "    # train_f1_score_record = []\n",
    "    # val_f1_score_record = []\n",
    "    # test_f1_score_record = []\n",
    "    # train_specificity_record = []\n",
    "    # val_specificity_record = []\n",
    "    # test_specificity_record = []\n",
    "    \n",
    "    for i in range(k_fold):\n",
    "        print(f\"Start {i+1}th-fold in {k_fold} cross validation\")\n",
    "\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, train_size, val_size, test_size)\n",
    "\n",
    "        file_name = os.path.join(path, f\"{i}_fold_{base_file_name}\")\n",
    "        csv_path = os.path.join(path, f\"{i}_fold_{base_csv_name}\")\n",
    "\n",
    "\n",
    "        lr_change = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, min_lr=0.0001)\n",
    "\n",
    "        model_checkpoint = tf.keras.callbacks.ModelCheckpoint(file_name, monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", metric=\"val_acc\")\n",
    "\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.01, patience=10, mode=\"min\")\n",
    "\n",
    "        # csv logger\n",
    "        csv_logger = tf.keras.callbacks.CSVLogger(csv_path)\n",
    "\n",
    "        callbacks = [lr_change, model_checkpoint, early_stopping, csv_logger]\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        model = base_model_cnn(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]),\n",
    "                                num_dense_units=num_dense_units, num_classes=num_classes,\n",
    "                                kernel_size=kernel_size, max_pool_kernel=max_pool_kernel, \n",
    "                                num_conv_filters=conv_filters)\n",
    "        \n",
    "        # monitor specificity, sensitivity, f1 score\n",
    "        model.compile(loss = \"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"AUC\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        \n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "                verbose=1)\n",
    "        \n",
    "        # train_loss, train_acc, train_auc, train_precision, train_recall, train_f1_score, train_specificity = model.evaluate(X_train, y_train, verbose=0)\n",
    "        # val_loss, val_acc, val_auc, val_precision, val_recall, val_f1_score, val_specificity = model.evaluate(X_val, y_val, verbose=0)\n",
    "        # test_loss, test_acc, test_auc, test_precision, test_recall, test_f1_score, test_specificity = model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        train_loss, train_acc, train_auc, train_precision, train_recall = model.evaluate(X_train, y_train, verbose=0)\n",
    "        val_loss, val_acc, val_auc, val_precision, val_recall = model.evaluate(X_val, y_val, verbose=0)\n",
    "        test_loss, test_acc, test_auc, test_precision, test_recall= model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        \n",
    "        train_loss_record.append(train_loss)\n",
    "        train_acc_record.append(train_acc)\n",
    "        val_loss_record.append(val_loss)\n",
    "        val_acc_record.append(val_acc)\n",
    "        test_loss_record.append(test_loss)\n",
    "        test_acc_record.append(test_acc)\n",
    "        train_auc_record.append(train_auc)\n",
    "        val_auc_record.append(val_auc)\n",
    "        test_auc_record.append(test_auc)\n",
    "        train_precision_record.append(train_precision)\n",
    "        val_precision_record.append(val_precision)\n",
    "        test_precision_record.append(test_precision)\n",
    "        train_recall_record.append(train_recall)\n",
    "        val_recall_record.append(val_recall)\n",
    "        test_recall_record.append(test_recall)\n",
    "        # train_f1_score_record.append(train_f1_score)\n",
    "        # val_f1_score_record.append(val_f1_score)\n",
    "        # test_f1_score_record.append(test_f1_score)\n",
    "        # train_specificity_record.append(train_specificity)\n",
    "        # val_specificity_record.append(val_specificity)\n",
    "        # test_specificity_record.append(test_specificity)\n",
    "        \n",
    "\n",
    "    train_loss_avg = np.mean(train_loss_record)\n",
    "    train_acc_avg = np.mean(train_acc_record)\n",
    "    val_loss_avg = np.mean(val_loss_record)\n",
    "    val_acc_avg = np.mean(val_acc_record)\n",
    "    test_loss_avg = np.mean(test_loss_record)\n",
    "    test_acc_avg = np.mean(test_acc_record)\n",
    "    train_auc_avg = np.mean(train_auc_record)\n",
    "    val_auc_avg = np.mean(val_auc_record)\n",
    "    test_auc_avg = np.mean(test_auc_record)\n",
    "    train_precision_avg = np.mean(train_precision_record)\n",
    "    val_precision_avg = np.mean(val_precision_record)\n",
    "    test_precision_avg = np.mean(test_precision_record)\n",
    "    train_recall_avg = np.mean(train_recall_record)\n",
    "    val_recall_avg = np.mean(val_recall_record)\n",
    "    test_recall_avg = np.mean(test_recall_record)\n",
    "    # train_f1_score_avg = np.mean(train_f1_score_record)\n",
    "    # val_f1_score_avg = np.mean(val_f1_score_record)\n",
    "    # test_f1_score_avg = np.mean(test_f1_score_record)\n",
    "    # train_specificity_avg = np.mean(train_specificity_record)\n",
    "    # val_specificity_avg = np.mean(val_specificity_record)\n",
    "    # test_specificity_avg = np.mean(test_specificity_record)\n",
    "    \n",
    "\n",
    "    print(f\"{k_fold}-fold cv train loss avg: {train_loss_avg:.4f}, train acc avg: {train_acc_avg:.4f}, val loss avg: {val_loss_avg:.4f}, val acc avg: {val_acc_avg:.4f}, test loss avg: {test_loss_avg:.4f}, test acc avg: {test_acc_avg:.4f} \\n \\\n",
    "            train auc avg: {train_auc_avg:.4f}, val auc avg: {val_auc_avg:.4f}, test auc avg: {test_auc_avg:.4f} \\n \\\n",
    "                train precision avg: {train_precision_avg:.4f}, val precision avg: {val_precision_avg:.4f}, test precision avg: {test_precision_avg:.4f} \\n \\\n",
    "                    train recall avg: {train_recall_avg:.4f}, val recall avg: {val_recall_avg:.4f}, test recall avg: {test_recall_avg:.4f}\")\n",
    "                        # train f1 score avg: {train_f1_score_avg:.4f}, val f1 score avg: {val_f1_score_avg:.4f}, test f1 score avg: {test_f1_score_avg:.4f} \\n \\\n",
    "                        #     train specificity avg: {train_specificity_avg:.4f}, val specificity avg: {val_specificity_avg:.4f}, test specificity avg: {test_specificity_avg:.4f}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 4s 29ms/step - loss: 76.4929 - accuracy: 0.6501 - auc: 0.6619 - precision_11: 0.6501 - recall_11: 0.6501 - val_loss: 82.7118 - val_accuracy: 0.5969 - val_auc: 0.5969 - val_precision_11: 0.5969 - val_recall_11: 0.5969 - lr: 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 1.2754 - accuracy: 0.7357 - auc: 0.7636 - precision_11: 0.7357 - recall_11: 0.7357 - val_loss: 1.7336 - val_accuracy: 0.6678 - val_auc: 0.7241 - val_precision_11: 0.6678 - val_recall_11: 0.6678 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5957 - accuracy: 0.7557 - auc: 0.8295 - precision_11: 0.7557 - recall_11: 0.7557 - val_loss: 0.7909 - val_accuracy: 0.6972 - val_auc: 0.7979 - val_precision_11: 0.6972 - val_recall_11: 0.6972 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4834 - accuracy: 0.8336 - auc: 0.8977 - precision_11: 0.8336 - recall_11: 0.8336 - val_loss: 0.3537 - val_accuracy: 0.8581 - val_auc: 0.9292 - val_precision_11: 0.8581 - val_recall_11: 0.8581 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3008 - accuracy: 0.8795 - auc: 0.9453 - precision_11: 0.8795 - recall_11: 0.8795 - val_loss: 0.2362 - val_accuracy: 0.9048 - val_auc: 0.9661 - val_precision_11: 0.9048 - val_recall_11: 0.9048 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2538 - accuracy: 0.9036 - auc: 0.9618 - precision_11: 0.9036 - recall_11: 0.9036 - val_loss: 1.2843 - val_accuracy: 0.7872 - val_auc: 0.8530 - val_precision_11: 0.7872 - val_recall_11: 0.7872 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2721 - accuracy: 0.8873 - auc: 0.9559 - precision_11: 0.8873 - recall_11: 0.8873 - val_loss: 1.2928 - val_accuracy: 0.3824 - val_auc: 0.5439 - val_precision_11: 0.3824 - val_recall_11: 0.3824 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2214 - accuracy: 0.9151 - auc: 0.9700 - precision_11: 0.9151 - recall_11: 0.9151 - val_loss: 0.3073 - val_accuracy: 0.8443 - val_auc: 0.9446 - val_precision_11: 0.8443 - val_recall_11: 0.8443 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2122 - accuracy: 0.9211 - auc: 0.9722 - precision_11: 0.9211 - recall_11: 0.9211 - val_loss: 0.1868 - val_accuracy: 0.9239 - val_auc: 0.9818 - val_precision_11: 0.9239 - val_recall_11: 0.9239 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2119 - accuracy: 0.9240 - auc: 0.9727 - precision_11: 0.9240 - recall_11: 0.9240 - val_loss: 2.5448 - val_accuracy: 0.6471 - val_auc: 0.7599 - val_precision_11: 0.6471 - val_recall_11: 0.6471 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2027 - accuracy: 0.9274 - auc: 0.9741 - precision_11: 0.9274 - recall_11: 0.9274 - val_loss: 3.4520 - val_accuracy: 0.5986 - val_auc: 0.6547 - val_precision_11: 0.5986 - val_recall_11: 0.5986 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2600 - accuracy: 0.9292 - auc: 0.9738 - precision_11: 0.9292 - recall_11: 0.9292 - val_loss: 0.1981 - val_accuracy: 0.9394 - val_auc: 0.9771 - val_precision_11: 0.9394 - val_recall_11: 0.9394 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1617 - accuracy: 0.9466 - auc: 0.9829 - precision_11: 0.9466 - recall_11: 0.9466 - val_loss: 0.1721 - val_accuracy: 0.9308 - val_auc: 0.9841 - val_precision_11: 0.9308 - val_recall_11: 0.9308 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1601 - accuracy: 0.9477 - auc: 0.9831 - precision_11: 0.9477 - recall_11: 0.9477 - val_loss: 0.1463 - val_accuracy: 0.9550 - val_auc: 0.9859 - val_precision_11: 0.9550 - val_recall_11: 0.9550 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1521 - accuracy: 0.9466 - auc: 0.9855 - precision_11: 0.9466 - recall_11: 0.9466 - val_loss: 0.9758 - val_accuracy: 0.7716 - val_auc: 0.8452 - val_precision_11: 0.7716 - val_recall_11: 0.7716 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1676 - accuracy: 0.9400 - auc: 0.9820 - precision_11: 0.9400 - recall_11: 0.9400 - val_loss: 0.1908 - val_accuracy: 0.9446 - val_auc: 0.9793 - val_precision_11: 0.9446 - val_recall_11: 0.9446 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1413 - accuracy: 0.9489 - auc: 0.9871 - precision_11: 0.9489 - recall_11: 0.9489 - val_loss: 0.9813 - val_accuracy: 0.5692 - val_auc: 0.6659 - val_precision_11: 0.5692 - val_recall_11: 0.5692 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1342 - accuracy: 0.9481 - auc: 0.9889 - precision_11: 0.9481 - recall_11: 0.9481 - val_loss: 0.1707 - val_accuracy: 0.9412 - val_auc: 0.9853 - val_precision_11: 0.9412 - val_recall_11: 0.9412 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1639 - accuracy: 0.9418 - auc: 0.9832 - precision_11: 0.9418 - recall_11: 0.9418 - val_loss: 0.3665 - val_accuracy: 0.8702 - val_auc: 0.9453 - val_precision_11: 0.8702 - val_recall_11: 0.8702 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1357 - accuracy: 0.9489 - auc: 0.9877 - precision_11: 0.9489 - recall_11: 0.9489 - val_loss: 0.1612 - val_accuracy: 0.9464 - val_auc: 0.9855 - val_precision_11: 0.9464 - val_recall_11: 0.9464 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1681 - accuracy: 0.9426 - auc: 0.9821 - precision_11: 0.9426 - recall_11: 0.9426 - val_loss: 0.4681 - val_accuracy: 0.7647 - val_auc: 0.8773 - val_precision_11: 0.7647 - val_recall_11: 0.7647 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1364 - accuracy: 0.9533 - auc: 0.9876 - precision_11: 0.9533 - recall_11: 0.9533 - val_loss: 0.1567 - val_accuracy: 0.9567 - val_auc: 0.9822 - val_precision_11: 0.9567 - val_recall_11: 0.9567 - lr: 0.0050\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1205 - accuracy: 0.9589 - auc: 0.9905 - precision_11: 0.9589 - recall_11: 0.9589 - val_loss: 0.1878 - val_accuracy: 0.9464 - val_auc: 0.9779 - val_precision_11: 0.9464 - val_recall_11: 0.9464 - lr: 0.0050\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3552 - accuracy: 0.9359 - auc: 0.9698 - precision_11: 0.9359 - recall_11: 0.9359 - val_loss: 0.1802 - val_accuracy: 0.9602 - val_auc: 0.9850 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1307 - accuracy: 0.9522 - auc: 0.9888 - precision_11: 0.9522 - recall_11: 0.9522 - val_loss: 0.2497 - val_accuracy: 0.9412 - val_auc: 0.9717 - val_precision_11: 0.9412 - val_recall_11: 0.9412 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1218 - accuracy: 0.9581 - auc: 0.9898 - precision_11: 0.9581 - recall_11: 0.9581 - val_loss: 0.1977 - val_accuracy: 0.9308 - val_auc: 0.9831 - val_precision_11: 0.9308 - val_recall_11: 0.9308 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1034 - accuracy: 0.9626 - auc: 0.9927 - precision_11: 0.9626 - recall_11: 0.9626 - val_loss: 0.1468 - val_accuracy: 0.9481 - val_auc: 0.9916 - val_precision_11: 0.9481 - val_recall_11: 0.9481 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1021 - accuracy: 0.9633 - auc: 0.9925 - precision_11: 0.9633 - recall_11: 0.9633 - val_loss: 0.1015 - val_accuracy: 0.9654 - val_auc: 0.9922 - val_precision_11: 0.9654 - val_recall_11: 0.9654 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1067 - accuracy: 0.9603 - auc: 0.9925 - precision_11: 0.9603 - recall_11: 0.9603 - val_loss: 0.1270 - val_accuracy: 0.9498 - val_auc: 0.9919 - val_precision_11: 0.9498 - val_recall_11: 0.9498 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0973 - accuracy: 0.9640 - auc: 0.9938 - precision_11: 0.9640 - recall_11: 0.9640 - val_loss: 0.1125 - val_accuracy: 0.9602 - val_auc: 0.9927 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0025\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0886 - accuracy: 0.9674 - auc: 0.9949 - precision_11: 0.9674 - recall_11: 0.9674 - val_loss: 0.2619 - val_accuracy: 0.9031 - val_auc: 0.9649 - val_precision_11: 0.9031 - val_recall_11: 0.9031 - lr: 0.0025\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0877 - accuracy: 0.9685 - auc: 0.9947 - precision_11: 0.9685 - recall_11: 0.9685 - val_loss: 0.1260 - val_accuracy: 0.9585 - val_auc: 0.9911 - val_precision_11: 0.9585 - val_recall_11: 0.9585 - lr: 0.0025\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0882 - accuracy: 0.9685 - auc: 0.9947 - precision_11: 0.9685 - recall_11: 0.9685 - val_loss: 0.1592 - val_accuracy: 0.9567 - val_auc: 0.9827 - val_precision_11: 0.9567 - val_recall_11: 0.9567 - lr: 0.0025\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0897 - accuracy: 0.9685 - auc: 0.9945 - precision_11: 0.9685 - recall_11: 0.9685 - val_loss: 0.1265 - val_accuracy: 0.9602 - val_auc: 0.9906 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0025\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0856 - accuracy: 0.9715 - auc: 0.9947 - precision_11: 0.9715 - recall_11: 0.9715 - val_loss: 0.1375 - val_accuracy: 0.9619 - val_auc: 0.9908 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 0.0025\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0811 - accuracy: 0.9700 - auc: 0.9954 - precision_11: 0.9700 - recall_11: 0.9700 - val_loss: 0.1300 - val_accuracy: 0.9602 - val_auc: 0.9894 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0863 - accuracy: 0.9633 - auc: 0.9953 - precision_11: 0.9633 - recall_11: 0.9633 - val_loss: 0.1313 - val_accuracy: 0.9602 - val_auc: 0.9867 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0738 - accuracy: 0.9737 - auc: 0.9959 - precision_11: 0.9737 - recall_11: 0.9737 - val_loss: 0.3497 - val_accuracy: 0.9118 - val_auc: 0.9575 - val_precision_11: 0.9118 - val_recall_11: 0.9118 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0695 - accuracy: 0.9763 - auc: 0.9964 - precision_11: 0.9763 - recall_11: 0.9763 - val_loss: 0.2700 - val_accuracy: 0.9481 - val_auc: 0.9718 - val_precision_11: 0.9481 - val_recall_11: 0.9481 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0964 - accuracy: 0.9644 - auc: 0.9932 - precision_11: 0.9644 - recall_11: 0.9644 - val_loss: 0.3071 - val_accuracy: 0.9377 - val_auc: 0.9646 - val_precision_11: 0.9377 - val_recall_11: 0.9377 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0994 - accuracy: 0.9633 - auc: 0.9935 - precision_11: 0.9633 - recall_11: 0.9633 - val_loss: 0.8626 - val_accuracy: 0.8131 - val_auc: 0.8774 - val_precision_11: 0.8131 - val_recall_11: 0.8131 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0845 - accuracy: 0.9674 - auc: 0.9954 - precision_11: 0.9674 - recall_11: 0.9674 - val_loss: 0.1214 - val_accuracy: 0.9602 - val_auc: 0.9903 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0683 - accuracy: 0.9755 - auc: 0.9966 - precision_11: 0.9755 - recall_11: 0.9755 - val_loss: 0.1258 - val_accuracy: 0.9619 - val_auc: 0.9894 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 0.0012\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0731 - accuracy: 0.9729 - auc: 0.9964 - precision_11: 0.9729 - recall_11: 0.9729 - val_loss: 0.1191 - val_accuracy: 0.9637 - val_auc: 0.9896 - val_precision_11: 0.9637 - val_recall_11: 0.9637 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0689 - accuracy: 0.9778 - auc: 0.9960 - precision_11: 0.9778 - recall_11: 0.9778 - val_loss: 0.1295 - val_accuracy: 0.9619 - val_auc: 0.9893 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 0.0012\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0634 - accuracy: 0.9763 - auc: 0.9976 - precision_11: 0.9763 - recall_11: 0.9763 - val_loss: 0.1471 - val_accuracy: 0.9602 - val_auc: 0.9846 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 0.0012\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0543 - accuracy: 0.9815 - auc: 0.9981 - precision_11: 0.9815 - recall_11: 0.9815 - val_loss: 0.1583 - val_accuracy: 0.9585 - val_auc: 0.9871 - val_precision_11: 0.9585 - val_recall_11: 0.9585 - lr: 0.0012\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0680 - accuracy: 0.9781 - auc: 0.9967 - precision_11: 0.9781 - recall_11: 0.9781 - val_loss: 0.1427 - val_accuracy: 0.9567 - val_auc: 0.9895 - val_precision_11: 0.9567 - val_recall_11: 0.9567 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0570 - accuracy: 0.9800 - auc: 0.9978 - precision_11: 0.9800 - recall_11: 0.9800 - val_loss: 0.1628 - val_accuracy: 0.9533 - val_auc: 0.9832 - val_precision_11: 0.9533 - val_recall_11: 0.9533 - lr: 0.0012\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0564 - accuracy: 0.9781 - auc: 0.9977 - precision_11: 0.9781 - recall_11: 0.9781 - val_loss: 0.1549 - val_accuracy: 0.9619 - val_auc: 0.9852 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 0.0012\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0480 - accuracy: 0.9837 - auc: 0.9982 - precision_11: 0.9837 - recall_11: 0.9837 - val_loss: 0.2524 - val_accuracy: 0.9516 - val_auc: 0.9786 - val_precision_11: 0.9516 - val_recall_11: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0437 - accuracy: 0.9859 - auc: 0.9987 - precision_11: 0.9859 - recall_11: 0.9859 - val_loss: 0.2376 - val_accuracy: 0.9498 - val_auc: 0.9778 - val_precision_11: 0.9498 - val_recall_11: 0.9498 - lr: 6.2500e-04\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0410 - accuracy: 0.9855 - auc: 0.9988 - precision_11: 0.9855 - recall_11: 0.9855 - val_loss: 0.1753 - val_accuracy: 0.9550 - val_auc: 0.9820 - val_precision_11: 0.9550 - val_recall_11: 0.9550 - lr: 6.2500e-04\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0418 - accuracy: 0.9874 - auc: 0.9986 - precision_11: 0.9874 - recall_11: 0.9874 - val_loss: 0.1593 - val_accuracy: 0.9619 - val_auc: 0.9855 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0458 - accuracy: 0.9826 - auc: 0.9988 - precision_11: 0.9826 - recall_11: 0.9826 - val_loss: 0.1741 - val_accuracy: 0.9602 - val_auc: 0.9847 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 6.2500e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0373 - accuracy: 0.9874 - auc: 0.9991 - precision_11: 0.9874 - recall_11: 0.9874 - val_loss: 0.2879 - val_accuracy: 0.9464 - val_auc: 0.9733 - val_precision_11: 0.9464 - val_recall_11: 0.9464 - lr: 6.2500e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0397 - accuracy: 0.9848 - auc: 0.9990 - precision_11: 0.9848 - recall_11: 0.9848 - val_loss: 0.2211 - val_accuracy: 0.9567 - val_auc: 0.9822 - val_precision_11: 0.9567 - val_recall_11: 0.9567 - lr: 6.2500e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0463 - accuracy: 0.9826 - auc: 0.9985 - precision_11: 0.9826 - recall_11: 0.9826 - val_loss: 0.1571 - val_accuracy: 0.9689 - val_auc: 0.9861 - val_precision_11: 0.9689 - val_recall_11: 0.9689 - lr: 6.2500e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0378 - accuracy: 0.9863 - auc: 0.9991 - precision_11: 0.9863 - recall_11: 0.9863 - val_loss: 0.1480 - val_accuracy: 0.9671 - val_auc: 0.9881 - val_precision_11: 0.9671 - val_recall_11: 0.9671 - lr: 6.2500e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0357 - accuracy: 0.9878 - auc: 0.9992 - precision_11: 0.9878 - recall_11: 0.9878 - val_loss: 0.1822 - val_accuracy: 0.9619 - val_auc: 0.9846 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 3.1250e-04\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0340 - accuracy: 0.9885 - auc: 0.9993 - precision_11: 0.9885 - recall_11: 0.9885 - val_loss: 0.1700 - val_accuracy: 0.9671 - val_auc: 0.9865 - val_precision_11: 0.9671 - val_recall_11: 0.9671 - lr: 3.1250e-04\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0353 - accuracy: 0.9874 - auc: 0.9992 - precision_11: 0.9874 - recall_11: 0.9874 - val_loss: 0.2022 - val_accuracy: 0.9619 - val_auc: 0.9830 - val_precision_11: 0.9619 - val_recall_11: 0.9619 - lr: 3.1250e-04\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0330 - accuracy: 0.9904 - auc: 0.9989 - precision_11: 0.9904 - recall_11: 0.9904 - val_loss: 0.1597 - val_accuracy: 0.9689 - val_auc: 0.9879 - val_precision_11: 0.9689 - val_recall_11: 0.9689 - lr: 3.1250e-04\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0358 - accuracy: 0.9870 - auc: 0.9992 - precision_11: 0.9870 - recall_11: 0.9870 - val_loss: 0.1689 - val_accuracy: 0.9602 - val_auc: 0.9846 - val_precision_11: 0.9602 - val_recall_11: 0.9602 - lr: 3.1250e-04\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0356 - accuracy: 0.9881 - auc: 0.9988 - precision_11: 0.9881 - recall_11: 0.9881 - val_loss: 0.1758 - val_accuracy: 0.9637 - val_auc: 0.9845 - val_precision_11: 0.9637 - val_recall_11: 0.9637 - lr: 3.1250e-04\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0340 - accuracy: 0.9896 - auc: 0.9992 - precision_11: 0.9896 - recall_11: 0.9896 - val_loss: 0.1750 - val_accuracy: 0.9637 - val_auc: 0.9870 - val_precision_11: 0.9637 - val_recall_11: 0.9637 - lr: 3.1250e-04\n",
      "Start 2th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 102.8160 - accuracy: 0.6075 - auc: 0.6177 - precision_12: 0.6075 - recall_12: 0.6075"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 30ms/step - loss: 102.8160 - accuracy: 0.6075 - auc: 0.6177 - precision_12: 0.6075 - recall_12: 0.6075 - val_loss: 1.1918 - val_accuracy: 0.6194 - val_auc: 0.6950 - val_precision_12: 0.6194 - val_recall_12: 0.6194 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.8401 - accuracy: 0.6475 - auc: 0.7026 - precision_12: 0.6475 - recall_12: 0.6475 - val_loss: 0.8530 - val_accuracy: 0.4066 - val_auc: 0.4636 - val_precision_12: 0.4066 - val_recall_12: 0.4066 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.6542 - accuracy: 0.6931 - auc: 0.7329 - precision_12: 0.6931 - recall_12: 0.6931 - val_loss: 0.7990 - val_accuracy: 0.6661 - val_auc: 0.7227 - val_precision_12: 0.6661 - val_recall_12: 0.6661 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.6589 - accuracy: 0.7228 - auc: 0.7616 - precision_12: 0.7228 - recall_12: 0.7228 - val_loss: 0.5778 - val_accuracy: 0.7457 - val_auc: 0.7712 - val_precision_12: 0.7457 - val_recall_12: 0.7457 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5826 - accuracy: 0.7257 - auc: 0.7705 - precision_12: 0.7257 - recall_12: 0.7257 - val_loss: 0.6465 - val_accuracy: 0.6817 - val_auc: 0.7269 - val_precision_12: 0.6817 - val_recall_12: 0.6817 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5713 - accuracy: 0.7309 - auc: 0.7800 - precision_12: 0.7309 - recall_12: 0.7309 - val_loss: 0.5862 - val_accuracy: 0.7232 - val_auc: 0.7723 - val_precision_12: 0.7232 - val_recall_12: 0.7232 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5393 - accuracy: 0.7487 - auc: 0.8076 - precision_12: 0.7487 - recall_12: 0.7487 - val_loss: 0.5750 - val_accuracy: 0.7353 - val_auc: 0.7861 - val_precision_12: 0.7353 - val_recall_12: 0.7353 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5379 - accuracy: 0.7583 - auc: 0.8113 - precision_12: 0.7583 - recall_12: 0.7583 - val_loss: 0.4992 - val_accuracy: 0.7561 - val_auc: 0.8484 - val_precision_12: 0.7561 - val_recall_12: 0.7561 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5480 - accuracy: 0.7739 - auc: 0.8316 - precision_12: 0.7739 - recall_12: 0.7739 - val_loss: 0.4671 - val_accuracy: 0.7820 - val_auc: 0.8754 - val_precision_12: 0.7820 - val_recall_12: 0.7820 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4927 - accuracy: 0.7787 - auc: 0.8423 - precision_12: 0.7787 - recall_12: 0.7787 - val_loss: 0.4413 - val_accuracy: 0.7924 - val_auc: 0.8890 - val_precision_12: 0.7924 - val_recall_12: 0.7924 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5325 - accuracy: 0.7784 - auc: 0.8371 - precision_12: 0.7784 - recall_12: 0.7784 - val_loss: 0.5055 - val_accuracy: 0.7699 - val_auc: 0.8672 - val_precision_12: 0.7699 - val_recall_12: 0.7699 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4446 - accuracy: 0.7947 - auc: 0.8737 - precision_12: 0.7947 - recall_12: 0.7947 - val_loss: 0.3766 - val_accuracy: 0.8028 - val_auc: 0.9054 - val_precision_12: 0.8028 - val_recall_12: 0.8028 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3965 - accuracy: 0.8136 - auc: 0.8975 - precision_12: 0.8136 - recall_12: 0.8136 - val_loss: 0.3530 - val_accuracy: 0.8080 - val_auc: 0.9160 - val_precision_12: 0.8080 - val_recall_12: 0.8080 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3825 - accuracy: 0.8236 - auc: 0.9066 - precision_12: 0.8236 - recall_12: 0.8236 - val_loss: 0.4185 - val_accuracy: 0.7976 - val_auc: 0.9001 - val_precision_12: 0.7976 - val_recall_12: 0.7976 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3402 - accuracy: 0.8399 - auc: 0.9231 - precision_12: 0.8399 - recall_12: 0.8399 - val_loss: 0.4605 - val_accuracy: 0.7422 - val_auc: 0.8603 - val_precision_12: 0.7422 - val_recall_12: 0.7422 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.3392 - accuracy: 0.8517 - auc: 0.9289 - precision_12: 0.8517 - recall_12: 0.8517 - val_loss: 0.3872 - val_accuracy: 0.8097 - val_auc: 0.9042 - val_precision_12: 0.8097 - val_recall_12: 0.8097 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2797 - accuracy: 0.8851 - auc: 0.9501 - precision_12: 0.8851 - recall_12: 0.8851 - val_loss: 0.5098 - val_accuracy: 0.7388 - val_auc: 0.8445 - val_precision_12: 0.7388 - val_recall_12: 0.7388 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2660 - accuracy: 0.8855 - auc: 0.9560 - precision_12: 0.8855 - recall_12: 0.8855 - val_loss: 0.2527 - val_accuracy: 0.9014 - val_auc: 0.9569 - val_precision_12: 0.9014 - val_recall_12: 0.9014 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2267 - accuracy: 0.9148 - auc: 0.9675 - precision_12: 0.9148 - recall_12: 0.9148 - val_loss: 0.6709 - val_accuracy: 0.6540 - val_auc: 0.7513 - val_precision_12: 0.6540 - val_recall_12: 0.6540 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2249 - accuracy: 0.9118 - auc: 0.9694 - precision_12: 0.9118 - recall_12: 0.9118 - val_loss: 1.4640 - val_accuracy: 0.4862 - val_auc: 0.5871 - val_precision_12: 0.4862 - val_recall_12: 0.4862 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2680 - accuracy: 0.9170 - auc: 0.9693 - precision_12: 0.9170 - recall_12: 0.9170 - val_loss: 0.6385 - val_accuracy: 0.7215 - val_auc: 0.8125 - val_precision_12: 0.7215 - val_recall_12: 0.7215 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1977 - accuracy: 0.9277 - auc: 0.9760 - precision_12: 0.9277 - recall_12: 0.9277 - val_loss: 0.2161 - val_accuracy: 0.9083 - val_auc: 0.9707 - val_precision_12: 0.9083 - val_recall_12: 0.9083 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1865 - accuracy: 0.9270 - auc: 0.9781 - precision_12: 0.9270 - recall_12: 0.9270 - val_loss: 0.2595 - val_accuracy: 0.9152 - val_auc: 0.9665 - val_precision_12: 0.9152 - val_recall_12: 0.9152 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1675 - accuracy: 0.9400 - auc: 0.9822 - precision_12: 0.9400 - recall_12: 0.9400 - val_loss: 0.1862 - val_accuracy: 0.9377 - val_auc: 0.9763 - val_precision_12: 0.9377 - val_recall_12: 0.9377 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1867 - accuracy: 0.9277 - auc: 0.9784 - precision_12: 0.9277 - recall_12: 0.9277 - val_loss: 2.9755 - val_accuracy: 0.6263 - val_auc: 0.6846 - val_precision_12: 0.6263 - val_recall_12: 0.6263 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1517 - accuracy: 0.9392 - auc: 0.9858 - precision_12: 0.9392 - recall_12: 0.9392 - val_loss: 5.5853 - val_accuracy: 0.5986 - val_auc: 0.6129 - val_precision_12: 0.5986 - val_recall_12: 0.5986 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1964 - accuracy: 0.9296 - auc: 0.9776 - precision_12: 0.9296 - recall_12: 0.9296 - val_loss: 0.1745 - val_accuracy: 0.9481 - val_auc: 0.9789 - val_precision_12: 0.9481 - val_recall_12: 0.9481 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2243 - accuracy: 0.9173 - auc: 0.9709 - precision_12: 0.9173 - recall_12: 0.9173 - val_loss: 0.2813 - val_accuracy: 0.9187 - val_auc: 0.9594 - val_precision_12: 0.9187 - val_recall_12: 0.9187 - lr: 0.0100\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1624 - accuracy: 0.9385 - auc: 0.9832 - precision_12: 0.9385 - recall_12: 0.9385 - val_loss: 0.5317 - val_accuracy: 0.8927 - val_auc: 0.9306 - val_precision_12: 0.8927 - val_recall_12: 0.8927 - lr: 0.0100\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1505 - accuracy: 0.9459 - auc: 0.9847 - precision_12: 0.9459 - recall_12: 0.9459 - val_loss: 0.7335 - val_accuracy: 0.8478 - val_auc: 0.8950 - val_precision_12: 0.8478 - val_recall_12: 0.8478 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1451 - accuracy: 0.9455 - auc: 0.9867 - precision_12: 0.9455 - recall_12: 0.9455 - val_loss: 0.4344 - val_accuracy: 0.8685 - val_auc: 0.9364 - val_precision_12: 0.8685 - val_recall_12: 0.8685 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1323 - accuracy: 0.9477 - auc: 0.9890 - precision_12: 0.9477 - recall_12: 0.9477 - val_loss: 0.3116 - val_accuracy: 0.9048 - val_auc: 0.9589 - val_precision_12: 0.9048 - val_recall_12: 0.9048 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1346 - accuracy: 0.9466 - auc: 0.9881 - precision_12: 0.9466 - recall_12: 0.9466 - val_loss: 0.1888 - val_accuracy: 0.9308 - val_auc: 0.9763 - val_precision_12: 0.9308 - val_recall_12: 0.9308 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1292 - accuracy: 0.9544 - auc: 0.9895 - precision_12: 0.9544 - recall_12: 0.9544 - val_loss: 0.1628 - val_accuracy: 0.9429 - val_auc: 0.9833 - val_precision_12: 0.9429 - val_recall_12: 0.9429 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1394 - accuracy: 0.9470 - auc: 0.9879 - precision_12: 0.9470 - recall_12: 0.9470 - val_loss: 0.9552 - val_accuracy: 0.8149 - val_auc: 0.8788 - val_precision_12: 0.8149 - val_recall_12: 0.8149 - lr: 0.0050\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1407 - accuracy: 0.9500 - auc: 0.9870 - precision_12: 0.9500 - recall_12: 0.9500 - val_loss: 0.6298 - val_accuracy: 0.8651 - val_auc: 0.9089 - val_precision_12: 0.8651 - val_recall_12: 0.8651 - lr: 0.0050\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1351 - accuracy: 0.9529 - auc: 0.9885 - precision_12: 0.9529 - recall_12: 0.9529 - val_loss: 0.1626 - val_accuracy: 0.9446 - val_auc: 0.9829 - val_precision_12: 0.9446 - val_recall_12: 0.9446 - lr: 0.0050\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1199 - accuracy: 0.9611 - auc: 0.9906 - precision_12: 0.9611 - recall_12: 0.9611 - val_loss: 0.1627 - val_accuracy: 0.9464 - val_auc: 0.9818 - val_precision_12: 0.9464 - val_recall_12: 0.9464 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1151 - accuracy: 0.9637 - auc: 0.9908 - precision_12: 0.9637 - recall_12: 0.9637 - val_loss: 0.2037 - val_accuracy: 0.9498 - val_auc: 0.9779 - val_precision_12: 0.9498 - val_recall_12: 0.9498 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0981 - accuracy: 0.9655 - auc: 0.9933 - precision_12: 0.9655 - recall_12: 0.9655 - val_loss: 0.1798 - val_accuracy: 0.9308 - val_auc: 0.9819 - val_precision_12: 0.9308 - val_recall_12: 0.9308 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1025 - accuracy: 0.9618 - auc: 0.9929 - precision_12: 0.9618 - recall_12: 0.9618 - val_loss: 0.1886 - val_accuracy: 0.9412 - val_auc: 0.9802 - val_precision_12: 0.9412 - val_recall_12: 0.9412 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1049 - accuracy: 0.9603 - auc: 0.9928 - precision_12: 0.9603 - recall_12: 0.9603 - val_loss: 0.2840 - val_accuracy: 0.9170 - val_auc: 0.9653 - val_precision_12: 0.9170 - val_recall_12: 0.9170 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0999 - accuracy: 0.9648 - auc: 0.9931 - precision_12: 0.9648 - recall_12: 0.9648 - val_loss: 0.1900 - val_accuracy: 0.9377 - val_auc: 0.9790 - val_precision_12: 0.9377 - val_recall_12: 0.9377 - lr: 0.0025\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0900 - accuracy: 0.9666 - auc: 0.9947 - precision_12: 0.9666 - recall_12: 0.9666 - val_loss: 0.1871 - val_accuracy: 0.9429 - val_auc: 0.9807 - val_precision_12: 0.9429 - val_recall_12: 0.9429 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0927 - accuracy: 0.9652 - auc: 0.9941 - precision_12: 0.9652 - recall_12: 0.9652 - val_loss: 0.2179 - val_accuracy: 0.9273 - val_auc: 0.9764 - val_precision_12: 0.9273 - val_recall_12: 0.9273 - lr: 0.0012\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0871 - accuracy: 0.9703 - auc: 0.9946 - precision_12: 0.9703 - recall_12: 0.9703 - val_loss: 0.1996 - val_accuracy: 0.9429 - val_auc: 0.9776 - val_precision_12: 0.9429 - val_recall_12: 0.9429 - lr: 0.0012\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0908 - accuracy: 0.9640 - auc: 0.9948 - precision_12: 0.9640 - recall_12: 0.9640 - val_loss: 0.1963 - val_accuracy: 0.9446 - val_auc: 0.9788 - val_precision_12: 0.9446 - val_recall_12: 0.9446 - lr: 0.0012\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0898 - accuracy: 0.9685 - auc: 0.9947 - precision_12: 0.9685 - recall_12: 0.9685 - val_loss: 0.1879 - val_accuracy: 0.9412 - val_auc: 0.9809 - val_precision_12: 0.9412 - val_recall_12: 0.9412 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0885 - accuracy: 0.9685 - auc: 0.9941 - precision_12: 0.9685 - recall_12: 0.9685 - val_loss: 0.1977 - val_accuracy: 0.9343 - val_auc: 0.9808 - val_precision_12: 0.9343 - val_recall_12: 0.9343 - lr: 0.0012\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0808 - accuracy: 0.9703 - auc: 0.9958 - precision_12: 0.9703 - recall_12: 0.9703 - val_loss: 0.1856 - val_accuracy: 0.9429 - val_auc: 0.9813 - val_precision_12: 0.9429 - val_recall_12: 0.9429 - lr: 6.2500e-04\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0700 - accuracy: 0.9744 - auc: 0.9968 - precision_12: 0.9744 - recall_12: 0.9744 - val_loss: 0.1995 - val_accuracy: 0.9308 - val_auc: 0.9810 - val_precision_12: 0.9308 - val_recall_12: 0.9308 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0745 - accuracy: 0.9726 - auc: 0.9962 - precision_12: 0.9726 - recall_12: 0.9726 - val_loss: 0.1777 - val_accuracy: 0.9429 - val_auc: 0.9812 - val_precision_12: 0.9429 - val_recall_12: 0.9429 - lr: 6.2500e-04\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0839 - accuracy: 0.9729 - auc: 0.9945 - precision_12: 0.9729 - recall_12: 0.9729 - val_loss: 0.1927 - val_accuracy: 0.9446 - val_auc: 0.9809 - val_precision_12: 0.9446 - val_recall_12: 0.9446 - lr: 6.2500e-04\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0723 - accuracy: 0.9733 - auc: 0.9967 - precision_12: 0.9733 - recall_12: 0.9733 - val_loss: 0.2509 - val_accuracy: 0.9325 - val_auc: 0.9722 - val_precision_12: 0.9325 - val_recall_12: 0.9325 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0694 - accuracy: 0.9744 - auc: 0.9964 - precision_12: 0.9744 - recall_12: 0.9744 - val_loss: 0.1947 - val_accuracy: 0.9446 - val_auc: 0.9812 - val_precision_12: 0.9446 - val_recall_12: 0.9446 - lr: 3.1250e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0750 - accuracy: 0.9763 - auc: 0.9960 - precision_12: 0.9763 - recall_12: 0.9763 - val_loss: 0.1855 - val_accuracy: 0.9481 - val_auc: 0.9825 - val_precision_12: 0.9481 - val_recall_12: 0.9481 - lr: 3.1250e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0684 - accuracy: 0.9748 - auc: 0.9966 - precision_12: 0.9748 - recall_12: 0.9748 - val_loss: 0.1832 - val_accuracy: 0.9446 - val_auc: 0.9824 - val_precision_12: 0.9446 - val_recall_12: 0.9446 - lr: 3.1250e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0741 - accuracy: 0.9733 - auc: 0.9962 - precision_12: 0.9733 - recall_12: 0.9733 - val_loss: 0.1844 - val_accuracy: 0.9446 - val_auc: 0.9811 - val_precision_12: 0.9446 - val_recall_12: 0.9446 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0634 - accuracy: 0.9770 - auc: 0.9973 - precision_12: 0.9770 - recall_12: 0.9770 - val_loss: 0.1922 - val_accuracy: 0.9412 - val_auc: 0.9813 - val_precision_12: 0.9412 - val_recall_12: 0.9412 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0673 - accuracy: 0.9733 - auc: 0.9964 - precision_12: 0.9733 - recall_12: 0.9733 - val_loss: 0.1859 - val_accuracy: 0.9412 - val_auc: 0.9823 - val_precision_12: 0.9412 - val_recall_12: 0.9412 - lr: 3.1250e-04\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0686 - accuracy: 0.9759 - auc: 0.9962 - precision_12: 0.9759 - recall_12: 0.9759 - val_loss: 0.2128 - val_accuracy: 0.9325 - val_auc: 0.9807 - val_precision_12: 0.9325 - val_recall_12: 0.9325 - lr: 3.1250e-04\n",
      "Start 3th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 4s 30ms/step - loss: 119.9034 - accuracy: 0.5838 - auc: 0.5896 - precision_13: 0.5838 - recall_13: 0.5838 - val_loss: 56.0893 - val_accuracy: 0.4031 - val_auc: 0.4031 - val_precision_13: 0.4031 - val_recall_13: 0.4031 - lr: 0.0100\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 2s 25ms/step - loss: 0.7859 - accuracy: 0.7554 - auc: 0.8139 - precision_13: 0.7554 - recall_13: 0.7554 - val_loss: 3.1659 - val_accuracy: 0.3339 - val_auc: 0.4028 - val_precision_13: 0.3339 - val_recall_13: 0.3339 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.3420 - accuracy: 0.8658 - auc: 0.9300 - precision_13: 0.8658 - recall_13: 0.8658 - val_loss: 0.9842 - val_accuracy: 0.7595 - val_auc: 0.7903 - val_precision_13: 0.7595 - val_recall_13: 0.7595 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.3108 - accuracy: 0.8851 - auc: 0.9446 - precision_13: 0.8851 - recall_13: 0.8851 - val_loss: 0.4340 - val_accuracy: 0.7907 - val_auc: 0.8873 - val_precision_13: 0.7907 - val_recall_13: 0.7907 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2461 - accuracy: 0.9073 - auc: 0.9642 - precision_13: 0.9073 - recall_13: 0.9073 - val_loss: 0.6086 - val_accuracy: 0.6903 - val_auc: 0.7725 - val_precision_13: 0.6903 - val_recall_13: 0.6903 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2482 - accuracy: 0.9040 - auc: 0.9626 - precision_13: 0.9040 - recall_13: 0.9040 - val_loss: 0.9127 - val_accuracy: 0.5329 - val_auc: 0.6382 - val_precision_13: 0.5329 - val_recall_13: 0.5329 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2027 - accuracy: 0.9199 - auc: 0.9750 - precision_13: 0.9199 - recall_13: 0.9199 - val_loss: 0.9315 - val_accuracy: 0.4931 - val_auc: 0.6459 - val_precision_13: 0.4931 - val_recall_13: 0.4931 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1776 - accuracy: 0.9337 - auc: 0.9806 - precision_13: 0.9337 - recall_13: 0.9337 - val_loss: 0.1699 - val_accuracy: 0.9308 - val_auc: 0.9845 - val_precision_13: 0.9308 - val_recall_13: 0.9308 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1763 - accuracy: 0.9322 - auc: 0.9809 - precision_13: 0.9322 - recall_13: 0.9322 - val_loss: 0.1583 - val_accuracy: 0.9377 - val_auc: 0.9848 - val_precision_13: 0.9377 - val_recall_13: 0.9377 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1566 - accuracy: 0.9429 - auc: 0.9842 - precision_13: 0.9429 - recall_13: 0.9429 - val_loss: 0.1103 - val_accuracy: 0.9498 - val_auc: 0.9927 - val_precision_13: 0.9498 - val_recall_13: 0.9498 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1539 - accuracy: 0.9385 - auc: 0.9854 - precision_13: 0.9385 - recall_13: 0.9385 - val_loss: 1.4903 - val_accuracy: 0.5087 - val_auc: 0.6385 - val_precision_13: 0.5087 - val_recall_13: 0.5087 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1594 - accuracy: 0.9366 - auc: 0.9836 - precision_13: 0.9366 - recall_13: 0.9366 - val_loss: 0.1064 - val_accuracy: 0.9619 - val_auc: 0.9934 - val_precision_13: 0.9619 - val_recall_13: 0.9619 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1322 - accuracy: 0.9489 - auc: 0.9885 - precision_13: 0.9489 - recall_13: 0.9489 - val_loss: 0.1172 - val_accuracy: 0.9516 - val_auc: 0.9915 - val_precision_13: 0.9516 - val_recall_13: 0.9516 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1390 - accuracy: 0.9463 - auc: 0.9878 - precision_13: 0.9463 - recall_13: 0.9463 - val_loss: 0.3927 - val_accuracy: 0.8408 - val_auc: 0.9272 - val_precision_13: 0.8408 - val_recall_13: 0.8408 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1513 - accuracy: 0.9359 - auc: 0.9858 - precision_13: 0.9359 - recall_13: 0.9359 - val_loss: 0.2449 - val_accuracy: 0.9100 - val_auc: 0.9634 - val_precision_13: 0.9100 - val_recall_13: 0.9100 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1281 - accuracy: 0.9511 - auc: 0.9895 - precision_13: 0.9511 - recall_13: 0.9511 - val_loss: 0.1240 - val_accuracy: 0.9498 - val_auc: 0.9904 - val_precision_13: 0.9498 - val_recall_13: 0.9498 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1217 - accuracy: 0.9514 - auc: 0.9906 - precision_13: 0.9514 - recall_13: 0.9514 - val_loss: 1.0218 - val_accuracy: 0.5450 - val_auc: 0.7038 - val_precision_13: 0.5450 - val_recall_13: 0.5450 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1187 - accuracy: 0.9522 - auc: 0.9911 - precision_13: 0.9522 - recall_13: 0.9522 - val_loss: 1.3127 - val_accuracy: 0.5381 - val_auc: 0.6769 - val_precision_13: 0.5381 - val_recall_13: 0.5381 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1013 - accuracy: 0.9622 - auc: 0.9932 - precision_13: 0.9622 - recall_13: 0.9622 - val_loss: 0.1207 - val_accuracy: 0.9637 - val_auc: 0.9902 - val_precision_13: 0.9637 - val_recall_13: 0.9637 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1125 - accuracy: 0.9581 - auc: 0.9916 - precision_13: 0.9581 - recall_13: 0.9581 - val_loss: 0.1232 - val_accuracy: 0.9602 - val_auc: 0.9885 - val_precision_13: 0.9602 - val_recall_13: 0.9602 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1116 - accuracy: 0.9589 - auc: 0.9913 - precision_13: 0.9589 - recall_13: 0.9589 - val_loss: 0.8621 - val_accuracy: 0.7682 - val_auc: 0.8803 - val_precision_13: 0.7682 - val_recall_13: 0.7682 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1066 - accuracy: 0.9563 - auc: 0.9924 - precision_13: 0.9563 - recall_13: 0.9563 - val_loss: 0.0937 - val_accuracy: 0.9619 - val_auc: 0.9947 - val_precision_13: 0.9619 - val_recall_13: 0.9619 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0822 - accuracy: 0.9689 - auc: 0.9958 - precision_13: 0.9689 - recall_13: 0.9689 - val_loss: 0.2307 - val_accuracy: 0.8997 - val_auc: 0.9710 - val_precision_13: 0.8997 - val_recall_13: 0.8997 - lr: 0.0050\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0794 - accuracy: 0.9678 - auc: 0.9959 - precision_13: 0.9678 - recall_13: 0.9678 - val_loss: 0.0736 - val_accuracy: 0.9689 - val_auc: 0.9967 - val_precision_13: 0.9689 - val_recall_13: 0.9689 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0684 - accuracy: 0.9733 - auc: 0.9964 - precision_13: 0.9733 - recall_13: 0.9733 - val_loss: 0.1379 - val_accuracy: 0.9412 - val_auc: 0.9879 - val_precision_13: 0.9412 - val_recall_13: 0.9412 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0751 - accuracy: 0.9700 - auc: 0.9958 - precision_13: 0.9700 - recall_13: 0.9700 - val_loss: 0.0757 - val_accuracy: 0.9654 - val_auc: 0.9968 - val_precision_13: 0.9654 - val_recall_13: 0.9654 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0660 - accuracy: 0.9729 - auc: 0.9971 - precision_13: 0.9729 - recall_13: 0.9729 - val_loss: 0.2458 - val_accuracy: 0.9031 - val_auc: 0.9723 - val_precision_13: 0.9031 - val_recall_13: 0.9031 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0680 - accuracy: 0.9715 - auc: 0.9972 - precision_13: 0.9715 - recall_13: 0.9715 - val_loss: 0.3344 - val_accuracy: 0.9170 - val_auc: 0.9609 - val_precision_13: 0.9170 - val_recall_13: 0.9170 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0596 - accuracy: 0.9748 - auc: 0.9979 - precision_13: 0.9748 - recall_13: 0.9748 - val_loss: 1.7080 - val_accuracy: 0.6298 - val_auc: 0.6917 - val_precision_13: 0.6298 - val_recall_13: 0.6298 - lr: 0.0050\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0648 - accuracy: 0.9741 - auc: 0.9975 - precision_13: 0.9741 - recall_13: 0.9741 - val_loss: 0.0899 - val_accuracy: 0.9654 - val_auc: 0.9932 - val_precision_13: 0.9654 - val_recall_13: 0.9654 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0526 - accuracy: 0.9781 - auc: 0.9983 - precision_13: 0.9781 - recall_13: 0.9781 - val_loss: 0.1196 - val_accuracy: 0.9602 - val_auc: 0.9912 - val_precision_13: 0.9602 - val_recall_13: 0.9602 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0619 - accuracy: 0.9763 - auc: 0.9971 - precision_13: 0.9763 - recall_13: 0.9763 - val_loss: 0.2016 - val_accuracy: 0.9446 - val_auc: 0.9794 - val_precision_13: 0.9446 - val_recall_13: 0.9446 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0593 - accuracy: 0.9755 - auc: 0.9976 - precision_13: 0.9755 - recall_13: 0.9755 - val_loss: 0.2538 - val_accuracy: 0.9118 - val_auc: 0.9696 - val_precision_13: 0.9118 - val_recall_13: 0.9118 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0832 - accuracy: 0.9681 - auc: 0.9950 - precision_13: 0.9681 - recall_13: 0.9681 - val_loss: 0.3178 - val_accuracy: 0.8789 - val_auc: 0.9490 - val_precision_13: 0.8789 - val_recall_13: 0.8789 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0469 - accuracy: 0.9837 - auc: 0.9984 - precision_13: 0.9837 - recall_13: 0.9837 - val_loss: 0.1307 - val_accuracy: 0.9550 - val_auc: 0.9869 - val_precision_13: 0.9550 - val_recall_13: 0.9550 - lr: 0.0025\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0389 - accuracy: 0.9830 - auc: 0.9991 - precision_13: 0.9830 - recall_13: 0.9830 - val_loss: 0.0844 - val_accuracy: 0.9671 - val_auc: 0.9967 - val_precision_13: 0.9671 - val_recall_13: 0.9671 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0362 - accuracy: 0.9859 - auc: 0.9993 - precision_13: 0.9859 - recall_13: 0.9859 - val_loss: 0.0867 - val_accuracy: 0.9671 - val_auc: 0.9953 - val_precision_13: 0.9671 - val_recall_13: 0.9671 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0330 - accuracy: 0.9878 - auc: 0.9990 - precision_13: 0.9878 - recall_13: 0.9878 - val_loss: 0.1331 - val_accuracy: 0.9533 - val_auc: 0.9923 - val_precision_13: 0.9533 - val_recall_13: 0.9533 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0386 - accuracy: 0.9848 - auc: 0.9988 - precision_13: 0.9848 - recall_13: 0.9848 - val_loss: 0.0789 - val_accuracy: 0.9637 - val_auc: 0.9966 - val_precision_13: 0.9637 - val_recall_13: 0.9637 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0337 - accuracy: 0.9833 - auc: 0.9993 - precision_13: 0.9833 - recall_13: 0.9833 - val_loss: 0.0829 - val_accuracy: 0.9758 - val_auc: 0.9946 - val_precision_13: 0.9758 - val_recall_13: 0.9758 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0365 - accuracy: 0.9859 - auc: 0.9992 - precision_13: 0.9859 - recall_13: 0.9859 - val_loss: 0.1827 - val_accuracy: 0.9325 - val_auc: 0.9843 - val_precision_13: 0.9325 - val_recall_13: 0.9325 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0237 - accuracy: 0.9907 - auc: 0.9997 - precision_13: 0.9907 - recall_13: 0.9907 - val_loss: 0.1282 - val_accuracy: 0.9533 - val_auc: 0.9902 - val_precision_13: 0.9533 - val_recall_13: 0.9533 - lr: 0.0012\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0200 - accuracy: 0.9911 - auc: 0.9998 - precision_13: 0.9911 - recall_13: 0.9911 - val_loss: 0.0964 - val_accuracy: 0.9637 - val_auc: 0.9940 - val_precision_13: 0.9637 - val_recall_13: 0.9637 - lr: 0.0012\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0232 - accuracy: 0.9900 - auc: 0.9997 - precision_13: 0.9900 - recall_13: 0.9900 - val_loss: 0.1354 - val_accuracy: 0.9585 - val_auc: 0.9895 - val_precision_13: 0.9585 - val_recall_13: 0.9585 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0167 - accuracy: 0.9944 - auc: 0.9999 - precision_13: 0.9944 - recall_13: 0.9944 - val_loss: 0.1321 - val_accuracy: 0.9619 - val_auc: 0.9916 - val_precision_13: 0.9619 - val_recall_13: 0.9619 - lr: 0.0012\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0251 - accuracy: 0.9911 - auc: 0.9993 - precision_13: 0.9911 - recall_13: 0.9911 - val_loss: 0.2665 - val_accuracy: 0.9291 - val_auc: 0.9731 - val_precision_13: 0.9291 - val_recall_13: 0.9291 - lr: 0.0012\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0264 - accuracy: 0.9878 - auc: 0.9996 - precision_13: 0.9878 - recall_13: 0.9878 - val_loss: 0.0962 - val_accuracy: 0.9654 - val_auc: 0.9953 - val_precision_13: 0.9654 - val_recall_13: 0.9654 - lr: 0.0012\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0250 - accuracy: 0.9911 - auc: 0.9996 - precision_13: 0.9911 - recall_13: 0.9911 - val_loss: 0.0800 - val_accuracy: 0.9706 - val_auc: 0.9948 - val_precision_13: 0.9706 - val_recall_13: 0.9706 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0157 - accuracy: 0.9941 - auc: 0.9999 - precision_13: 0.9941 - recall_13: 0.9941 - val_loss: 0.0851 - val_accuracy: 0.9706 - val_auc: 0.9946 - val_precision_13: 0.9706 - val_recall_13: 0.9706 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0155 - accuracy: 0.9937 - auc: 0.9999 - precision_13: 0.9937 - recall_13: 0.9937 - val_loss: 0.1073 - val_accuracy: 0.9671 - val_auc: 0.9941 - val_precision_13: 0.9671 - val_recall_13: 0.9671 - lr: 6.2500e-04\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0178 - accuracy: 0.9944 - auc: 0.9995 - precision_13: 0.9944 - recall_13: 0.9944 - val_loss: 0.1616 - val_accuracy: 0.9602 - val_auc: 0.9893 - val_precision_13: 0.9602 - val_recall_13: 0.9602 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0330 - accuracy: 0.9867 - auc: 0.9994 - precision_13: 0.9867 - recall_13: 0.9867 - val_loss: 0.0983 - val_accuracy: 0.9654 - val_auc: 0.9944 - val_precision_13: 0.9654 - val_recall_13: 0.9654 - lr: 6.2500e-04\n",
      "Start 4th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 122.8837 - accuracy: 0.6490 - auc: 0.6666 - precision_14: 0.6490 - recall_14: 0.6490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 30ms/step - loss: 122.8837 - accuracy: 0.6490 - auc: 0.6666 - precision_14: 0.6490 - recall_14: 0.6490 - val_loss: 81.2394 - val_accuracy: 0.5969 - val_auc: 0.5969 - val_precision_14: 0.5969 - val_recall_14: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.9885 - accuracy: 0.7298 - auc: 0.8016 - precision_14: 0.7298 - recall_14: 0.7298 - val_loss: 3.6986 - val_accuracy: 0.6505 - val_auc: 0.6390 - val_precision_14: 0.6505 - val_recall_14: 0.6505 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5219 - accuracy: 0.7950 - auc: 0.8718 - precision_14: 0.7950 - recall_14: 0.7950 - val_loss: 1.3581 - val_accuracy: 0.7249 - val_auc: 0.6476 - val_precision_14: 0.7249 - val_recall_14: 0.7249 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3958 - accuracy: 0.8225 - auc: 0.9059 - precision_14: 0.8225 - recall_14: 0.8225 - val_loss: 0.4673 - val_accuracy: 0.7491 - val_auc: 0.8609 - val_precision_14: 0.7491 - val_recall_14: 0.7491 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3563 - accuracy: 0.8358 - auc: 0.9195 - precision_14: 0.8358 - recall_14: 0.8358 - val_loss: 0.3088 - val_accuracy: 0.8599 - val_auc: 0.9432 - val_precision_14: 0.8599 - val_recall_14: 0.8599 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.3533 - accuracy: 0.8484 - auc: 0.9265 - precision_14: 0.8484 - recall_14: 0.8484 - val_loss: 0.3097 - val_accuracy: 0.8806 - val_auc: 0.9449 - val_precision_14: 0.8806 - val_recall_14: 0.8806 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3006 - accuracy: 0.8643 - auc: 0.9448 - precision_14: 0.8643 - recall_14: 0.8643 - val_loss: 0.6910 - val_accuracy: 0.7353 - val_auc: 0.8556 - val_precision_14: 0.7353 - val_recall_14: 0.7353 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2972 - accuracy: 0.8729 - auc: 0.9471 - precision_14: 0.8729 - recall_14: 0.8729 - val_loss: 0.2877 - val_accuracy: 0.8737 - val_auc: 0.9570 - val_precision_14: 0.8737 - val_recall_14: 0.8737 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.2895 - accuracy: 0.8710 - auc: 0.9479 - precision_14: 0.8710 - recall_14: 0.8710 - val_loss: 0.2546 - val_accuracy: 0.8945 - val_auc: 0.9619 - val_precision_14: 0.8945 - val_recall_14: 0.8945 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2597 - accuracy: 0.8907 - auc: 0.9603 - precision_14: 0.8907 - recall_14: 0.8907 - val_loss: 0.9560 - val_accuracy: 0.7284 - val_auc: 0.8458 - val_precision_14: 0.7284 - val_recall_14: 0.7284 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2956 - accuracy: 0.8821 - auc: 0.9511 - precision_14: 0.8821 - recall_14: 0.8821 - val_loss: 0.4273 - val_accuracy: 0.7993 - val_auc: 0.9045 - val_precision_14: 0.7993 - val_recall_14: 0.7993 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2375 - accuracy: 0.8984 - auc: 0.9661 - precision_14: 0.8984 - recall_14: 0.8984 - val_loss: 0.2398 - val_accuracy: 0.8893 - val_auc: 0.9670 - val_precision_14: 0.8893 - val_recall_14: 0.8893 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1920 - accuracy: 0.9248 - auc: 0.9775 - precision_14: 0.9248 - recall_14: 0.9248 - val_loss: 0.2576 - val_accuracy: 0.8979 - val_auc: 0.9664 - val_precision_14: 0.8979 - val_recall_14: 0.8979 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1847 - accuracy: 0.9318 - auc: 0.9788 - precision_14: 0.9318 - recall_14: 0.9318 - val_loss: 0.4855 - val_accuracy: 0.7889 - val_auc: 0.8697 - val_precision_14: 0.7889 - val_recall_14: 0.7889 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1624 - accuracy: 0.9385 - auc: 0.9836 - precision_14: 0.9385 - recall_14: 0.9385 - val_loss: 0.4294 - val_accuracy: 0.8443 - val_auc: 0.9278 - val_precision_14: 0.8443 - val_recall_14: 0.8443 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1692 - accuracy: 0.9370 - auc: 0.9823 - precision_14: 0.9370 - recall_14: 0.9370 - val_loss: 0.1539 - val_accuracy: 0.9394 - val_auc: 0.9838 - val_precision_14: 0.9394 - val_recall_14: 0.9394 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1590 - accuracy: 0.9411 - auc: 0.9846 - precision_14: 0.9411 - recall_14: 0.9411 - val_loss: 0.1913 - val_accuracy: 0.9481 - val_auc: 0.9766 - val_precision_14: 0.9481 - val_recall_14: 0.9481 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1431 - accuracy: 0.9440 - auc: 0.9869 - precision_14: 0.9440 - recall_14: 0.9440 - val_loss: 0.2672 - val_accuracy: 0.9135 - val_auc: 0.9642 - val_precision_14: 0.9135 - val_recall_14: 0.9135 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1361 - accuracy: 0.9503 - auc: 0.9884 - precision_14: 0.9503 - recall_14: 0.9503 - val_loss: 0.9157 - val_accuracy: 0.7803 - val_auc: 0.8755 - val_precision_14: 0.7803 - val_recall_14: 0.7803 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1223 - accuracy: 0.9555 - auc: 0.9903 - precision_14: 0.9555 - recall_14: 0.9555 - val_loss: 0.8648 - val_accuracy: 0.6246 - val_auc: 0.7629 - val_precision_14: 0.6246 - val_recall_14: 0.6246 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1266 - accuracy: 0.9544 - auc: 0.9896 - precision_14: 0.9544 - recall_14: 0.9544 - val_loss: 1.1396 - val_accuracy: 0.5554 - val_auc: 0.6727 - val_precision_14: 0.5554 - val_recall_14: 0.5554 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1357 - accuracy: 0.9470 - auc: 0.9883 - precision_14: 0.9470 - recall_14: 0.9470 - val_loss: 0.2314 - val_accuracy: 0.9014 - val_auc: 0.9672 - val_precision_14: 0.9014 - val_recall_14: 0.9014 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1293 - accuracy: 0.9537 - auc: 0.9892 - precision_14: 0.9537 - recall_14: 0.9537 - val_loss: 0.1428 - val_accuracy: 0.9533 - val_auc: 0.9875 - val_precision_14: 0.9533 - val_recall_14: 0.9533 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1118 - accuracy: 0.9577 - auc: 0.9916 - precision_14: 0.9577 - recall_14: 0.9577 - val_loss: 0.1521 - val_accuracy: 0.9464 - val_auc: 0.9847 - val_precision_14: 0.9464 - val_recall_14: 0.9464 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1225 - accuracy: 0.9511 - auc: 0.9906 - precision_14: 0.9511 - recall_14: 0.9511 - val_loss: 0.2806 - val_accuracy: 0.9394 - val_auc: 0.9664 - val_precision_14: 0.9394 - val_recall_14: 0.9394 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1136 - accuracy: 0.9596 - auc: 0.9911 - precision_14: 0.9596 - recall_14: 0.9596 - val_loss: 0.2077 - val_accuracy: 0.9239 - val_auc: 0.9796 - val_precision_14: 0.9239 - val_recall_14: 0.9239 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0946 - accuracy: 0.9629 - auc: 0.9940 - precision_14: 0.9629 - recall_14: 0.9629 - val_loss: 0.1596 - val_accuracy: 0.9481 - val_auc: 0.9848 - val_precision_14: 0.9481 - val_recall_14: 0.9481 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0854 - accuracy: 0.9629 - auc: 0.9954 - precision_14: 0.9629 - recall_14: 0.9629 - val_loss: 0.2016 - val_accuracy: 0.9308 - val_auc: 0.9804 - val_precision_14: 0.9308 - val_recall_14: 0.9308 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0771 - accuracy: 0.9703 - auc: 0.9962 - precision_14: 0.9703 - recall_14: 0.9703 - val_loss: 0.2675 - val_accuracy: 0.9412 - val_auc: 0.9697 - val_precision_14: 0.9412 - val_recall_14: 0.9412 - lr: 0.0050\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0860 - accuracy: 0.9640 - auc: 0.9955 - precision_14: 0.9640 - recall_14: 0.9640 - val_loss: 0.4237 - val_accuracy: 0.8651 - val_auc: 0.9437 - val_precision_14: 0.8651 - val_recall_14: 0.8651 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0918 - accuracy: 0.9640 - auc: 0.9941 - precision_14: 0.9640 - recall_14: 0.9640 - val_loss: 0.3472 - val_accuracy: 0.8893 - val_auc: 0.9471 - val_precision_14: 0.8893 - val_recall_14: 0.8893 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0666 - accuracy: 0.9711 - auc: 0.9973 - precision_14: 0.9711 - recall_14: 0.9711 - val_loss: 0.5306 - val_accuracy: 0.8512 - val_auc: 0.9341 - val_precision_14: 0.8512 - val_recall_14: 0.8512 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0895 - accuracy: 0.9615 - auc: 0.9950 - precision_14: 0.9615 - recall_14: 0.9615 - val_loss: 0.2754 - val_accuracy: 0.9135 - val_auc: 0.9722 - val_precision_14: 0.9135 - val_recall_14: 0.9135 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0886 - accuracy: 0.9670 - auc: 0.9951 - precision_14: 0.9670 - recall_14: 0.9670 - val_loss: 0.2609 - val_accuracy: 0.9308 - val_auc: 0.9717 - val_precision_14: 0.9308 - val_recall_14: 0.9308 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0897 - accuracy: 0.9663 - auc: 0.9942 - precision_14: 0.9663 - recall_14: 0.9663 - val_loss: 0.1740 - val_accuracy: 0.9360 - val_auc: 0.9823 - val_precision_14: 0.9360 - val_recall_14: 0.9360 - lr: 0.0050\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0577 - accuracy: 0.9770 - auc: 0.9979 - precision_14: 0.9770 - recall_14: 0.9770 - val_loss: 0.1606 - val_accuracy: 0.9533 - val_auc: 0.9856 - val_precision_14: 0.9533 - val_recall_14: 0.9533 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0587 - accuracy: 0.9785 - auc: 0.9976 - precision_14: 0.9785 - recall_14: 0.9785 - val_loss: 0.3250 - val_accuracy: 0.9291 - val_auc: 0.9641 - val_precision_14: 0.9291 - val_recall_14: 0.9291 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0489 - accuracy: 0.9804 - auc: 0.9983 - precision_14: 0.9804 - recall_14: 0.9804 - val_loss: 0.3602 - val_accuracy: 0.9291 - val_auc: 0.9648 - val_precision_14: 0.9291 - val_recall_14: 0.9291 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0494 - accuracy: 0.9822 - auc: 0.9982 - precision_14: 0.9822 - recall_14: 0.9822 - val_loss: 0.2317 - val_accuracy: 0.9429 - val_auc: 0.9787 - val_precision_14: 0.9429 - val_recall_14: 0.9429 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0509 - accuracy: 0.9807 - auc: 0.9981 - precision_14: 0.9807 - recall_14: 0.9807 - val_loss: 0.4679 - val_accuracy: 0.9118 - val_auc: 0.9487 - val_precision_14: 0.9118 - val_recall_14: 0.9118 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0499 - accuracy: 0.9807 - auc: 0.9982 - precision_14: 0.9807 - recall_14: 0.9807 - val_loss: 0.2050 - val_accuracy: 0.9429 - val_auc: 0.9780 - val_precision_14: 0.9429 - val_recall_14: 0.9429 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0355 - accuracy: 0.9848 - auc: 0.9993 - precision_14: 0.9848 - recall_14: 0.9848 - val_loss: 0.1959 - val_accuracy: 0.9516 - val_auc: 0.9804 - val_precision_14: 0.9516 - val_recall_14: 0.9516 - lr: 0.0012\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0345 - accuracy: 0.9855 - auc: 0.9993 - precision_14: 0.9855 - recall_14: 0.9855 - val_loss: 0.2216 - val_accuracy: 0.9360 - val_auc: 0.9779 - val_precision_14: 0.9360 - val_recall_14: 0.9360 - lr: 0.0012\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0306 - accuracy: 0.9878 - auc: 0.9995 - precision_14: 0.9878 - recall_14: 0.9878 - val_loss: 0.1859 - val_accuracy: 0.9567 - val_auc: 0.9817 - val_precision_14: 0.9567 - val_recall_14: 0.9567 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0258 - accuracy: 0.9904 - auc: 0.9996 - precision_14: 0.9904 - recall_14: 0.9904 - val_loss: 0.1999 - val_accuracy: 0.9533 - val_auc: 0.9810 - val_precision_14: 0.9533 - val_recall_14: 0.9533 - lr: 0.0012\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0358 - accuracy: 0.9855 - auc: 0.9992 - precision_14: 0.9855 - recall_14: 0.9855 - val_loss: 0.1960 - val_accuracy: 0.9464 - val_auc: 0.9836 - val_precision_14: 0.9464 - val_recall_14: 0.9464 - lr: 0.0012\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0308 - accuracy: 0.9885 - auc: 0.9994 - precision_14: 0.9885 - recall_14: 0.9885 - val_loss: 0.2002 - val_accuracy: 0.9498 - val_auc: 0.9804 - val_precision_14: 0.9498 - val_recall_14: 0.9498 - lr: 0.0012\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0326 - accuracy: 0.9870 - auc: 0.9991 - precision_14: 0.9870 - recall_14: 0.9870 - val_loss: 0.2964 - val_accuracy: 0.9273 - val_auc: 0.9698 - val_precision_14: 0.9273 - val_recall_14: 0.9273 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0372 - accuracy: 0.9863 - auc: 0.9992 - precision_14: 0.9863 - recall_14: 0.9863 - val_loss: 0.2115 - val_accuracy: 0.9464 - val_auc: 0.9799 - val_precision_14: 0.9464 - val_recall_14: 0.9464 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0239 - accuracy: 0.9907 - auc: 0.9997 - precision_14: 0.9907 - recall_14: 0.9907 - val_loss: 0.2455 - val_accuracy: 0.9550 - val_auc: 0.9762 - val_precision_14: 0.9550 - val_recall_14: 0.9550 - lr: 6.2500e-04\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0174 - accuracy: 0.9948 - auc: 0.9999 - precision_14: 0.9948 - recall_14: 0.9948 - val_loss: 0.2664 - val_accuracy: 0.9516 - val_auc: 0.9763 - val_precision_14: 0.9516 - val_recall_14: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0245 - accuracy: 0.9904 - auc: 0.9996 - precision_14: 0.9904 - recall_14: 0.9904 - val_loss: 0.2363 - val_accuracy: 0.9429 - val_auc: 0.9790 - val_precision_14: 0.9429 - val_recall_14: 0.9429 - lr: 6.2500e-04\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0242 - accuracy: 0.9911 - auc: 0.9996 - precision_14: 0.9911 - recall_14: 0.9911 - val_loss: 0.2281 - val_accuracy: 0.9481 - val_auc: 0.9779 - val_precision_14: 0.9481 - val_recall_14: 0.9481 - lr: 6.2500e-04\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0233 - accuracy: 0.9918 - auc: 0.9997 - precision_14: 0.9918 - recall_14: 0.9918 - val_loss: 0.2337 - val_accuracy: 0.9533 - val_auc: 0.9785 - val_precision_14: 0.9533 - val_recall_14: 0.9533 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0194 - accuracy: 0.9922 - auc: 0.9998 - precision_14: 0.9922 - recall_14: 0.9922 - val_loss: 0.2435 - val_accuracy: 0.9498 - val_auc: 0.9770 - val_precision_14: 0.9498 - val_recall_14: 0.9498 - lr: 3.1250e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0185 - accuracy: 0.9930 - auc: 0.9998 - precision_14: 0.9930 - recall_14: 0.9930 - val_loss: 0.2741 - val_accuracy: 0.9498 - val_auc: 0.9749 - val_precision_14: 0.9498 - val_recall_14: 0.9498 - lr: 3.1250e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0156 - accuracy: 0.9937 - auc: 0.9999 - precision_14: 0.9937 - recall_14: 0.9937 - val_loss: 0.2716 - val_accuracy: 0.9498 - val_auc: 0.9800 - val_precision_14: 0.9498 - val_recall_14: 0.9498 - lr: 3.1250e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0179 - accuracy: 0.9941 - auc: 0.9998 - precision_14: 0.9941 - recall_14: 0.9941 - val_loss: 0.2350 - val_accuracy: 0.9533 - val_auc: 0.9784 - val_precision_14: 0.9533 - val_recall_14: 0.9533 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0149 - accuracy: 0.9963 - auc: 0.9999 - precision_14: 0.9963 - recall_14: 0.9963 - val_loss: 0.2327 - val_accuracy: 0.9516 - val_auc: 0.9802 - val_precision_14: 0.9516 - val_recall_14: 0.9516 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0230 - accuracy: 0.9904 - auc: 0.9994 - precision_14: 0.9904 - recall_14: 0.9904 - val_loss: 0.2590 - val_accuracy: 0.9464 - val_auc: 0.9798 - val_precision_14: 0.9464 - val_recall_14: 0.9464 - lr: 3.1250e-04\n",
      "Start 5th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - 4s 30ms/step - loss: 102.4483 - accuracy: 0.6353 - auc: 0.6454 - precision_15: 0.6353 - recall_15: 0.6353 - val_loss: 1.2541 - val_accuracy: 0.5969 - val_auc: 0.5060 - val_precision_15: 0.5969 - val_recall_15: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 2s 25ms/step - loss: 0.7170 - accuracy: 0.7557 - auc: 0.7824 - precision_15: 0.7557 - recall_15: 0.7557 - val_loss: 0.8484 - val_accuracy: 0.4844 - val_auc: 0.4726 - val_precision_15: 0.4844 - val_recall_15: 0.4844 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5217 - accuracy: 0.7721 - auc: 0.8258 - precision_15: 0.7721 - recall_15: 0.7721 - val_loss: 0.5585 - val_accuracy: 0.7301 - val_auc: 0.8010 - val_precision_15: 0.7301 - val_recall_15: 0.7301 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5513 - accuracy: 0.7717 - auc: 0.8265 - precision_15: 0.7717 - recall_15: 0.7717 - val_loss: 0.5415 - val_accuracy: 0.7785 - val_auc: 0.8361 - val_precision_15: 0.7785 - val_recall_15: 0.7785 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.8240 - accuracy: 0.7880 - auc: 0.8385 - precision_15: 0.7880 - recall_15: 0.7880 - val_loss: 0.4565 - val_accuracy: 0.8529 - val_auc: 0.8985 - val_precision_15: 0.8529 - val_recall_15: 0.8529 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4731 - accuracy: 0.7798 - auc: 0.8579 - precision_15: 0.7798 - recall_15: 0.7798 - val_loss: 0.4537 - val_accuracy: 0.8512 - val_auc: 0.8918 - val_precision_15: 0.8512 - val_recall_15: 0.8512 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4535 - accuracy: 0.8062 - auc: 0.8705 - precision_15: 0.8062 - recall_15: 0.8062 - val_loss: 0.3847 - val_accuracy: 0.8581 - val_auc: 0.9216 - val_precision_15: 0.8581 - val_recall_15: 0.8581 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4492 - accuracy: 0.8058 - auc: 0.8712 - precision_15: 0.8058 - recall_15: 0.8058 - val_loss: 0.3861 - val_accuracy: 0.8495 - val_auc: 0.9125 - val_precision_15: 0.8495 - val_recall_15: 0.8495 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.8920 - accuracy: 0.7650 - auc: 0.8144 - precision_15: 0.7650 - recall_15: 0.7650 - val_loss: 0.5525 - val_accuracy: 0.7976 - val_auc: 0.8387 - val_precision_15: 0.7976 - val_recall_15: 0.7976 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.7255 - accuracy: 0.7665 - auc: 0.8203 - precision_15: 0.7665 - recall_15: 0.7665 - val_loss: 0.4666 - val_accuracy: 0.7993 - val_auc: 0.8683 - val_precision_15: 0.7993 - val_recall_15: 0.7993 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5496 - accuracy: 0.7835 - auc: 0.8462 - precision_15: 0.7835 - recall_15: 0.7835 - val_loss: 0.4599 - val_accuracy: 0.7803 - val_auc: 0.8695 - val_precision_15: 0.7803 - val_recall_15: 0.7803 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4444 - accuracy: 0.8080 - auc: 0.8751 - precision_15: 0.8080 - recall_15: 0.8080 - val_loss: 0.3652 - val_accuracy: 0.8426 - val_auc: 0.9169 - val_precision_15: 0.8426 - val_recall_15: 0.8426 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4144 - accuracy: 0.8173 - auc: 0.8931 - precision_15: 0.8173 - recall_15: 0.8173 - val_loss: 0.3809 - val_accuracy: 0.8737 - val_auc: 0.9117 - val_precision_15: 0.8737 - val_recall_15: 0.8737 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3983 - accuracy: 0.8180 - auc: 0.9000 - precision_15: 0.8180 - recall_15: 0.8180 - val_loss: 0.6905 - val_accuracy: 0.6436 - val_auc: 0.7282 - val_precision_15: 0.6436 - val_recall_15: 0.6436 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3752 - accuracy: 0.8314 - auc: 0.9148 - precision_15: 0.8314 - recall_15: 0.8314 - val_loss: 0.4221 - val_accuracy: 0.8547 - val_auc: 0.9177 - val_precision_15: 0.8547 - val_recall_15: 0.8547 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3313 - accuracy: 0.8617 - auc: 0.9340 - precision_15: 0.8617 - recall_15: 0.8617 - val_loss: 0.8070 - val_accuracy: 0.6176 - val_auc: 0.7037 - val_precision_15: 0.6176 - val_recall_15: 0.6176 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3139 - accuracy: 0.8666 - auc: 0.9403 - precision_15: 0.8666 - recall_15: 0.8666 - val_loss: 0.5424 - val_accuracy: 0.7561 - val_auc: 0.8510 - val_precision_15: 0.7561 - val_recall_15: 0.7561 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2904 - accuracy: 0.8873 - auc: 0.9491 - precision_15: 0.8873 - recall_15: 0.8873 - val_loss: 0.2499 - val_accuracy: 0.9031 - val_auc: 0.9664 - val_precision_15: 0.9031 - val_recall_15: 0.9031 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2890 - accuracy: 0.8847 - auc: 0.9503 - precision_15: 0.8847 - recall_15: 0.8847 - val_loss: 0.2674 - val_accuracy: 0.8858 - val_auc: 0.9582 - val_precision_15: 0.8858 - val_recall_15: 0.8858 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2509 - accuracy: 0.8996 - auc: 0.9620 - precision_15: 0.8996 - recall_15: 0.8996 - val_loss: 0.2851 - val_accuracy: 0.8841 - val_auc: 0.9551 - val_precision_15: 0.8841 - val_recall_15: 0.8841 - lr: 0.0050\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2487 - accuracy: 0.9062 - auc: 0.9637 - precision_15: 0.9062 - recall_15: 0.9062 - val_loss: 0.2578 - val_accuracy: 0.8927 - val_auc: 0.9637 - val_precision_15: 0.8927 - val_recall_15: 0.8927 - lr: 0.0050\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2376 - accuracy: 0.9047 - auc: 0.9665 - precision_15: 0.9047 - recall_15: 0.9047 - val_loss: 0.4616 - val_accuracy: 0.8391 - val_auc: 0.8878 - val_precision_15: 0.8391 - val_recall_15: 0.8391 - lr: 0.0050\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2624 - accuracy: 0.8918 - auc: 0.9587 - precision_15: 0.8918 - recall_15: 0.8918 - val_loss: 0.5332 - val_accuracy: 0.8045 - val_auc: 0.8905 - val_precision_15: 0.8045 - val_recall_15: 0.8045 - lr: 0.0050\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2274 - accuracy: 0.9085 - auc: 0.9698 - precision_15: 0.9085 - recall_15: 0.9085 - val_loss: 0.6392 - val_accuracy: 0.7785 - val_auc: 0.8647 - val_precision_15: 0.7785 - val_recall_15: 0.7785 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2203 - accuracy: 0.9114 - auc: 0.9706 - precision_15: 0.9114 - recall_15: 0.9114 - val_loss: 0.3707 - val_accuracy: 0.8443 - val_auc: 0.9324 - val_precision_15: 0.8443 - val_recall_15: 0.8443 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2430 - accuracy: 0.9040 - auc: 0.9649 - precision_15: 0.9040 - recall_15: 0.9040 - val_loss: 0.5026 - val_accuracy: 0.7249 - val_auc: 0.8471 - val_precision_15: 0.7249 - val_recall_15: 0.7249 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2663 - accuracy: 0.8925 - auc: 0.9573 - precision_15: 0.8925 - recall_15: 0.8925 - val_loss: 0.3857 - val_accuracy: 0.8235 - val_auc: 0.9176 - val_precision_15: 0.8235 - val_recall_15: 0.8235 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2461 - accuracy: 0.8996 - auc: 0.9654 - precision_15: 0.8996 - recall_15: 0.8996 - val_loss: 0.3734 - val_accuracy: 0.8737 - val_auc: 0.9286 - val_precision_15: 0.8737 - val_recall_15: 0.8737 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2694 - accuracy: 0.9262 - auc: 0.9709 - precision_15: 0.9262 - recall_15: 0.9262 - val_loss: 0.5118 - val_accuracy: 0.8564 - val_auc: 0.9150 - val_precision_15: 0.8564 - val_recall_15: 0.8564 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1768 - accuracy: 0.9333 - auc: 0.9810 - precision_15: 0.9333 - recall_15: 0.9333 - val_loss: 0.1735 - val_accuracy: 0.9325 - val_auc: 0.9817 - val_precision_15: 0.9325 - val_recall_15: 0.9325 - lr: 0.0025\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1591 - accuracy: 0.9433 - auc: 0.9851 - precision_15: 0.9433 - recall_15: 0.9433 - val_loss: 0.2040 - val_accuracy: 0.9221 - val_auc: 0.9806 - val_precision_15: 0.9221 - val_recall_15: 0.9221 - lr: 0.0025\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1499 - accuracy: 0.9418 - auc: 0.9862 - precision_15: 0.9418 - recall_15: 0.9418 - val_loss: 0.1272 - val_accuracy: 0.9516 - val_auc: 0.9900 - val_precision_15: 0.9516 - val_recall_15: 0.9516 - lr: 0.0025\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1741 - accuracy: 0.9403 - auc: 0.9804 - precision_15: 0.9403 - recall_15: 0.9403 - val_loss: 0.1702 - val_accuracy: 0.9256 - val_auc: 0.9837 - val_precision_15: 0.9256 - val_recall_15: 0.9256 - lr: 0.0025\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1485 - accuracy: 0.9477 - auc: 0.9854 - precision_15: 0.9477 - recall_15: 0.9477 - val_loss: 0.1430 - val_accuracy: 0.9464 - val_auc: 0.9885 - val_precision_15: 0.9464 - val_recall_15: 0.9464 - lr: 0.0025\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1653 - accuracy: 0.9422 - auc: 0.9831 - precision_15: 0.9422 - recall_15: 0.9422 - val_loss: 0.2171 - val_accuracy: 0.9083 - val_auc: 0.9709 - val_precision_15: 0.9083 - val_recall_15: 0.9083 - lr: 0.0025\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1476 - accuracy: 0.9466 - auc: 0.9860 - precision_15: 0.9466 - recall_15: 0.9466 - val_loss: 0.1509 - val_accuracy: 0.9360 - val_auc: 0.9859 - val_precision_15: 0.9360 - val_recall_15: 0.9360 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1413 - accuracy: 0.9489 - auc: 0.9880 - precision_15: 0.9489 - recall_15: 0.9489 - val_loss: 1.4903 - val_accuracy: 0.6211 - val_auc: 0.7385 - val_precision_15: 0.6211 - val_recall_15: 0.6211 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1383 - accuracy: 0.9470 - auc: 0.9880 - precision_15: 0.9470 - recall_15: 0.9470 - val_loss: 0.1327 - val_accuracy: 0.9498 - val_auc: 0.9893 - val_precision_15: 0.9498 - val_recall_15: 0.9498 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1549 - accuracy: 0.9396 - auc: 0.9850 - precision_15: 0.9396 - recall_15: 0.9396 - val_loss: 0.1560 - val_accuracy: 0.9481 - val_auc: 0.9845 - val_precision_15: 0.9481 - val_recall_15: 0.9481 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1364 - accuracy: 0.9496 - auc: 0.9881 - precision_15: 0.9496 - recall_15: 0.9496 - val_loss: 0.2581 - val_accuracy: 0.9239 - val_auc: 0.9747 - val_precision_15: 0.9239 - val_recall_15: 0.9239 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1601 - accuracy: 0.9396 - auc: 0.9840 - precision_15: 0.9396 - recall_15: 0.9396 - val_loss: 0.2981 - val_accuracy: 0.9204 - val_auc: 0.9632 - val_precision_15: 0.9204 - val_recall_15: 0.9204 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1571 - accuracy: 0.9414 - auc: 0.9844 - precision_15: 0.9414 - recall_15: 0.9414 - val_loss: 0.3303 - val_accuracy: 0.8478 - val_auc: 0.9379 - val_precision_15: 0.8478 - val_recall_15: 0.8478 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1472 - accuracy: 0.9474 - auc: 0.9864 - precision_15: 0.9474 - recall_15: 0.9474 - val_loss: 0.1268 - val_accuracy: 0.9516 - val_auc: 0.9886 - val_precision_15: 0.9516 - val_recall_15: 0.9516 - lr: 0.0025\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1131 - accuracy: 0.9581 - auc: 0.9916 - precision_15: 0.9581 - recall_15: 0.9581 - val_loss: 0.1233 - val_accuracy: 0.9654 - val_auc: 0.9893 - val_precision_15: 0.9654 - val_recall_15: 0.9654 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1107 - accuracy: 0.9596 - auc: 0.9924 - precision_15: 0.9596 - recall_15: 0.9596 - val_loss: 0.2997 - val_accuracy: 0.9100 - val_auc: 0.9643 - val_precision_15: 0.9100 - val_recall_15: 0.9100 - lr: 0.0012\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1243 - accuracy: 0.9559 - auc: 0.9905 - precision_15: 0.9559 - recall_15: 0.9559 - val_loss: 0.2669 - val_accuracy: 0.9118 - val_auc: 0.9631 - val_precision_15: 0.9118 - val_recall_15: 0.9118 - lr: 0.0012\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1131 - accuracy: 0.9622 - auc: 0.9919 - precision_15: 0.9622 - recall_15: 0.9622 - val_loss: 0.1197 - val_accuracy: 0.9533 - val_auc: 0.9901 - val_precision_15: 0.9533 - val_recall_15: 0.9533 - lr: 0.0012\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1182 - accuracy: 0.9589 - auc: 0.9907 - precision_15: 0.9589 - recall_15: 0.9589 - val_loss: 0.1673 - val_accuracy: 0.9377 - val_auc: 0.9833 - val_precision_15: 0.9377 - val_recall_15: 0.9377 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1095 - accuracy: 0.9574 - auc: 0.9923 - precision_15: 0.9574 - recall_15: 0.9574 - val_loss: 0.1269 - val_accuracy: 0.9550 - val_auc: 0.9890 - val_precision_15: 0.9550 - val_recall_15: 0.9550 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0966 - accuracy: 0.9637 - auc: 0.9940 - precision_15: 0.9637 - recall_15: 0.9637 - val_loss: 0.1791 - val_accuracy: 0.9343 - val_auc: 0.9845 - val_precision_15: 0.9343 - val_recall_15: 0.9343 - lr: 6.2500e-04\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1035 - accuracy: 0.9603 - auc: 0.9926 - precision_15: 0.9603 - recall_15: 0.9603 - val_loss: 0.2930 - val_accuracy: 0.9031 - val_auc: 0.9688 - val_precision_15: 0.9031 - val_recall_15: 0.9031 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0909 - accuracy: 0.9648 - auc: 0.9947 - precision_15: 0.9648 - recall_15: 0.9648 - val_loss: 0.1229 - val_accuracy: 0.9602 - val_auc: 0.9909 - val_precision_15: 0.9602 - val_recall_15: 0.9602 - lr: 6.2500e-04\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0928 - accuracy: 0.9633 - auc: 0.9945 - precision_15: 0.9633 - recall_15: 0.9633 - val_loss: 0.1500 - val_accuracy: 0.9498 - val_auc: 0.9881 - val_precision_15: 0.9498 - val_recall_15: 0.9498 - lr: 6.2500e-04\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0877 - accuracy: 0.9670 - auc: 0.9950 - precision_15: 0.9670 - recall_15: 0.9670 - val_loss: 0.2438 - val_accuracy: 0.9308 - val_auc: 0.9706 - val_precision_15: 0.9308 - val_recall_15: 0.9308 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0897 - accuracy: 0.9666 - auc: 0.9950 - precision_15: 0.9666 - recall_15: 0.9666 - val_loss: 0.1719 - val_accuracy: 0.9412 - val_auc: 0.9864 - val_precision_15: 0.9412 - val_recall_15: 0.9412 - lr: 6.2500e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0927 - accuracy: 0.9644 - auc: 0.9939 - precision_15: 0.9644 - recall_15: 0.9644 - val_loss: 0.1478 - val_accuracy: 0.9429 - val_auc: 0.9873 - val_precision_15: 0.9429 - val_recall_15: 0.9429 - lr: 6.2500e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0919 - accuracy: 0.9674 - auc: 0.9939 - precision_15: 0.9674 - recall_15: 0.9674 - val_loss: 0.1124 - val_accuracy: 0.9637 - val_auc: 0.9913 - val_precision_15: 0.9637 - val_recall_15: 0.9637 - lr: 6.2500e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0876 - accuracy: 0.9663 - auc: 0.9950 - precision_15: 0.9663 - recall_15: 0.9663 - val_loss: 0.1295 - val_accuracy: 0.9602 - val_auc: 0.9874 - val_precision_15: 0.9602 - val_recall_15: 0.9602 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0801 - accuracy: 0.9692 - auc: 0.9957 - precision_15: 0.9692 - recall_15: 0.9692 - val_loss: 0.1290 - val_accuracy: 0.9567 - val_auc: 0.9897 - val_precision_15: 0.9567 - val_recall_15: 0.9567 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0786 - accuracy: 0.9692 - auc: 0.9957 - precision_15: 0.9692 - recall_15: 0.9692 - val_loss: 0.1301 - val_accuracy: 0.9516 - val_auc: 0.9900 - val_precision_15: 0.9516 - val_recall_15: 0.9516 - lr: 3.1250e-04\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0790 - accuracy: 0.9685 - auc: 0.9957 - precision_15: 0.9685 - recall_15: 0.9685 - val_loss: 0.1791 - val_accuracy: 0.9412 - val_auc: 0.9850 - val_precision_15: 0.9412 - val_recall_15: 0.9412 - lr: 3.1250e-04\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0793 - accuracy: 0.9726 - auc: 0.9954 - precision_15: 0.9726 - recall_15: 0.9726 - val_loss: 0.1195 - val_accuracy: 0.9619 - val_auc: 0.9914 - val_precision_15: 0.9619 - val_recall_15: 0.9619 - lr: 3.1250e-04\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0781 - accuracy: 0.9729 - auc: 0.9951 - precision_15: 0.9729 - recall_15: 0.9729 - val_loss: 0.1658 - val_accuracy: 0.9481 - val_auc: 0.9850 - val_precision_15: 0.9481 - val_recall_15: 0.9481 - lr: 3.1250e-04\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0790 - accuracy: 0.9681 - auc: 0.9962 - precision_15: 0.9681 - recall_15: 0.9681 - val_loss: 0.1223 - val_accuracy: 0.9602 - val_auc: 0.9893 - val_precision_15: 0.9602 - val_recall_15: 0.9602 - lr: 3.1250e-04\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0804 - accuracy: 0.9729 - auc: 0.9949 - precision_15: 0.9729 - recall_15: 0.9729 - val_loss: 0.2040 - val_accuracy: 0.9394 - val_auc: 0.9811 - val_precision_15: 0.9394 - val_recall_15: 0.9394 - lr: 3.1250e-04\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0817 - accuracy: 0.9659 - auc: 0.9954 - precision_15: 0.9659 - recall_15: 0.9659 - val_loss: 0.1180 - val_accuracy: 0.9637 - val_auc: 0.9911 - val_precision_15: 0.9637 - val_recall_15: 0.9637 - lr: 3.1250e-04\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0685 - accuracy: 0.9722 - auc: 0.9970 - precision_15: 0.9722 - recall_15: 0.9722 - val_loss: 0.1593 - val_accuracy: 0.9481 - val_auc: 0.9860 - val_precision_15: 0.9481 - val_recall_15: 0.9481 - lr: 1.5625e-04\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0707 - accuracy: 0.9729 - auc: 0.9965 - precision_15: 0.9729 - recall_15: 0.9729 - val_loss: 0.1226 - val_accuracy: 0.9619 - val_auc: 0.9912 - val_precision_15: 0.9619 - val_recall_15: 0.9619 - lr: 1.5625e-04\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0632 - accuracy: 0.9759 - auc: 0.9974 - precision_15: 0.9759 - recall_15: 0.9759 - val_loss: 0.1435 - val_accuracy: 0.9550 - val_auc: 0.9872 - val_precision_15: 0.9550 - val_recall_15: 0.9550 - lr: 1.5625e-04\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0650 - accuracy: 0.9722 - auc: 0.9973 - precision_15: 0.9722 - recall_15: 0.9722 - val_loss: 0.1152 - val_accuracy: 0.9671 - val_auc: 0.9917 - val_precision_15: 0.9671 - val_recall_15: 0.9671 - lr: 1.5625e-04\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0667 - accuracy: 0.9741 - auc: 0.9969 - precision_15: 0.9741 - recall_15: 0.9741 - val_loss: 0.1195 - val_accuracy: 0.9654 - val_auc: 0.9911 - val_precision_15: 0.9654 - val_recall_15: 0.9654 - lr: 1.5625e-04\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0642 - accuracy: 0.9789 - auc: 0.9970 - precision_15: 0.9789 - recall_15: 0.9789 - val_loss: 0.1211 - val_accuracy: 0.9637 - val_auc: 0.9886 - val_precision_15: 0.9637 - val_recall_15: 0.9637 - lr: 1.5625e-04\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0622 - accuracy: 0.9722 - auc: 0.9977 - precision_15: 0.9722 - recall_15: 0.9722 - val_loss: 0.1166 - val_accuracy: 0.9671 - val_auc: 0.9906 - val_precision_15: 0.9671 - val_recall_15: 0.9671 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0659 - accuracy: 0.9766 - auc: 0.9971 - precision_15: 0.9766 - recall_15: 0.9766 - val_loss: 0.1213 - val_accuracy: 0.9671 - val_auc: 0.9904 - val_precision_15: 0.9671 - val_recall_15: 0.9671 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0665 - accuracy: 0.9766 - auc: 0.9969 - precision_15: 0.9766 - recall_15: 0.9766 - val_loss: 0.1424 - val_accuracy: 0.9637 - val_auc: 0.9875 - val_precision_15: 0.9637 - val_recall_15: 0.9637 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0643 - accuracy: 0.9763 - auc: 0.9970 - precision_15: 0.9763 - recall_15: 0.9763 - val_loss: 0.1211 - val_accuracy: 0.9671 - val_auc: 0.9886 - val_precision_15: 0.9671 - val_recall_15: 0.9671 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0658 - accuracy: 0.9722 - auc: 0.9971 - precision_15: 0.9722 - recall_15: 0.9722 - val_loss: 0.1429 - val_accuracy: 0.9567 - val_auc: 0.9888 - val_precision_15: 0.9567 - val_recall_15: 0.9567 - lr: 1.0000e-04\n",
      "5-fold cv train loss avg: 0.0339, train acc avg: 0.9859, val loss avg: 0.1776, val acc avg: 0.9529, test loss avg: 0.1910, test acc avg: 0.9551 \n",
      "             train auc avg: 0.9990, val auc avg: 0.9861, test auc avg: 0.9830 \n",
      "                 train precision avg: 0.9859, val precision avg: 0.9529, test precision avg: 0.9551 \n",
      "                     train recall avg: 0.9859, val recall avg: 0.9529, test recall avg: 0.9551\n"
     ]
    }
   ],
   "source": [
    "# perform k-fold cross validation\n",
    "kfold_training(X_stft_normalized, y, k_fold, train_size, val_size, test_size, base_model_cnn, base_file_name, base_csv_name, path, learning_rate, epochs, batch_size, num_dense_units, num_classes, kernel_size, max_pool_kernel, conv_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each patient in patients, do k-fold cross validation\n",
    "# patients = [\"a01r\", \"a02r\", \"a03r\", \"a04r\", \"b01r\", \"c02r\"]\n",
    "\n",
    "# for patient in patients:\n",
    "#     print(f\"Start training for patient {patient}\")\n",
    "#     X_stft = np.load(f\"stft_individual/{patient}_stft_features.npy\")\n",
    "#     y = np.load(f\"stft_individual/{patient}_labels.npy\")\n",
    "\n",
    "#     X_stft = process_data_for_conv2D(X_stft)\n",
    "#     print(X_stft.shape)\n",
    "#     print(y.shape)\n",
    "#     path = f\"weights/{patient}/\"\n",
    "#     if not os.path.exists(path):\n",
    "#         print(f\"Create directory {path}\")\n",
    "#         os.makedirs(path)\n",
    "#     kfold_training(X_stft, y, k_fold, train_size, val_size, test_size, base_model_cnn, base_file_name, base_csv_name, path, learning_rate, epochs, batch_size, num_dense_units, num_classes, kernel_size, max_pool_kernel, conv_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model \n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
