{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 04:48:14.940511: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-05 04:48:14.963034: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-05 04:48:14.963057: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-05 04:48:14.963073: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-05 04:48:14.967544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(X, y, train_size, val_size, test_size):\n",
    "    X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, train_size=train_size, stratify=y)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=test_size/(test_size+val_size), stratify=y_val_test)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "def process_data_for_conv2D(X):\n",
    "    X_conv2D = []\n",
    "    for sample in X:\n",
    "        sample = np.reshape(sample, newshape=(sample.shape[0], sample.shape[1], 1))\n",
    "        X_conv2D.append(sample)\n",
    "    return np.array(X_conv2D, dtype=np.float32)\n",
    "\n",
    "def data_iter(X, y, batch_size):\n",
    "    n_samples = X.shape[0]\n",
    "    idx = list(range(n_samples))\n",
    "    while True:\n",
    "        for i in range(0, n_samples, batch_size):\n",
    "            j = idx[i: min(i+batch_size, n_samples)]\n",
    "            yield X[j, :], y[j, : ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some blocks for NN\n",
    "\n",
    "def base_conv_block(n_conv_filters, kernel_size):\n",
    "    def f(input_):\n",
    "        x = tf.keras.layers.Conv2D(n_conv_filters, kernel_size, padding='same')(input_)\n",
    "\n",
    "\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation('relu')(x)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "def base_model_cnn(input_shape, num_conv_filters = [32, 64, 128], kernel_size = (2, 2), max_pool_kernel = (1, 3), num_dense_units=128, num_classes=2):\n",
    "    input_ = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = input_\n",
    "    for n_conv_filters in num_conv_filters:\n",
    "        x = base_conv_block(n_conv_filters, kernel_size)(x)\n",
    "        x = tf.keras.layers.MaxPooling2D(max_pool_kernel)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(num_dense_units, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3855, 188, 257, 1)\n",
      "(3855, 2)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "X_stft = np.load(\"stft/stft_features.npy\")\n",
    "y = np.load(\"stft/labels.npy\")\n",
    "\n",
    "# process data for conv2d\n",
    "X_stft = process_data_for_conv2D(X_stft)\n",
    "print(X_stft.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_size = (3, 3)\n",
    "max_pool_kernel = (1, 4)\n",
    "conv_filters = [32, 64, 128, 256]\n",
    "num_dense_units = 512\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# keep track of best model and log\n",
    "base_file_name = \"cnn_model.hdf5\"\n",
    "path = \"weights/\"\n",
    "base_csv_name = \"cnn_logs.csv\"\n",
    "\n",
    "# create directory if not exist\n",
    "if not os.path.exists(path):\n",
    "    print(f\"Create directory {path}\")\n",
    "    os.makedirs(path)\n",
    "\n",
    "train_loss_record = []\n",
    "train_acc_record = []\n",
    "val_loss_record = []\n",
    "val_acc_record = []\n",
    "test_loss_record = []\n",
    "test_acc_record = []\n",
    "\n",
    "# prepare for k-fold cross validation\n",
    "k_fold = 5\n",
    "\n",
    "\n",
    "def kfold_training(X, y, k_fold, train_size, val_size, test_size, base_model_cnn, base_file_name, base_csv_name, path, learning_rate, epochs, batch_size, num_dense_units, num_classes, kernel_size, max_pool_kernel, conv_filters):\n",
    "    train_loss_record = []\n",
    "    train_acc_record = []\n",
    "    val_loss_record = []\n",
    "    val_acc_record = []\n",
    "    test_loss_record = []\n",
    "    test_acc_record = []\n",
    "    train_auc_record = []\n",
    "    val_auc_record = []\n",
    "    test_auc_record = []\n",
    "    train_precision_record = []\n",
    "    val_precision_record = []\n",
    "    test_precision_record = []\n",
    "    train_recall_record = []\n",
    "    val_recall_record = []\n",
    "    test_recall_record = []\n",
    "    # train_f1_score_record = []\n",
    "    # val_f1_score_record = []\n",
    "    # test_f1_score_record = []\n",
    "    # train_specificity_record = []\n",
    "    # val_specificity_record = []\n",
    "    # test_specificity_record = []\n",
    "    \n",
    "    for i in range(k_fold):\n",
    "        print(f\"Start {i+1}th-fold in {k_fold} cross validation\")\n",
    "\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X_stft, y, train_size, val_size, test_size)\n",
    "\n",
    "        file_name = os.path.join(path, f\"{i}_fold_{base_file_name}\")\n",
    "        csv_path = os.path.join(path, f\"{i}_fold_{base_csv_name}\")\n",
    "\n",
    "\n",
    "        lr_change = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=3, min_lr=0.0001)\n",
    "\n",
    "        model_checkpoint = tf.keras.callbacks.ModelCheckpoint(file_name, monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", metric=\"val_acc\")\n",
    "\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.01, patience=10, mode=\"min\")\n",
    "\n",
    "        # csv logger\n",
    "        csv_logger = tf.keras.callbacks.CSVLogger(csv_path)\n",
    "\n",
    "        callbacks = [lr_change, model_checkpoint, early_stopping, csv_logger]\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "        model = base_model_cnn(input_shape=(X_train.shape[1], X_train.shape[2], X_train.shape[3]),\n",
    "                                num_dense_units=num_dense_units, num_classes=num_classes,\n",
    "                                kernel_size=kernel_size, max_pool_kernel=max_pool_kernel, \n",
    "                                num_conv_filters=conv_filters)\n",
    "        \n",
    "        # monitor specificity, sensitivity, f1 score\n",
    "        model.compile(loss = \"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\", \"AUC\", tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        \n",
    "        model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs,\n",
    "                validation_data=(X_val, y_val), callbacks=callbacks,\n",
    "                verbose=1)\n",
    "        \n",
    "        # train_loss, train_acc, train_auc, train_precision, train_recall, train_f1_score, train_specificity = model.evaluate(X_train, y_train, verbose=0)\n",
    "        # val_loss, val_acc, val_auc, val_precision, val_recall, val_f1_score, val_specificity = model.evaluate(X_val, y_val, verbose=0)\n",
    "        # test_loss, test_acc, test_auc, test_precision, test_recall, test_f1_score, test_specificity = model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        train_loss, train_acc, train_auc, train_precision, train_recall = model.evaluate(X_train, y_train, verbose=0)\n",
    "        val_loss, val_acc, val_auc, val_precision, val_recall = model.evaluate(X_val, y_val, verbose=0)\n",
    "        test_loss, test_acc, test_auc, test_precision, test_recall= model.evaluate(X_test, y_test, verbose=0)\n",
    "        \n",
    "        \n",
    "        train_loss_record.append(train_loss)\n",
    "        train_acc_record.append(train_acc)\n",
    "        val_loss_record.append(val_loss)\n",
    "        val_acc_record.append(val_acc)\n",
    "        test_loss_record.append(test_loss)\n",
    "        test_acc_record.append(test_acc)\n",
    "        train_auc_record.append(train_auc)\n",
    "        val_auc_record.append(val_auc)\n",
    "        test_auc_record.append(test_auc)\n",
    "        train_precision_record.append(train_precision)\n",
    "        val_precision_record.append(val_precision)\n",
    "        test_precision_record.append(test_precision)\n",
    "        train_recall_record.append(train_recall)\n",
    "        val_recall_record.append(val_recall)\n",
    "        test_recall_record.append(test_recall)\n",
    "        # train_f1_score_record.append(train_f1_score)\n",
    "        # val_f1_score_record.append(val_f1_score)\n",
    "        # test_f1_score_record.append(test_f1_score)\n",
    "        # train_specificity_record.append(train_specificity)\n",
    "        # val_specificity_record.append(val_specificity)\n",
    "        # test_specificity_record.append(test_specificity)\n",
    "        \n",
    "\n",
    "    train_loss_avg = np.mean(train_loss_record)\n",
    "    train_acc_avg = np.mean(train_acc_record)\n",
    "    val_loss_avg = np.mean(val_loss_record)\n",
    "    val_acc_avg = np.mean(val_acc_record)\n",
    "    test_loss_avg = np.mean(test_loss_record)\n",
    "    test_acc_avg = np.mean(test_acc_record)\n",
    "    train_auc_avg = np.mean(train_auc_record)\n",
    "    val_auc_avg = np.mean(val_auc_record)\n",
    "    test_auc_avg = np.mean(test_auc_record)\n",
    "    train_precision_avg = np.mean(train_precision_record)\n",
    "    val_precision_avg = np.mean(val_precision_record)\n",
    "    test_precision_avg = np.mean(test_precision_record)\n",
    "    train_recall_avg = np.mean(train_recall_record)\n",
    "    val_recall_avg = np.mean(val_recall_record)\n",
    "    test_recall_avg = np.mean(test_recall_record)\n",
    "    # train_f1_score_avg = np.mean(train_f1_score_record)\n",
    "    # val_f1_score_avg = np.mean(val_f1_score_record)\n",
    "    # test_f1_score_avg = np.mean(test_f1_score_record)\n",
    "    # train_specificity_avg = np.mean(train_specificity_record)\n",
    "    # val_specificity_avg = np.mean(val_specificity_record)\n",
    "    # test_specificity_avg = np.mean(test_specificity_record)\n",
    "    \n",
    "\n",
    "    print(f\"{k_fold}-fold cv train loss avg: {train_loss_avg:.4f}, train acc avg: {train_acc_avg:.4f}, val loss avg: {val_loss_avg:.4f}, val acc avg: {val_acc_avg:.4f}, test loss avg: {test_loss_avg:.4f}, test acc avg: {test_acc_avg:.4f} \\n \\\n",
    "            train auc avg: {train_auc_avg:.4f}, val auc avg: {val_auc_avg:.4f}, test auc avg: {test_auc_avg:.4f} \\n \\\n",
    "                train precision avg: {train_precision_avg:.4f}, val precision avg: {val_precision_avg:.4f}, test precision avg: {test_precision_avg:.4f} \\n \\\n",
    "                    train recall avg: {train_recall_avg:.4f}, val recall avg: {val_recall_avg:.4f}, test recall avg: {test_recall_avg:.4f}\")\n",
    "                        # train f1 score avg: {train_f1_score_avg:.4f}, val f1 score avg: {val_f1_score_avg:.4f}, test f1 score avg: {test_f1_score_avg:.4f} \\n \\\n",
    "                        #     train specificity avg: {train_specificity_avg:.4f}, val specificity avg: {val_specificity_avg:.4f}, test specificity avg: {test_specificity_avg:.4f}\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 1th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 95.9891 - accuracy: 0.6464 - auc: 0.6629 - precision_6: 0.6464 - recall_6: 0.6464"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 31ms/step - loss: 95.9891 - accuracy: 0.6464 - auc: 0.6629 - precision_6: 0.6464 - recall_6: 0.6464 - val_loss: 16.1820 - val_accuracy: 0.5969 - val_auc: 0.5969 - val_precision_6: 0.5969 - val_recall_6: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.6642 - accuracy: 0.7380 - auc: 0.7964 - precision_6: 0.7380 - recall_6: 0.7380 - val_loss: 1.1581 - val_accuracy: 0.6228 - val_auc: 0.7419 - val_precision_6: 0.6228 - val_recall_6: 0.6228 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4868 - accuracy: 0.7861 - auc: 0.8535 - precision_6: 0.7861 - recall_6: 0.7861 - val_loss: 0.5695 - val_accuracy: 0.7388 - val_auc: 0.8277 - val_precision_6: 0.7388 - val_recall_6: 0.7388 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4551 - accuracy: 0.7987 - auc: 0.8726 - precision_6: 0.7987 - recall_6: 0.7987 - val_loss: 0.4419 - val_accuracy: 0.7889 - val_auc: 0.8783 - val_precision_6: 0.7889 - val_recall_6: 0.7889 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4021 - accuracy: 0.8195 - auc: 0.8994 - precision_6: 0.8195 - recall_6: 0.8195 - val_loss: 0.5099 - val_accuracy: 0.7664 - val_auc: 0.8332 - val_precision_6: 0.7664 - val_recall_6: 0.7664 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3765 - accuracy: 0.8377 - auc: 0.9112 - precision_6: 0.8377 - recall_6: 0.8377 - val_loss: 0.4121 - val_accuracy: 0.8564 - val_auc: 0.8966 - val_precision_6: 0.8564 - val_recall_6: 0.8564 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3408 - accuracy: 0.8495 - auc: 0.9278 - precision_6: 0.8495 - recall_6: 0.8495 - val_loss: 0.5629 - val_accuracy: 0.6903 - val_auc: 0.7665 - val_precision_6: 0.6903 - val_recall_6: 0.6903 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3415 - accuracy: 0.8562 - auc: 0.9283 - precision_6: 0.8562 - recall_6: 0.8562 - val_loss: 0.8103 - val_accuracy: 0.5848 - val_auc: 0.6451 - val_precision_6: 0.5848 - val_recall_6: 0.5848 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2878 - accuracy: 0.8821 - auc: 0.9490 - precision_6: 0.8821 - recall_6: 0.8821 - val_loss: 0.8033 - val_accuracy: 0.5969 - val_auc: 0.6223 - val_precision_6: 0.5969 - val_recall_6: 0.5969 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2632 - accuracy: 0.8910 - auc: 0.9571 - precision_6: 0.8910 - recall_6: 0.8910 - val_loss: 0.3633 - val_accuracy: 0.8495 - val_auc: 0.9209 - val_precision_6: 0.8495 - val_recall_6: 0.8495 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.4305 - accuracy: 0.8640 - auc: 0.9295 - precision_6: 0.8640 - recall_6: 0.8640 - val_loss: 0.3438 - val_accuracy: 0.8633 - val_auc: 0.9286 - val_precision_6: 0.8633 - val_recall_6: 0.8633 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5753 - accuracy: 0.8625 - auc: 0.9327 - precision_6: 0.8625 - recall_6: 0.8625 - val_loss: 0.5377 - val_accuracy: 0.7232 - val_auc: 0.8276 - val_precision_6: 0.7232 - val_recall_6: 0.7232 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2280 - accuracy: 0.9047 - auc: 0.9690 - precision_6: 0.9047 - recall_6: 0.9047 - val_loss: 0.2654 - val_accuracy: 0.8668 - val_auc: 0.9610 - val_precision_6: 0.8668 - val_recall_6: 0.8668 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3209 - accuracy: 0.8884 - auc: 0.9527 - precision_6: 0.8884 - recall_6: 0.8884 - val_loss: 1.3973 - val_accuracy: 0.4100 - val_auc: 0.4523 - val_precision_6: 0.4100 - val_recall_6: 0.4100 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2632 - accuracy: 0.8866 - auc: 0.9581 - precision_6: 0.8866 - recall_6: 0.8866 - val_loss: 1.8153 - val_accuracy: 0.4066 - val_auc: 0.4227 - val_precision_6: 0.4066 - val_recall_6: 0.4066 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1973 - accuracy: 0.9244 - auc: 0.9765 - precision_6: 0.9244 - recall_6: 0.9244 - val_loss: 0.2783 - val_accuracy: 0.8962 - val_auc: 0.9552 - val_precision_6: 0.8962 - val_recall_6: 0.8962 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1890 - accuracy: 0.9322 - auc: 0.9780 - precision_6: 0.9322 - recall_6: 0.9322 - val_loss: 0.1969 - val_accuracy: 0.9083 - val_auc: 0.9769 - val_precision_6: 0.9083 - val_recall_6: 0.9083 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1927 - accuracy: 0.9244 - auc: 0.9779 - precision_6: 0.9244 - recall_6: 0.9244 - val_loss: 0.2976 - val_accuracy: 0.9187 - val_auc: 0.9604 - val_precision_6: 0.9187 - val_recall_6: 0.9187 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2142 - accuracy: 0.9222 - auc: 0.9719 - precision_6: 0.9222 - recall_6: 0.9222 - val_loss: 0.9247 - val_accuracy: 0.5363 - val_auc: 0.6829 - val_precision_6: 0.5363 - val_recall_6: 0.5363 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1844 - accuracy: 0.9322 - auc: 0.9789 - precision_6: 0.9322 - recall_6: 0.9322 - val_loss: 0.9731 - val_accuracy: 0.6021 - val_auc: 0.7319 - val_precision_6: 0.6021 - val_recall_6: 0.6021 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1896 - accuracy: 0.9303 - auc: 0.9783 - precision_6: 0.9303 - recall_6: 0.9303 - val_loss: 0.2767 - val_accuracy: 0.9170 - val_auc: 0.9659 - val_precision_6: 0.9170 - val_recall_6: 0.9170 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1999 - accuracy: 0.9233 - auc: 0.9762 - precision_6: 0.9233 - recall_6: 0.9233 - val_loss: 1.0472 - val_accuracy: 0.4689 - val_auc: 0.6436 - val_precision_6: 0.4689 - val_recall_6: 0.4689 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1804 - accuracy: 0.9318 - auc: 0.9802 - precision_6: 0.9318 - recall_6: 0.9318 - val_loss: 0.2229 - val_accuracy: 0.9221 - val_auc: 0.9754 - val_precision_6: 0.9221 - val_recall_6: 0.9221 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1839 - accuracy: 0.9311 - auc: 0.9795 - precision_6: 0.9311 - recall_6: 0.9311 - val_loss: 0.2054 - val_accuracy: 0.9377 - val_auc: 0.9817 - val_precision_6: 0.9377 - val_recall_6: 0.9377 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2159 - accuracy: 0.9203 - auc: 0.9729 - precision_6: 0.9203 - recall_6: 0.9203 - val_loss: 0.3198 - val_accuracy: 0.9135 - val_auc: 0.9570 - val_precision_6: 0.9135 - val_recall_6: 0.9135 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2501 - accuracy: 0.9162 - auc: 0.9673 - precision_6: 0.9162 - recall_6: 0.9162 - val_loss: 3.6339 - val_accuracy: 0.6592 - val_auc: 0.6915 - val_precision_6: 0.6592 - val_recall_6: 0.6592 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1792 - accuracy: 0.9248 - auc: 0.9802 - precision_6: 0.9248 - recall_6: 0.9248 - val_loss: 0.6806 - val_accuracy: 0.8651 - val_auc: 0.9160 - val_precision_6: 0.8651 - val_recall_6: 0.8651 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1541 - accuracy: 0.9418 - auc: 0.9853 - precision_6: 0.9418 - recall_6: 0.9418 - val_loss: 0.1824 - val_accuracy: 0.9343 - val_auc: 0.9862 - val_precision_6: 0.9343 - val_recall_6: 0.9343 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1404 - accuracy: 0.9448 - auc: 0.9880 - precision_6: 0.9448 - recall_6: 0.9448 - val_loss: 0.4851 - val_accuracy: 0.9100 - val_auc: 0.9392 - val_precision_6: 0.9100 - val_recall_6: 0.9100 - lr: 0.0050\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1677 - accuracy: 0.9362 - auc: 0.9834 - precision_6: 0.9362 - recall_6: 0.9362 - val_loss: 0.1759 - val_accuracy: 0.9429 - val_auc: 0.9852 - val_precision_6: 0.9429 - val_recall_6: 0.9429 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1410 - accuracy: 0.9481 - auc: 0.9869 - precision_6: 0.9481 - recall_6: 0.9481 - val_loss: 0.1978 - val_accuracy: 0.9377 - val_auc: 0.9814 - val_precision_6: 0.9377 - val_recall_6: 0.9377 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1384 - accuracy: 0.9477 - auc: 0.9879 - precision_6: 0.9477 - recall_6: 0.9477 - val_loss: 0.1911 - val_accuracy: 0.9325 - val_auc: 0.9827 - val_precision_6: 0.9325 - val_recall_6: 0.9325 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1480 - accuracy: 0.9477 - auc: 0.9869 - precision_6: 0.9477 - recall_6: 0.9477 - val_loss: 0.7233 - val_accuracy: 0.6661 - val_auc: 0.7892 - val_precision_6: 0.6661 - val_recall_6: 0.6661 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1359 - accuracy: 0.9451 - auc: 0.9885 - precision_6: 0.9451 - recall_6: 0.9451 - val_loss: 0.1979 - val_accuracy: 0.9308 - val_auc: 0.9804 - val_precision_6: 0.9308 - val_recall_6: 0.9308 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1707 - accuracy: 0.9377 - auc: 0.9823 - precision_6: 0.9377 - recall_6: 0.9377 - val_loss: 0.4329 - val_accuracy: 0.7941 - val_auc: 0.9047 - val_precision_6: 0.7941 - val_recall_6: 0.7941 - lr: 0.0050\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1577 - accuracy: 0.9359 - auc: 0.9857 - precision_6: 0.9359 - recall_6: 0.9359 - val_loss: 0.2155 - val_accuracy: 0.9187 - val_auc: 0.9733 - val_precision_6: 0.9187 - val_recall_6: 0.9187 - lr: 0.0050\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1487 - accuracy: 0.9466 - auc: 0.9860 - precision_6: 0.9466 - recall_6: 0.9466 - val_loss: 0.3968 - val_accuracy: 0.9291 - val_auc: 0.9639 - val_precision_6: 0.9291 - val_recall_6: 0.9291 - lr: 0.0050\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1290 - accuracy: 0.9552 - auc: 0.9893 - precision_6: 0.9552 - recall_6: 0.9552 - val_loss: 0.4030 - val_accuracy: 0.9187 - val_auc: 0.9574 - val_precision_6: 0.9187 - val_recall_6: 0.9187 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1159 - accuracy: 0.9537 - auc: 0.9918 - precision_6: 0.9537 - recall_6: 0.9537 - val_loss: 0.1682 - val_accuracy: 0.9429 - val_auc: 0.9873 - val_precision_6: 0.9429 - val_recall_6: 0.9429 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1107 - accuracy: 0.9592 - auc: 0.9918 - precision_6: 0.9592 - recall_6: 0.9592 - val_loss: 0.2834 - val_accuracy: 0.9308 - val_auc: 0.9718 - val_precision_6: 0.9308 - val_recall_6: 0.9308 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1109 - accuracy: 0.9555 - auc: 0.9921 - precision_6: 0.9555 - recall_6: 0.9555 - val_loss: 0.1934 - val_accuracy: 0.9343 - val_auc: 0.9850 - val_precision_6: 0.9343 - val_recall_6: 0.9343 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1029 - accuracy: 0.9585 - auc: 0.9930 - precision_6: 0.9585 - recall_6: 0.9585 - val_loss: 0.2613 - val_accuracy: 0.9100 - val_auc: 0.9727 - val_precision_6: 0.9100 - val_recall_6: 0.9100 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0974 - accuracy: 0.9640 - auc: 0.9934 - precision_6: 0.9640 - recall_6: 0.9640 - val_loss: 0.1650 - val_accuracy: 0.9481 - val_auc: 0.9899 - val_precision_6: 0.9481 - val_recall_6: 0.9481 - lr: 0.0025\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0934 - accuracy: 0.9629 - auc: 0.9940 - precision_6: 0.9629 - recall_6: 0.9629 - val_loss: 0.2352 - val_accuracy: 0.9221 - val_auc: 0.9749 - val_precision_6: 0.9221 - val_recall_6: 0.9221 - lr: 0.0025\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1096 - accuracy: 0.9585 - auc: 0.9923 - precision_6: 0.9585 - recall_6: 0.9585 - val_loss: 0.7147 - val_accuracy: 0.8685 - val_auc: 0.9216 - val_precision_6: 0.8685 - val_recall_6: 0.8685 - lr: 0.0025\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1003 - accuracy: 0.9596 - auc: 0.9934 - precision_6: 0.9596 - recall_6: 0.9596 - val_loss: 0.1548 - val_accuracy: 0.9481 - val_auc: 0.9888 - val_precision_6: 0.9481 - val_recall_6: 0.9481 - lr: 0.0025\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1153 - accuracy: 0.9566 - auc: 0.9911 - precision_6: 0.9566 - recall_6: 0.9566 - val_loss: 1.4100 - val_accuracy: 0.5813 - val_auc: 0.7084 - val_precision_6: 0.5813 - val_recall_6: 0.5813 - lr: 0.0025\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1023 - accuracy: 0.9596 - auc: 0.9932 - precision_6: 0.9596 - recall_6: 0.9596 - val_loss: 0.1665 - val_accuracy: 0.9394 - val_auc: 0.9867 - val_precision_6: 0.9394 - val_recall_6: 0.9394 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0782 - accuracy: 0.9666 - auc: 0.9963 - precision_6: 0.9666 - recall_6: 0.9666 - val_loss: 0.2366 - val_accuracy: 0.9412 - val_auc: 0.9800 - val_precision_6: 0.9412 - val_recall_6: 0.9412 - lr: 0.0012\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0755 - accuracy: 0.9696 - auc: 0.9963 - precision_6: 0.9696 - recall_6: 0.9696 - val_loss: 0.2007 - val_accuracy: 0.9412 - val_auc: 0.9819 - val_precision_6: 0.9412 - val_recall_6: 0.9412 - lr: 0.0012\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0796 - accuracy: 0.9689 - auc: 0.9956 - precision_6: 0.9689 - recall_6: 0.9689 - val_loss: 0.1649 - val_accuracy: 0.9429 - val_auc: 0.9873 - val_precision_6: 0.9429 - val_recall_6: 0.9429 - lr: 0.0012\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0830 - accuracy: 0.9689 - auc: 0.9955 - precision_6: 0.9689 - recall_6: 0.9689 - val_loss: 0.1890 - val_accuracy: 0.9429 - val_auc: 0.9859 - val_precision_6: 0.9429 - val_recall_6: 0.9429 - lr: 0.0012\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0805 - accuracy: 0.9666 - auc: 0.9959 - precision_6: 0.9666 - recall_6: 0.9666 - val_loss: 0.1957 - val_accuracy: 0.9412 - val_auc: 0.9827 - val_precision_6: 0.9412 - val_recall_6: 0.9412 - lr: 0.0012\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0679 - accuracy: 0.9741 - auc: 0.9970 - precision_6: 0.9741 - recall_6: 0.9741 - val_loss: 0.1832 - val_accuracy: 0.9516 - val_auc: 0.9851 - val_precision_6: 0.9516 - val_recall_6: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0708 - accuracy: 0.9722 - auc: 0.9962 - precision_6: 0.9722 - recall_6: 0.9722 - val_loss: 0.2812 - val_accuracy: 0.9343 - val_auc: 0.9741 - val_precision_6: 0.9343 - val_recall_6: 0.9343 - lr: 6.2500e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0681 - accuracy: 0.9729 - auc: 0.9964 - precision_6: 0.9729 - recall_6: 0.9729 - val_loss: 0.1807 - val_accuracy: 0.9516 - val_auc: 0.9886 - val_precision_6: 0.9516 - val_recall_6: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0657 - accuracy: 0.9741 - auc: 0.9971 - precision_6: 0.9741 - recall_6: 0.9741 - val_loss: 0.1542 - val_accuracy: 0.9550 - val_auc: 0.9887 - val_precision_6: 0.9550 - val_recall_6: 0.9550 - lr: 6.2500e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0633 - accuracy: 0.9744 - auc: 0.9971 - precision_6: 0.9744 - recall_6: 0.9744 - val_loss: 0.3001 - val_accuracy: 0.9308 - val_auc: 0.9757 - val_precision_6: 0.9308 - val_recall_6: 0.9308 - lr: 6.2500e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0612 - accuracy: 0.9770 - auc: 0.9972 - precision_6: 0.9770 - recall_6: 0.9770 - val_loss: 0.1784 - val_accuracy: 0.9464 - val_auc: 0.9879 - val_precision_6: 0.9464 - val_recall_6: 0.9464 - lr: 6.2500e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0582 - accuracy: 0.9778 - auc: 0.9978 - precision_6: 0.9778 - recall_6: 0.9778 - val_loss: 0.2167 - val_accuracy: 0.9567 - val_auc: 0.9814 - val_precision_6: 0.9567 - val_recall_6: 0.9567 - lr: 6.2500e-04\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0696 - accuracy: 0.9729 - auc: 0.9969 - precision_6: 0.9729 - recall_6: 0.9729 - val_loss: 0.1683 - val_accuracy: 0.9429 - val_auc: 0.9879 - val_precision_6: 0.9429 - val_recall_6: 0.9429 - lr: 6.2500e-04\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0607 - accuracy: 0.9752 - auc: 0.9978 - precision_6: 0.9752 - recall_6: 0.9752 - val_loss: 0.1958 - val_accuracy: 0.9481 - val_auc: 0.9875 - val_precision_6: 0.9481 - val_recall_6: 0.9481 - lr: 6.2500e-04\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0517 - accuracy: 0.9792 - auc: 0.9982 - precision_6: 0.9792 - recall_6: 0.9792 - val_loss: 0.2383 - val_accuracy: 0.9516 - val_auc: 0.9845 - val_precision_6: 0.9516 - val_recall_6: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0690 - accuracy: 0.9703 - auc: 0.9972 - precision_6: 0.9703 - recall_6: 0.9703 - val_loss: 0.1786 - val_accuracy: 0.9516 - val_auc: 0.9864 - val_precision_6: 0.9516 - val_recall_6: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0567 - accuracy: 0.9759 - auc: 0.9978 - precision_6: 0.9759 - recall_6: 0.9759 - val_loss: 0.2116 - val_accuracy: 0.9394 - val_auc: 0.9811 - val_precision_6: 0.9394 - val_recall_6: 0.9394 - lr: 6.2500e-04\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0596 - accuracy: 0.9748 - auc: 0.9976 - precision_6: 0.9748 - recall_6: 0.9748 - val_loss: 0.2076 - val_accuracy: 0.9412 - val_auc: 0.9831 - val_precision_6: 0.9412 - val_recall_6: 0.9412 - lr: 6.2500e-04\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0510 - accuracy: 0.9792 - auc: 0.9984 - precision_6: 0.9792 - recall_6: 0.9792 - val_loss: 0.1927 - val_accuracy: 0.9550 - val_auc: 0.9847 - val_precision_6: 0.9550 - val_recall_6: 0.9550 - lr: 3.1250e-04\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0495 - accuracy: 0.9844 - auc: 0.9980 - precision_6: 0.9844 - recall_6: 0.9844 - val_loss: 0.3146 - val_accuracy: 0.9187 - val_auc: 0.9737 - val_precision_6: 0.9187 - val_recall_6: 0.9187 - lr: 3.1250e-04\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0375 - accuracy: 0.9859 - auc: 0.9992 - precision_6: 0.9859 - recall_6: 0.9859 - val_loss: 0.2106 - val_accuracy: 0.9481 - val_auc: 0.9833 - val_precision_6: 0.9481 - val_recall_6: 0.9481 - lr: 3.1250e-04\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0546 - accuracy: 0.9789 - auc: 0.9973 - precision_6: 0.9789 - recall_6: 0.9789 - val_loss: 0.1804 - val_accuracy: 0.9567 - val_auc: 0.9859 - val_precision_6: 0.9567 - val_recall_6: 0.9567 - lr: 3.1250e-04\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0447 - accuracy: 0.9815 - auc: 0.9983 - precision_6: 0.9815 - recall_6: 0.9815 - val_loss: 0.2141 - val_accuracy: 0.9464 - val_auc: 0.9815 - val_precision_6: 0.9464 - val_recall_6: 0.9464 - lr: 3.1250e-04\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0502 - accuracy: 0.9826 - auc: 0.9979 - precision_6: 0.9826 - recall_6: 0.9826 - val_loss: 0.1721 - val_accuracy: 0.9498 - val_auc: 0.9870 - val_precision_6: 0.9498 - val_recall_6: 0.9498 - lr: 3.1250e-04\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0405 - accuracy: 0.9837 - auc: 0.9991 - precision_6: 0.9837 - recall_6: 0.9837 - val_loss: 0.2171 - val_accuracy: 0.9550 - val_auc: 0.9798 - val_precision_6: 0.9550 - val_recall_6: 0.9550 - lr: 1.5625e-04\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0330 - accuracy: 0.9889 - auc: 0.9990 - precision_6: 0.9889 - recall_6: 0.9889 - val_loss: 0.2116 - val_accuracy: 0.9550 - val_auc: 0.9803 - val_precision_6: 0.9550 - val_recall_6: 0.9550 - lr: 1.5625e-04\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0348 - accuracy: 0.9863 - auc: 0.9993 - precision_6: 0.9863 - recall_6: 0.9863 - val_loss: 0.2255 - val_accuracy: 0.9567 - val_auc: 0.9802 - val_precision_6: 0.9567 - val_recall_6: 0.9567 - lr: 1.5625e-04\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0365 - accuracy: 0.9833 - auc: 0.9992 - precision_6: 0.9833 - recall_6: 0.9833 - val_loss: 0.2335 - val_accuracy: 0.9533 - val_auc: 0.9817 - val_precision_6: 0.9533 - val_recall_6: 0.9533 - lr: 1.5625e-04\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0493 - accuracy: 0.9822 - auc: 0.9982 - precision_6: 0.9822 - recall_6: 0.9822 - val_loss: 0.2128 - val_accuracy: 0.9464 - val_auc: 0.9801 - val_precision_6: 0.9464 - val_recall_6: 0.9464 - lr: 1.5625e-04\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0387 - accuracy: 0.9859 - auc: 0.9991 - precision_6: 0.9859 - recall_6: 0.9859 - val_loss: 0.2081 - val_accuracy: 0.9619 - val_auc: 0.9834 - val_precision_6: 0.9619 - val_recall_6: 0.9619 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0372 - accuracy: 0.9870 - auc: 0.9988 - precision_6: 0.9870 - recall_6: 0.9870 - val_loss: 0.2078 - val_accuracy: 0.9637 - val_auc: 0.9819 - val_precision_6: 0.9637 - val_recall_6: 0.9637 - lr: 1.0000e-04\n",
      "Start 2th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 137.0212 - accuracy: 0.6053 - auc: 0.6159 - precision_7: 0.6053 - recall_7: 0.6053"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 31ms/step - loss: 137.0212 - accuracy: 0.6053 - auc: 0.6159 - precision_7: 0.6053 - recall_7: 0.6053 - val_loss: 488.3116 - val_accuracy: 0.5969 - val_auc: 0.5969 - val_precision_7: 0.5969 - val_recall_7: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 2.2287 - accuracy: 0.6564 - auc: 0.7051 - precision_7: 0.6564 - recall_7: 0.6564 - val_loss: 24.5672 - val_accuracy: 0.3962 - val_auc: 0.3230 - val_precision_7: 0.3962 - val_recall_7: 0.3962 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.8797 - accuracy: 0.6801 - auc: 0.7273 - precision_7: 0.6801 - recall_7: 0.6801 - val_loss: 13.0664 - val_accuracy: 0.4031 - val_auc: 0.4250 - val_precision_7: 0.4031 - val_recall_7: 0.4031 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.6490 - accuracy: 0.7457 - auc: 0.7882 - precision_7: 0.7457 - recall_7: 0.7457 - val_loss: 0.5721 - val_accuracy: 0.7388 - val_auc: 0.7836 - val_precision_7: 0.7388 - val_recall_7: 0.7388 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5250 - accuracy: 0.7635 - auc: 0.8188 - precision_7: 0.7635 - recall_7: 0.7635 - val_loss: 0.5020 - val_accuracy: 0.7716 - val_auc: 0.8352 - val_precision_7: 0.7716 - val_recall_7: 0.7716 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5276 - accuracy: 0.7795 - auc: 0.8337 - precision_7: 0.7795 - recall_7: 0.7795 - val_loss: 0.4660 - val_accuracy: 0.7803 - val_auc: 0.8678 - val_precision_7: 0.7803 - val_recall_7: 0.7803 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4754 - accuracy: 0.7891 - auc: 0.8538 - precision_7: 0.7891 - recall_7: 0.7891 - val_loss: 0.4523 - val_accuracy: 0.7941 - val_auc: 0.8743 - val_precision_7: 0.7941 - val_recall_7: 0.7941 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.4663 - accuracy: 0.7936 - auc: 0.8595 - precision_7: 0.7936 - recall_7: 0.7936 - val_loss: 0.4452 - val_accuracy: 0.8131 - val_auc: 0.8718 - val_precision_7: 0.8131 - val_recall_7: 0.8131 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4613 - accuracy: 0.7939 - auc: 0.8643 - precision_7: 0.7939 - recall_7: 0.7939 - val_loss: 0.4720 - val_accuracy: 0.7958 - val_auc: 0.8560 - val_precision_7: 0.7958 - val_recall_7: 0.7958 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.7615 - accuracy: 0.7954 - auc: 0.8554 - precision_7: 0.7954 - recall_7: 0.7954 - val_loss: 0.5535 - val_accuracy: 0.7543 - val_auc: 0.7945 - val_precision_7: 0.7543 - val_recall_7: 0.7543 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4406 - accuracy: 0.7995 - auc: 0.8772 - precision_7: 0.7995 - recall_7: 0.7995 - val_loss: 0.4806 - val_accuracy: 0.8080 - val_auc: 0.8687 - val_precision_7: 0.8080 - val_recall_7: 0.8080 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4104 - accuracy: 0.8136 - auc: 0.8919 - precision_7: 0.8136 - recall_7: 0.8136 - val_loss: 0.3940 - val_accuracy: 0.8235 - val_auc: 0.8986 - val_precision_7: 0.8235 - val_recall_7: 0.8235 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3551 - accuracy: 0.8425 - auc: 0.9208 - precision_7: 0.8425 - recall_7: 0.8425 - val_loss: 0.3371 - val_accuracy: 0.8616 - val_auc: 0.9351 - val_precision_7: 0.8616 - val_recall_7: 0.8616 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3435 - accuracy: 0.8447 - auc: 0.9260 - precision_7: 0.8447 - recall_7: 0.8447 - val_loss: 0.3626 - val_accuracy: 0.8218 - val_auc: 0.9190 - val_precision_7: 0.8218 - val_recall_7: 0.8218 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3189 - accuracy: 0.8592 - auc: 0.9349 - precision_7: 0.8592 - recall_7: 0.8592 - val_loss: 0.4254 - val_accuracy: 0.8028 - val_auc: 0.8834 - val_precision_7: 0.8028 - val_recall_7: 0.8028 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3053 - accuracy: 0.8677 - auc: 0.9420 - precision_7: 0.8677 - recall_7: 0.8677 - val_loss: 0.5555 - val_accuracy: 0.7405 - val_auc: 0.8264 - val_precision_7: 0.7405 - val_recall_7: 0.7405 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2945 - accuracy: 0.8773 - auc: 0.9475 - precision_7: 0.8773 - recall_7: 0.8773 - val_loss: 0.3234 - val_accuracy: 0.8512 - val_auc: 0.9372 - val_precision_7: 0.8512 - val_recall_7: 0.8512 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2747 - accuracy: 0.8821 - auc: 0.9539 - precision_7: 0.8821 - recall_7: 0.8821 - val_loss: 0.3261 - val_accuracy: 0.8478 - val_auc: 0.9379 - val_precision_7: 0.8478 - val_recall_7: 0.8478 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2625 - accuracy: 0.8844 - auc: 0.9575 - precision_7: 0.8844 - recall_7: 0.8844 - val_loss: 0.2717 - val_accuracy: 0.8910 - val_auc: 0.9586 - val_precision_7: 0.8910 - val_recall_7: 0.8910 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2348 - accuracy: 0.9051 - auc: 0.9668 - precision_7: 0.9051 - recall_7: 0.9051 - val_loss: 0.3000 - val_accuracy: 0.8806 - val_auc: 0.9502 - val_precision_7: 0.8806 - val_recall_7: 0.8806 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.2489 - accuracy: 0.8984 - auc: 0.9629 - precision_7: 0.8984 - recall_7: 0.8984 - val_loss: 0.2733 - val_accuracy: 0.8979 - val_auc: 0.9595 - val_precision_7: 0.8979 - val_recall_7: 0.8979 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2563 - accuracy: 0.8973 - auc: 0.9605 - precision_7: 0.8973 - recall_7: 0.8973 - val_loss: 0.4029 - val_accuracy: 0.8529 - val_auc: 0.9236 - val_precision_7: 0.8529 - val_recall_7: 0.8529 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2564 - accuracy: 0.9010 - auc: 0.9609 - precision_7: 0.9010 - recall_7: 0.9010 - val_loss: 0.7858 - val_accuracy: 0.7180 - val_auc: 0.8231 - val_precision_7: 0.7180 - val_recall_7: 0.7180 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.2059 - accuracy: 0.9207 - auc: 0.9739 - precision_7: 0.9207 - recall_7: 0.9207 - val_loss: 0.2262 - val_accuracy: 0.9031 - val_auc: 0.9675 - val_precision_7: 0.9031 - val_recall_7: 0.9031 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2208 - accuracy: 0.9122 - auc: 0.9710 - precision_7: 0.9122 - recall_7: 0.9122 - val_loss: 0.2455 - val_accuracy: 0.9031 - val_auc: 0.9680 - val_precision_7: 0.9031 - val_recall_7: 0.9031 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1823 - accuracy: 0.9311 - auc: 0.9793 - precision_7: 0.9311 - recall_7: 0.9311 - val_loss: 0.3699 - val_accuracy: 0.8702 - val_auc: 0.9420 - val_precision_7: 0.8702 - val_recall_7: 0.8702 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1878 - accuracy: 0.9255 - auc: 0.9784 - precision_7: 0.9255 - recall_7: 0.9255 - val_loss: 0.2015 - val_accuracy: 0.9187 - val_auc: 0.9752 - val_precision_7: 0.9187 - val_recall_7: 0.9187 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1768 - accuracy: 0.9355 - auc: 0.9804 - precision_7: 0.9355 - recall_7: 0.9355 - val_loss: 0.2435 - val_accuracy: 0.8997 - val_auc: 0.9636 - val_precision_7: 0.8997 - val_recall_7: 0.8997 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1892 - accuracy: 0.9274 - auc: 0.9778 - precision_7: 0.9274 - recall_7: 0.9274 - val_loss: 0.2093 - val_accuracy: 0.9273 - val_auc: 0.9731 - val_precision_7: 0.9273 - val_recall_7: 0.9273 - lr: 0.0050\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1755 - accuracy: 0.9362 - auc: 0.9804 - precision_7: 0.9362 - recall_7: 0.9362 - val_loss: 0.4064 - val_accuracy: 0.8374 - val_auc: 0.9381 - val_precision_7: 0.8374 - val_recall_7: 0.8374 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1745 - accuracy: 0.9337 - auc: 0.9805 - precision_7: 0.9337 - recall_7: 0.9337 - val_loss: 0.1813 - val_accuracy: 0.9273 - val_auc: 0.9806 - val_precision_7: 0.9273 - val_recall_7: 0.9273 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1708 - accuracy: 0.9355 - auc: 0.9817 - precision_7: 0.9355 - recall_7: 0.9355 - val_loss: 0.4562 - val_accuracy: 0.8253 - val_auc: 0.9180 - val_precision_7: 0.8253 - val_recall_7: 0.8253 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1603 - accuracy: 0.9374 - auc: 0.9841 - precision_7: 0.9374 - recall_7: 0.9374 - val_loss: 0.2499 - val_accuracy: 0.9135 - val_auc: 0.9642 - val_precision_7: 0.9135 - val_recall_7: 0.9135 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1702 - accuracy: 0.9385 - auc: 0.9817 - precision_7: 0.9385 - recall_7: 0.9385 - val_loss: 0.7513 - val_accuracy: 0.8045 - val_auc: 0.8774 - val_precision_7: 0.8045 - val_recall_7: 0.8045 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1641 - accuracy: 0.9422 - auc: 0.9826 - precision_7: 0.9422 - recall_7: 0.9422 - val_loss: 2.2064 - val_accuracy: 0.6401 - val_auc: 0.7234 - val_precision_7: 0.6401 - val_recall_7: 0.6401 - lr: 0.0050\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1466 - accuracy: 0.9448 - auc: 0.9866 - precision_7: 0.9448 - recall_7: 0.9448 - val_loss: 0.3004 - val_accuracy: 0.8512 - val_auc: 0.9483 - val_precision_7: 0.8512 - val_recall_7: 0.8512 - lr: 0.0050\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1431 - accuracy: 0.9459 - auc: 0.9871 - precision_7: 0.9459 - recall_7: 0.9459 - val_loss: 0.4966 - val_accuracy: 0.7889 - val_auc: 0.8997 - val_precision_7: 0.7889 - val_recall_7: 0.7889 - lr: 0.0050\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2303 - accuracy: 0.9392 - auc: 0.9759 - precision_7: 0.9392 - recall_7: 0.9392 - val_loss: 1.3620 - val_accuracy: 0.6453 - val_auc: 0.7459 - val_precision_7: 0.6453 - val_recall_7: 0.6453 - lr: 0.0050\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.2502 - accuracy: 0.9059 - auc: 0.9660 - precision_7: 0.9059 - recall_7: 0.9059 - val_loss: 0.2014 - val_accuracy: 0.9308 - val_auc: 0.9758 - val_precision_7: 0.9308 - val_recall_7: 0.9308 - lr: 0.0050\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1707 - accuracy: 0.9418 - auc: 0.9815 - precision_7: 0.9418 - recall_7: 0.9418 - val_loss: 0.2381 - val_accuracy: 0.9221 - val_auc: 0.9691 - val_precision_7: 0.9221 - val_recall_7: 0.9221 - lr: 0.0050\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1463 - accuracy: 0.9511 - auc: 0.9855 - precision_7: 0.9511 - recall_7: 0.9511 - val_loss: 0.1926 - val_accuracy: 0.9308 - val_auc: 0.9774 - val_precision_7: 0.9308 - val_recall_7: 0.9308 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1360 - accuracy: 0.9544 - auc: 0.9885 - precision_7: 0.9544 - recall_7: 0.9544 - val_loss: 0.1461 - val_accuracy: 0.9498 - val_auc: 0.9856 - val_precision_7: 0.9498 - val_recall_7: 0.9498 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1263 - accuracy: 0.9518 - auc: 0.9899 - precision_7: 0.9518 - recall_7: 0.9518 - val_loss: 0.1496 - val_accuracy: 0.9498 - val_auc: 0.9851 - val_precision_7: 0.9498 - val_recall_7: 0.9498 - lr: 0.0025\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1465 - accuracy: 0.9466 - auc: 0.9862 - precision_7: 0.9466 - recall_7: 0.9466 - val_loss: 0.1572 - val_accuracy: 0.9429 - val_auc: 0.9847 - val_precision_7: 0.9429 - val_recall_7: 0.9429 - lr: 0.0025\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1326 - accuracy: 0.9503 - auc: 0.9880 - precision_7: 0.9503 - recall_7: 0.9503 - val_loss: 0.1619 - val_accuracy: 0.9377 - val_auc: 0.9839 - val_precision_7: 0.9377 - val_recall_7: 0.9377 - lr: 0.0025\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1221 - accuracy: 0.9492 - auc: 0.9906 - precision_7: 0.9492 - recall_7: 0.9492 - val_loss: 0.3146 - val_accuracy: 0.9100 - val_auc: 0.9624 - val_precision_7: 0.9100 - val_recall_7: 0.9100 - lr: 0.0025\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1236 - accuracy: 0.9492 - auc: 0.9908 - precision_7: 0.9492 - recall_7: 0.9492 - val_loss: 0.3404 - val_accuracy: 0.8408 - val_auc: 0.9357 - val_precision_7: 0.8408 - val_recall_7: 0.8408 - lr: 0.0025\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1175 - accuracy: 0.9555 - auc: 0.9907 - precision_7: 0.9555 - recall_7: 0.9555 - val_loss: 0.4181 - val_accuracy: 0.8495 - val_auc: 0.9302 - val_precision_7: 0.8495 - val_recall_7: 0.8495 - lr: 0.0025\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1233 - accuracy: 0.9548 - auc: 0.9904 - precision_7: 0.9548 - recall_7: 0.9548 - val_loss: 0.1758 - val_accuracy: 0.9377 - val_auc: 0.9812 - val_precision_7: 0.9377 - val_recall_7: 0.9377 - lr: 0.0025\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1213 - accuracy: 0.9522 - auc: 0.9910 - precision_7: 0.9522 - recall_7: 0.9522 - val_loss: 0.2441 - val_accuracy: 0.9100 - val_auc: 0.9738 - val_precision_7: 0.9100 - val_recall_7: 0.9100 - lr: 0.0025\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1061 - accuracy: 0.9566 - auc: 0.9929 - precision_7: 0.9566 - recall_7: 0.9566 - val_loss: 0.1886 - val_accuracy: 0.9170 - val_auc: 0.9816 - val_precision_7: 0.9170 - val_recall_7: 0.9170 - lr: 0.0025\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1092 - accuracy: 0.9566 - auc: 0.9924 - precision_7: 0.9566 - recall_7: 0.9566 - val_loss: 0.1254 - val_accuracy: 0.9516 - val_auc: 0.9904 - val_precision_7: 0.9516 - val_recall_7: 0.9516 - lr: 0.0025\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1274 - accuracy: 0.9481 - auc: 0.9902 - precision_7: 0.9481 - recall_7: 0.9481 - val_loss: 0.1387 - val_accuracy: 0.9446 - val_auc: 0.9877 - val_precision_7: 0.9446 - val_recall_7: 0.9446 - lr: 0.0025\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1245 - accuracy: 0.9603 - auc: 0.9908 - precision_7: 0.9603 - recall_7: 0.9603 - val_loss: 0.1780 - val_accuracy: 0.9343 - val_auc: 0.9824 - val_precision_7: 0.9343 - val_recall_7: 0.9343 - lr: 0.0025\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1038 - accuracy: 0.9592 - auc: 0.9933 - precision_7: 0.9592 - recall_7: 0.9592 - val_loss: 0.1354 - val_accuracy: 0.9550 - val_auc: 0.9878 - val_precision_7: 0.9550 - val_recall_7: 0.9550 - lr: 0.0012\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0846 - accuracy: 0.9689 - auc: 0.9951 - precision_7: 0.9689 - recall_7: 0.9689 - val_loss: 0.1625 - val_accuracy: 0.9464 - val_auc: 0.9871 - val_precision_7: 0.9464 - val_recall_7: 0.9464 - lr: 0.0012\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0810 - accuracy: 0.9681 - auc: 0.9958 - precision_7: 0.9681 - recall_7: 0.9681 - val_loss: 0.1314 - val_accuracy: 0.9498 - val_auc: 0.9880 - val_precision_7: 0.9498 - val_recall_7: 0.9498 - lr: 0.0012\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0820 - accuracy: 0.9663 - auc: 0.9956 - precision_7: 0.9663 - recall_7: 0.9663 - val_loss: 0.1643 - val_accuracy: 0.9412 - val_auc: 0.9855 - val_precision_7: 0.9412 - val_recall_7: 0.9412 - lr: 0.0012\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0795 - accuracy: 0.9685 - auc: 0.9957 - precision_7: 0.9685 - recall_7: 0.9685 - val_loss: 0.1654 - val_accuracy: 0.9429 - val_auc: 0.9840 - val_precision_7: 0.9429 - val_recall_7: 0.9429 - lr: 0.0012\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0881 - accuracy: 0.9648 - auc: 0.9948 - precision_7: 0.9648 - recall_7: 0.9648 - val_loss: 0.1350 - val_accuracy: 0.9550 - val_auc: 0.9881 - val_precision_7: 0.9550 - val_recall_7: 0.9550 - lr: 0.0012\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0745 - accuracy: 0.9715 - auc: 0.9958 - precision_7: 0.9715 - recall_7: 0.9715 - val_loss: 0.1402 - val_accuracy: 0.9464 - val_auc: 0.9875 - val_precision_7: 0.9464 - val_recall_7: 0.9464 - lr: 0.0012\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0780 - accuracy: 0.9678 - auc: 0.9961 - precision_7: 0.9678 - recall_7: 0.9678 - val_loss: 0.1411 - val_accuracy: 0.9516 - val_auc: 0.9906 - val_precision_7: 0.9516 - val_recall_7: 0.9516 - lr: 0.0012\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0770 - accuracy: 0.9711 - auc: 0.9959 - precision_7: 0.9711 - recall_7: 0.9711 - val_loss: 0.1739 - val_accuracy: 0.9429 - val_auc: 0.9843 - val_precision_7: 0.9429 - val_recall_7: 0.9429 - lr: 0.0012\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0783 - accuracy: 0.9718 - auc: 0.9958 - precision_7: 0.9718 - recall_7: 0.9718 - val_loss: 0.2615 - val_accuracy: 0.9325 - val_auc: 0.9730 - val_precision_7: 0.9325 - val_recall_7: 0.9325 - lr: 0.0012\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0730 - accuracy: 0.9733 - auc: 0.9967 - precision_7: 0.9733 - recall_7: 0.9733 - val_loss: 0.1641 - val_accuracy: 0.9446 - val_auc: 0.9846 - val_precision_7: 0.9446 - val_recall_7: 0.9446 - lr: 6.2500e-04\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0612 - accuracy: 0.9766 - auc: 0.9973 - precision_7: 0.9766 - recall_7: 0.9766 - val_loss: 0.1400 - val_accuracy: 0.9516 - val_auc: 0.9884 - val_precision_7: 0.9516 - val_recall_7: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0619 - accuracy: 0.9737 - auc: 0.9974 - precision_7: 0.9737 - recall_7: 0.9737 - val_loss: 0.1442 - val_accuracy: 0.9533 - val_auc: 0.9883 - val_precision_7: 0.9533 - val_recall_7: 0.9533 - lr: 6.2500e-04\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0581 - accuracy: 0.9785 - auc: 0.9974 - precision_7: 0.9785 - recall_7: 0.9785 - val_loss: 0.1643 - val_accuracy: 0.9498 - val_auc: 0.9858 - val_precision_7: 0.9498 - val_recall_7: 0.9498 - lr: 6.2500e-04\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0579 - accuracy: 0.9785 - auc: 0.9979 - precision_7: 0.9785 - recall_7: 0.9785 - val_loss: 0.1811 - val_accuracy: 0.9464 - val_auc: 0.9826 - val_precision_7: 0.9464 - val_recall_7: 0.9464 - lr: 6.2500e-04\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0680 - accuracy: 0.9752 - auc: 0.9970 - precision_7: 0.9752 - recall_7: 0.9752 - val_loss: 0.1719 - val_accuracy: 0.9516 - val_auc: 0.9834 - val_precision_7: 0.9516 - val_recall_7: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0559 - accuracy: 0.9755 - auc: 0.9981 - precision_7: 0.9755 - recall_7: 0.9755 - val_loss: 0.1864 - val_accuracy: 0.9464 - val_auc: 0.9844 - val_precision_7: 0.9464 - val_recall_7: 0.9464 - lr: 6.2500e-04\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0690 - accuracy: 0.9711 - auc: 0.9971 - precision_7: 0.9711 - recall_7: 0.9711 - val_loss: 0.2678 - val_accuracy: 0.9100 - val_auc: 0.9724 - val_precision_7: 0.9100 - val_recall_7: 0.9100 - lr: 6.2500e-04\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0664 - accuracy: 0.9733 - auc: 0.9973 - precision_7: 0.9733 - recall_7: 0.9733 - val_loss: 0.1927 - val_accuracy: 0.9498 - val_auc: 0.9804 - val_precision_7: 0.9498 - val_recall_7: 0.9498 - lr: 6.2500e-04\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0596 - accuracy: 0.9789 - auc: 0.9976 - precision_7: 0.9789 - recall_7: 0.9789 - val_loss: 0.1652 - val_accuracy: 0.9533 - val_auc: 0.9860 - val_precision_7: 0.9533 - val_recall_7: 0.9533 - lr: 6.2500e-04\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0531 - accuracy: 0.9792 - auc: 0.9977 - precision_7: 0.9792 - recall_7: 0.9792 - val_loss: 0.1607 - val_accuracy: 0.9516 - val_auc: 0.9878 - val_precision_7: 0.9516 - val_recall_7: 0.9516 - lr: 3.1250e-04\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0596 - accuracy: 0.9755 - auc: 0.9976 - precision_7: 0.9755 - recall_7: 0.9755 - val_loss: 0.1673 - val_accuracy: 0.9498 - val_auc: 0.9850 - val_precision_7: 0.9498 - val_recall_7: 0.9498 - lr: 3.1250e-04\n",
      "Start 3th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 108.5598 - accuracy: 0.6030 - auc: 0.6262 - precision_8: 0.6030 - recall_8: 0.6030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 31ms/step - loss: 108.5598 - accuracy: 0.6030 - auc: 0.6262 - precision_8: 0.6030 - recall_8: 0.6030 - val_loss: 22.1194 - val_accuracy: 0.5969 - val_auc: 0.5969 - val_precision_8: 0.5969 - val_recall_8: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5978 - accuracy: 0.7235 - auc: 0.7734 - precision_8: 0.7235 - recall_8: 0.7235 - val_loss: 2.4415 - val_accuracy: 0.5952 - val_auc: 0.6868 - val_precision_8: 0.5952 - val_recall_8: 0.5952 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5996 - accuracy: 0.7806 - auc: 0.7986 - precision_8: 0.7806 - recall_8: 0.7806 - val_loss: 0.6875 - val_accuracy: 0.7284 - val_auc: 0.7905 - val_precision_8: 0.7284 - val_recall_8: 0.7284 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5444 - accuracy: 0.7872 - auc: 0.8112 - precision_8: 0.7872 - recall_8: 0.7872 - val_loss: 0.4966 - val_accuracy: 0.7976 - val_auc: 0.8349 - val_precision_8: 0.7976 - val_recall_8: 0.7976 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.7494 - accuracy: 0.7798 - auc: 0.8034 - precision_8: 0.7798 - recall_8: 0.7798 - val_loss: 0.5643 - val_accuracy: 0.8114 - val_auc: 0.8461 - val_precision_8: 0.8114 - val_recall_8: 0.8114 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.6332 - accuracy: 0.7802 - auc: 0.8242 - precision_8: 0.7802 - recall_8: 0.7802 - val_loss: 0.4424 - val_accuracy: 0.8062 - val_auc: 0.8928 - val_precision_8: 0.8062 - val_recall_8: 0.8062 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 1.1325 - accuracy: 0.7861 - auc: 0.8364 - precision_8: 0.7861 - recall_8: 0.7861 - val_loss: 0.4443 - val_accuracy: 0.8253 - val_auc: 0.8924 - val_precision_8: 0.8253 - val_recall_8: 0.8253 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5915 - accuracy: 0.8017 - auc: 0.8547 - precision_8: 0.8017 - recall_8: 0.8017 - val_loss: 0.4814 - val_accuracy: 0.8045 - val_auc: 0.8694 - val_precision_8: 0.8045 - val_recall_8: 0.8045 - lr: 0.0050\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.4090 - accuracy: 0.8351 - auc: 0.8990 - precision_8: 0.8351 - recall_8: 0.8351 - val_loss: 0.3597 - val_accuracy: 0.8547 - val_auc: 0.9180 - val_precision_8: 0.8547 - val_recall_8: 0.8547 - lr: 0.0050\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3808 - accuracy: 0.8428 - auc: 0.9098 - precision_8: 0.8428 - recall_8: 0.8428 - val_loss: 0.6817 - val_accuracy: 0.5657 - val_auc: 0.6717 - val_precision_8: 0.5657 - val_recall_8: 0.5657 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4532 - accuracy: 0.8643 - auc: 0.9313 - precision_8: 0.8643 - recall_8: 0.8643 - val_loss: 0.4268 - val_accuracy: 0.8218 - val_auc: 0.8846 - val_precision_8: 0.8218 - val_recall_8: 0.8218 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5828 - accuracy: 0.8558 - auc: 0.9170 - precision_8: 0.8558 - recall_8: 0.8558 - val_loss: 0.3390 - val_accuracy: 0.8651 - val_auc: 0.9268 - val_precision_8: 0.8651 - val_recall_8: 0.8651 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3058 - accuracy: 0.8781 - auc: 0.9420 - precision_8: 0.8781 - recall_8: 0.8781 - val_loss: 0.7635 - val_accuracy: 0.5087 - val_auc: 0.6319 - val_precision_8: 0.5087 - val_recall_8: 0.5087 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3685 - accuracy: 0.8706 - auc: 0.9355 - precision_8: 0.8706 - recall_8: 0.8706 - val_loss: 0.3072 - val_accuracy: 0.8599 - val_auc: 0.9421 - val_precision_8: 0.8599 - val_recall_8: 0.8599 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2823 - accuracy: 0.8855 - auc: 0.9495 - precision_8: 0.8855 - recall_8: 0.8855 - val_loss: 0.3457 - val_accuracy: 0.8495 - val_auc: 0.9265 - val_precision_8: 0.8495 - val_recall_8: 0.8495 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.2493 - accuracy: 0.9033 - auc: 0.9608 - precision_8: 0.9033 - recall_8: 0.9033 - val_loss: 0.2778 - val_accuracy: 0.8858 - val_auc: 0.9493 - val_precision_8: 0.8858 - val_recall_8: 0.8858 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.2436 - accuracy: 0.9077 - auc: 0.9622 - precision_8: 0.9077 - recall_8: 0.9077 - val_loss: 0.2589 - val_accuracy: 0.9031 - val_auc: 0.9561 - val_precision_8: 0.9031 - val_recall_8: 0.9031 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2314 - accuracy: 0.9114 - auc: 0.9668 - precision_8: 0.9114 - recall_8: 0.9114 - val_loss: 0.8801 - val_accuracy: 0.5138 - val_auc: 0.6281 - val_precision_8: 0.5138 - val_recall_8: 0.5138 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2279 - accuracy: 0.9192 - auc: 0.9667 - precision_8: 0.9192 - recall_8: 0.9192 - val_loss: 0.4269 - val_accuracy: 0.8495 - val_auc: 0.9214 - val_precision_8: 0.8495 - val_recall_8: 0.8495 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2041 - accuracy: 0.9225 - auc: 0.9736 - precision_8: 0.9225 - recall_8: 0.9225 - val_loss: 0.2912 - val_accuracy: 0.8858 - val_auc: 0.9482 - val_precision_8: 0.8858 - val_recall_8: 0.8858 - lr: 0.0050\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2199 - accuracy: 0.9199 - auc: 0.9673 - precision_8: 0.9199 - recall_8: 0.9199 - val_loss: 0.6656 - val_accuracy: 0.7837 - val_auc: 0.8730 - val_precision_8: 0.7837 - val_recall_8: 0.7837 - lr: 0.0050\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1893 - accuracy: 0.9340 - auc: 0.9773 - precision_8: 0.9340 - recall_8: 0.9340 - val_loss: 0.2116 - val_accuracy: 0.9273 - val_auc: 0.9688 - val_precision_8: 0.9273 - val_recall_8: 0.9273 - lr: 0.0050\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2268 - accuracy: 0.9140 - auc: 0.9658 - precision_8: 0.9140 - recall_8: 0.9140 - val_loss: 0.7158 - val_accuracy: 0.6332 - val_auc: 0.7368 - val_precision_8: 0.6332 - val_recall_8: 0.6332 - lr: 0.0050\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2206 - accuracy: 0.9188 - auc: 0.9698 - precision_8: 0.9188 - recall_8: 0.9188 - val_loss: 0.2334 - val_accuracy: 0.9187 - val_auc: 0.9624 - val_precision_8: 0.9187 - val_recall_8: 0.9187 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1855 - accuracy: 0.9314 - auc: 0.9774 - precision_8: 0.9314 - recall_8: 0.9314 - val_loss: 1.3860 - val_accuracy: 0.4118 - val_auc: 0.4153 - val_precision_8: 0.4118 - val_recall_8: 0.4118 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2303 - accuracy: 0.9136 - auc: 0.9654 - precision_8: 0.9136 - recall_8: 0.9136 - val_loss: 0.3026 - val_accuracy: 0.8702 - val_auc: 0.9497 - val_precision_8: 0.8702 - val_recall_8: 0.8702 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1874 - accuracy: 0.9314 - auc: 0.9780 - precision_8: 0.9314 - recall_8: 0.9314 - val_loss: 0.2143 - val_accuracy: 0.9204 - val_auc: 0.9721 - val_precision_8: 0.9204 - val_recall_8: 0.9204 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2175 - accuracy: 0.9159 - auc: 0.9706 - precision_8: 0.9159 - recall_8: 0.9159 - val_loss: 0.2577 - val_accuracy: 0.8875 - val_auc: 0.9587 - val_precision_8: 0.8875 - val_recall_8: 0.8875 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1939 - accuracy: 0.9337 - auc: 0.9749 - precision_8: 0.9337 - recall_8: 0.9337 - val_loss: 0.2167 - val_accuracy: 0.9187 - val_auc: 0.9684 - val_precision_8: 0.9187 - val_recall_8: 0.9187 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1644 - accuracy: 0.9455 - auc: 0.9825 - precision_8: 0.9455 - recall_8: 0.9455 - val_loss: 0.1780 - val_accuracy: 0.9343 - val_auc: 0.9793 - val_precision_8: 0.9343 - val_recall_8: 0.9343 - lr: 0.0025\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1708 - accuracy: 0.9385 - auc: 0.9822 - precision_8: 0.9385 - recall_8: 0.9385 - val_loss: 0.2011 - val_accuracy: 0.9291 - val_auc: 0.9740 - val_precision_8: 0.9291 - val_recall_8: 0.9291 - lr: 0.0025\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1709 - accuracy: 0.9411 - auc: 0.9808 - precision_8: 0.9411 - recall_8: 0.9411 - val_loss: 0.2760 - val_accuracy: 0.8910 - val_auc: 0.9578 - val_precision_8: 0.8910 - val_recall_8: 0.8910 - lr: 0.0025\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1606 - accuracy: 0.9474 - auc: 0.9823 - precision_8: 0.9474 - recall_8: 0.9474 - val_loss: 0.2128 - val_accuracy: 0.9118 - val_auc: 0.9705 - val_precision_8: 0.9118 - val_recall_8: 0.9118 - lr: 0.0025\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1570 - accuracy: 0.9477 - auc: 0.9827 - precision_8: 0.9477 - recall_8: 0.9477 - val_loss: 0.3297 - val_accuracy: 0.8824 - val_auc: 0.9487 - val_precision_8: 0.8824 - val_recall_8: 0.8824 - lr: 0.0025\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1525 - accuracy: 0.9463 - auc: 0.9845 - precision_8: 0.9463 - recall_8: 0.9463 - val_loss: 0.1922 - val_accuracy: 0.9360 - val_auc: 0.9749 - val_precision_8: 0.9360 - val_recall_8: 0.9360 - lr: 0.0025\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1622 - accuracy: 0.9422 - auc: 0.9837 - precision_8: 0.9422 - recall_8: 0.9422 - val_loss: 0.2756 - val_accuracy: 0.9152 - val_auc: 0.9603 - val_precision_8: 0.9152 - val_recall_8: 0.9152 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1625 - accuracy: 0.9444 - auc: 0.9819 - precision_8: 0.9444 - recall_8: 0.9444 - val_loss: 0.1601 - val_accuracy: 0.9394 - val_auc: 0.9842 - val_precision_8: 0.9394 - val_recall_8: 0.9394 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1424 - accuracy: 0.9514 - auc: 0.9865 - precision_8: 0.9514 - recall_8: 0.9514 - val_loss: 0.2009 - val_accuracy: 0.9170 - val_auc: 0.9754 - val_precision_8: 0.9170 - val_recall_8: 0.9170 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1649 - accuracy: 0.9437 - auc: 0.9809 - precision_8: 0.9437 - recall_8: 0.9437 - val_loss: 0.4528 - val_accuracy: 0.8616 - val_auc: 0.9251 - val_precision_8: 0.8616 - val_recall_8: 0.8616 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1526 - accuracy: 0.9477 - auc: 0.9845 - precision_8: 0.9477 - recall_8: 0.9477 - val_loss: 0.1776 - val_accuracy: 0.9291 - val_auc: 0.9811 - val_precision_8: 0.9291 - val_recall_8: 0.9291 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3372 - accuracy: 0.9166 - auc: 0.9598 - precision_8: 0.9166 - recall_8: 0.9166 - val_loss: 1.5438 - val_accuracy: 0.4170 - val_auc: 0.4167 - val_precision_8: 0.4170 - val_recall_8: 0.4170 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1907 - accuracy: 0.9314 - auc: 0.9760 - precision_8: 0.9314 - recall_8: 0.9314 - val_loss: 0.2417 - val_accuracy: 0.9014 - val_auc: 0.9681 - val_precision_8: 0.9014 - val_recall_8: 0.9014 - lr: 0.0012\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1448 - accuracy: 0.9533 - auc: 0.9854 - precision_8: 0.9533 - recall_8: 0.9533 - val_loss: 0.1633 - val_accuracy: 0.9446 - val_auc: 0.9815 - val_precision_8: 0.9446 - val_recall_8: 0.9446 - lr: 0.0012\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1499 - accuracy: 0.9552 - auc: 0.9844 - precision_8: 0.9552 - recall_8: 0.9552 - val_loss: 0.1649 - val_accuracy: 0.9429 - val_auc: 0.9820 - val_precision_8: 0.9429 - val_recall_8: 0.9429 - lr: 0.0012\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1179 - accuracy: 0.9640 - auc: 0.9902 - precision_8: 0.9640 - recall_8: 0.9640 - val_loss: 0.1642 - val_accuracy: 0.9394 - val_auc: 0.9835 - val_precision_8: 0.9394 - val_recall_8: 0.9394 - lr: 6.2500e-04\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1238 - accuracy: 0.9577 - auc: 0.9895 - precision_8: 0.9577 - recall_8: 0.9577 - val_loss: 0.1854 - val_accuracy: 0.9377 - val_auc: 0.9756 - val_precision_8: 0.9377 - val_recall_8: 0.9377 - lr: 6.2500e-04\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1243 - accuracy: 0.9622 - auc: 0.9893 - precision_8: 0.9622 - recall_8: 0.9622 - val_loss: 0.1470 - val_accuracy: 0.9446 - val_auc: 0.9861 - val_precision_8: 0.9446 - val_recall_8: 0.9446 - lr: 6.2500e-04\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1083 - accuracy: 0.9681 - auc: 0.9914 - precision_8: 0.9681 - recall_8: 0.9681 - val_loss: 0.2364 - val_accuracy: 0.9135 - val_auc: 0.9700 - val_precision_8: 0.9135 - val_recall_8: 0.9135 - lr: 6.2500e-04\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1166 - accuracy: 0.9615 - auc: 0.9893 - precision_8: 0.9615 - recall_8: 0.9615 - val_loss: 0.1618 - val_accuracy: 0.9394 - val_auc: 0.9825 - val_precision_8: 0.9394 - val_recall_8: 0.9394 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1197 - accuracy: 0.9618 - auc: 0.9891 - precision_8: 0.9618 - recall_8: 0.9618 - val_loss: 0.1831 - val_accuracy: 0.9360 - val_auc: 0.9790 - val_precision_8: 0.9360 - val_recall_8: 0.9360 - lr: 6.2500e-04\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1144 - accuracy: 0.9607 - auc: 0.9909 - precision_8: 0.9607 - recall_8: 0.9607 - val_loss: 0.1487 - val_accuracy: 0.9394 - val_auc: 0.9862 - val_precision_8: 0.9394 - val_recall_8: 0.9394 - lr: 6.2500e-04\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1023 - accuracy: 0.9689 - auc: 0.9923 - precision_8: 0.9689 - recall_8: 0.9689 - val_loss: 0.1524 - val_accuracy: 0.9429 - val_auc: 0.9850 - val_precision_8: 0.9429 - val_recall_8: 0.9429 - lr: 3.1250e-04\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0995 - accuracy: 0.9674 - auc: 0.9937 - precision_8: 0.9674 - recall_8: 0.9674 - val_loss: 0.1499 - val_accuracy: 0.9481 - val_auc: 0.9863 - val_precision_8: 0.9481 - val_recall_8: 0.9481 - lr: 3.1250e-04\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0945 - accuracy: 0.9689 - auc: 0.9942 - precision_8: 0.9689 - recall_8: 0.9689 - val_loss: 0.1587 - val_accuracy: 0.9446 - val_auc: 0.9815 - val_precision_8: 0.9446 - val_recall_8: 0.9446 - lr: 3.1250e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0986 - accuracy: 0.9681 - auc: 0.9923 - precision_8: 0.9681 - recall_8: 0.9681 - val_loss: 0.1528 - val_accuracy: 0.9412 - val_auc: 0.9853 - val_precision_8: 0.9412 - val_recall_8: 0.9412 - lr: 3.1250e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1059 - accuracy: 0.9648 - auc: 0.9914 - precision_8: 0.9648 - recall_8: 0.9648 - val_loss: 0.1501 - val_accuracy: 0.9446 - val_auc: 0.9862 - val_precision_8: 0.9446 - val_recall_8: 0.9446 - lr: 3.1250e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0980 - accuracy: 0.9711 - auc: 0.9936 - precision_8: 0.9711 - recall_8: 0.9711 - val_loss: 0.1594 - val_accuracy: 0.9394 - val_auc: 0.9845 - val_precision_8: 0.9394 - val_recall_8: 0.9394 - lr: 3.1250e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1006 - accuracy: 0.9666 - auc: 0.9928 - precision_8: 0.9666 - recall_8: 0.9666 - val_loss: 0.1529 - val_accuracy: 0.9481 - val_auc: 0.9846 - val_precision_8: 0.9481 - val_recall_8: 0.9481 - lr: 1.5625e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0996 - accuracy: 0.9692 - auc: 0.9926 - precision_8: 0.9692 - recall_8: 0.9692 - val_loss: 0.1622 - val_accuracy: 0.9377 - val_auc: 0.9834 - val_precision_8: 0.9377 - val_recall_8: 0.9377 - lr: 1.5625e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1028 - accuracy: 0.9689 - auc: 0.9911 - precision_8: 0.9689 - recall_8: 0.9689 - val_loss: 0.1505 - val_accuracy: 0.9481 - val_auc: 0.9844 - val_precision_8: 0.9481 - val_recall_8: 0.9481 - lr: 1.5625e-04\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0915 - accuracy: 0.9733 - auc: 0.9939 - precision_8: 0.9733 - recall_8: 0.9733 - val_loss: 0.1613 - val_accuracy: 0.9412 - val_auc: 0.9841 - val_precision_8: 0.9412 - val_recall_8: 0.9412 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0959 - accuracy: 0.9700 - auc: 0.9927 - precision_8: 0.9700 - recall_8: 0.9700 - val_loss: 0.1493 - val_accuracy: 0.9481 - val_auc: 0.9850 - val_precision_8: 0.9481 - val_recall_8: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0908 - accuracy: 0.9696 - auc: 0.9935 - precision_8: 0.9696 - recall_8: 0.9696 - val_loss: 0.1747 - val_accuracy: 0.9446 - val_auc: 0.9779 - val_precision_8: 0.9446 - val_recall_8: 0.9446 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0966 - accuracy: 0.9711 - auc: 0.9924 - precision_8: 0.9711 - recall_8: 0.9711 - val_loss: 0.1420 - val_accuracy: 0.9516 - val_auc: 0.9868 - val_precision_8: 0.9516 - val_recall_8: 0.9516 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0975 - accuracy: 0.9692 - auc: 0.9926 - precision_8: 0.9692 - recall_8: 0.9692 - val_loss: 0.1458 - val_accuracy: 0.9498 - val_auc: 0.9853 - val_precision_8: 0.9498 - val_recall_8: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0933 - accuracy: 0.9722 - auc: 0.9932 - precision_8: 0.9722 - recall_8: 0.9722 - val_loss: 0.1467 - val_accuracy: 0.9464 - val_auc: 0.9859 - val_precision_8: 0.9464 - val_recall_8: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0911 - accuracy: 0.9744 - auc: 0.9933 - precision_8: 0.9744 - recall_8: 0.9744 - val_loss: 0.1427 - val_accuracy: 0.9498 - val_auc: 0.9866 - val_precision_8: 0.9498 - val_recall_8: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1001 - accuracy: 0.9652 - auc: 0.9931 - precision_8: 0.9652 - recall_8: 0.9652 - val_loss: 0.1760 - val_accuracy: 0.9446 - val_auc: 0.9776 - val_precision_8: 0.9446 - val_recall_8: 0.9446 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0880 - accuracy: 0.9718 - auc: 0.9948 - precision_8: 0.9718 - recall_8: 0.9718 - val_loss: 0.1460 - val_accuracy: 0.9464 - val_auc: 0.9854 - val_precision_8: 0.9464 - val_recall_8: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0879 - accuracy: 0.9722 - auc: 0.9935 - precision_8: 0.9722 - recall_8: 0.9722 - val_loss: 0.1453 - val_accuracy: 0.9481 - val_auc: 0.9858 - val_precision_8: 0.9481 - val_recall_8: 0.9481 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0864 - accuracy: 0.9755 - auc: 0.9942 - precision_8: 0.9755 - recall_8: 0.9755 - val_loss: 0.1417 - val_accuracy: 0.9498 - val_auc: 0.9862 - val_precision_8: 0.9498 - val_recall_8: 0.9498 - lr: 1.0000e-04\n",
      "Start 4th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 109.7074 - accuracy: 0.6242 - auc: 0.6255 - precision_9: 0.6242 - recall_9: 0.6242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 31ms/step - loss: 109.7074 - accuracy: 0.6242 - auc: 0.6255 - precision_9: 0.6242 - recall_9: 0.6242 - val_loss: 2.7680 - val_accuracy: 0.5969 - val_auc: 0.6447 - val_precision_9: 0.5969 - val_recall_9: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5947 - accuracy: 0.7461 - auc: 0.7938 - precision_9: 0.7461 - recall_9: 0.7461 - val_loss: 1.0329 - val_accuracy: 0.6176 - val_auc: 0.7076 - val_precision_9: 0.6176 - val_recall_9: 0.6176 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5246 - accuracy: 0.7695 - auc: 0.8198 - precision_9: 0.7695 - recall_9: 0.7695 - val_loss: 0.7679 - val_accuracy: 0.7232 - val_auc: 0.7546 - val_precision_9: 0.7232 - val_recall_9: 0.7232 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5159 - accuracy: 0.7728 - auc: 0.8273 - precision_9: 0.7728 - recall_9: 0.7728 - val_loss: 0.5457 - val_accuracy: 0.7561 - val_auc: 0.8183 - val_precision_9: 0.7561 - val_recall_9: 0.7561 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4996 - accuracy: 0.7776 - auc: 0.8373 - precision_9: 0.7776 - recall_9: 0.7776 - val_loss: 0.4421 - val_accuracy: 0.8062 - val_auc: 0.8929 - val_precision_9: 0.8062 - val_recall_9: 0.8062 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4714 - accuracy: 0.7787 - auc: 0.8552 - precision_9: 0.7787 - recall_9: 0.7787 - val_loss: 0.4566 - val_accuracy: 0.7907 - val_auc: 0.8667 - val_precision_9: 0.7907 - val_recall_9: 0.7907 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4726 - accuracy: 0.7869 - auc: 0.8575 - precision_9: 0.7869 - recall_9: 0.7869 - val_loss: 0.5076 - val_accuracy: 0.8045 - val_auc: 0.8497 - val_precision_9: 0.8045 - val_recall_9: 0.8045 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4571 - accuracy: 0.7924 - auc: 0.8673 - precision_9: 0.7924 - recall_9: 0.7924 - val_loss: 0.4350 - val_accuracy: 0.8010 - val_auc: 0.8956 - val_precision_9: 0.8010 - val_recall_9: 0.8010 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4041 - accuracy: 0.8054 - auc: 0.8946 - precision_9: 0.8054 - recall_9: 0.8054 - val_loss: 0.4865 - val_accuracy: 0.7630 - val_auc: 0.8380 - val_precision_9: 0.7630 - val_recall_9: 0.7630 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3896 - accuracy: 0.8139 - auc: 0.9013 - precision_9: 0.8139 - recall_9: 0.8139 - val_loss: 0.3857 - val_accuracy: 0.8374 - val_auc: 0.9115 - val_precision_9: 0.8374 - val_recall_9: 0.8374 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3610 - accuracy: 0.8295 - auc: 0.9181 - precision_9: 0.8295 - recall_9: 0.8295 - val_loss: 1.7817 - val_accuracy: 0.4308 - val_auc: 0.5184 - val_precision_9: 0.4308 - val_recall_9: 0.4308 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4607 - accuracy: 0.8065 - auc: 0.8947 - precision_9: 0.8065 - recall_9: 0.8065 - val_loss: 0.4551 - val_accuracy: 0.7837 - val_auc: 0.8695 - val_precision_9: 0.7837 - val_recall_9: 0.7837 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.5097 - accuracy: 0.8380 - auc: 0.9102 - precision_9: 0.8380 - recall_9: 0.8380 - val_loss: 0.4323 - val_accuracy: 0.8218 - val_auc: 0.8855 - val_precision_9: 0.8218 - val_recall_9: 0.8218 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.3409 - accuracy: 0.8458 - auc: 0.9307 - precision_9: 0.8458 - recall_9: 0.8458 - val_loss: 0.3278 - val_accuracy: 0.8702 - val_auc: 0.9476 - val_precision_9: 0.8702 - val_recall_9: 0.8702 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3416 - accuracy: 0.8365 - auc: 0.9298 - precision_9: 0.8365 - recall_9: 0.8365 - val_loss: 0.4637 - val_accuracy: 0.8253 - val_auc: 0.8789 - val_precision_9: 0.8253 - val_recall_9: 0.8253 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3157 - accuracy: 0.8503 - auc: 0.9392 - precision_9: 0.8503 - recall_9: 0.8503 - val_loss: 0.5198 - val_accuracy: 0.7457 - val_auc: 0.8557 - val_precision_9: 0.7457 - val_recall_9: 0.7457 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3972 - accuracy: 0.8525 - auc: 0.9182 - precision_9: 0.8525 - recall_9: 0.8525 - val_loss: 1.2282 - val_accuracy: 0.6817 - val_auc: 0.7336 - val_precision_9: 0.6817 - val_recall_9: 0.6817 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3524 - accuracy: 0.8566 - auc: 0.9295 - precision_9: 0.8566 - recall_9: 0.8566 - val_loss: 0.5480 - val_accuracy: 0.7699 - val_auc: 0.8239 - val_precision_9: 0.7699 - val_recall_9: 0.7699 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2992 - accuracy: 0.8751 - auc: 0.9466 - precision_9: 0.8751 - recall_9: 0.8751 - val_loss: 0.3629 - val_accuracy: 0.8702 - val_auc: 0.9219 - val_precision_9: 0.8702 - val_recall_9: 0.8702 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2438 - accuracy: 0.8910 - auc: 0.9636 - precision_9: 0.8910 - recall_9: 0.8910 - val_loss: 1.1253 - val_accuracy: 0.7439 - val_auc: 0.8173 - val_precision_9: 0.7439 - val_recall_9: 0.7439 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2992 - accuracy: 0.8662 - auc: 0.9483 - precision_9: 0.8662 - recall_9: 0.8662 - val_loss: 0.3499 - val_accuracy: 0.8633 - val_auc: 0.9316 - val_precision_9: 0.8633 - val_recall_9: 0.8633 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2568 - accuracy: 0.8877 - auc: 0.9614 - precision_9: 0.8877 - recall_9: 0.8877 - val_loss: 0.7263 - val_accuracy: 0.8426 - val_auc: 0.8906 - val_precision_9: 0.8426 - val_recall_9: 0.8426 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3154 - accuracy: 0.8569 - auc: 0.9450 - precision_9: 0.8569 - recall_9: 0.8569 - val_loss: 2.5271 - val_accuracy: 0.6367 - val_auc: 0.7329 - val_precision_9: 0.6367 - val_recall_9: 0.6367 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2300 - accuracy: 0.8803 - auc: 0.9672 - precision_9: 0.8803 - recall_9: 0.8803 - val_loss: 0.5492 - val_accuracy: 0.8339 - val_auc: 0.9108 - val_precision_9: 0.8339 - val_recall_9: 0.8339 - lr: 0.0050\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.2662 - accuracy: 0.8951 - auc: 0.9605 - precision_9: 0.8951 - recall_9: 0.8951 - val_loss: 0.3131 - val_accuracy: 0.8824 - val_auc: 0.9519 - val_precision_9: 0.8824 - val_recall_9: 0.8824 - lr: 0.0050\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2443 - accuracy: 0.8940 - auc: 0.9645 - precision_9: 0.8940 - recall_9: 0.8940 - val_loss: 0.5201 - val_accuracy: 0.7958 - val_auc: 0.8751 - val_precision_9: 0.7958 - val_recall_9: 0.7958 - lr: 0.0050\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2411 - accuracy: 0.9114 - auc: 0.9678 - precision_9: 0.9114 - recall_9: 0.9114 - val_loss: 0.3696 - val_accuracy: 0.8616 - val_auc: 0.9463 - val_precision_9: 0.8616 - val_recall_9: 0.8616 - lr: 0.0050\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1926 - accuracy: 0.9307 - auc: 0.9783 - precision_9: 0.9307 - recall_9: 0.9307 - val_loss: 0.2063 - val_accuracy: 0.9256 - val_auc: 0.9769 - val_precision_9: 0.9256 - val_recall_9: 0.9256 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1927 - accuracy: 0.9418 - auc: 0.9789 - precision_9: 0.9418 - recall_9: 0.9418 - val_loss: 0.2215 - val_accuracy: 0.9256 - val_auc: 0.9745 - val_precision_9: 0.9256 - val_recall_9: 0.9256 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1859 - accuracy: 0.9370 - auc: 0.9810 - precision_9: 0.9370 - recall_9: 0.9370 - val_loss: 0.1966 - val_accuracy: 0.9152 - val_auc: 0.9790 - val_precision_9: 0.9152 - val_recall_9: 0.9152 - lr: 0.0025\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1817 - accuracy: 0.9351 - auc: 0.9806 - precision_9: 0.9351 - recall_9: 0.9351 - val_loss: 0.3236 - val_accuracy: 0.9152 - val_auc: 0.9705 - val_precision_9: 0.9152 - val_recall_9: 0.9152 - lr: 0.0025\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1646 - accuracy: 0.9407 - auc: 0.9832 - precision_9: 0.9407 - recall_9: 0.9407 - val_loss: 0.3307 - val_accuracy: 0.8858 - val_auc: 0.9547 - val_precision_9: 0.8858 - val_recall_9: 0.8858 - lr: 0.0025\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1594 - accuracy: 0.9285 - auc: 0.9841 - precision_9: 0.9285 - recall_9: 0.9285 - val_loss: 0.1821 - val_accuracy: 0.9273 - val_auc: 0.9816 - val_precision_9: 0.9273 - val_recall_9: 0.9273 - lr: 0.0025\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1520 - accuracy: 0.9459 - auc: 0.9855 - precision_9: 0.9459 - recall_9: 0.9459 - val_loss: 0.1756 - val_accuracy: 0.9308 - val_auc: 0.9810 - val_precision_9: 0.9308 - val_recall_9: 0.9308 - lr: 0.0025\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1479 - accuracy: 0.9489 - auc: 0.9862 - precision_9: 0.9489 - recall_9: 0.9489 - val_loss: 0.3156 - val_accuracy: 0.8685 - val_auc: 0.9559 - val_precision_9: 0.8685 - val_recall_9: 0.8685 - lr: 0.0025\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1512 - accuracy: 0.9396 - auc: 0.9860 - precision_9: 0.9396 - recall_9: 0.9396 - val_loss: 0.1557 - val_accuracy: 0.9377 - val_auc: 0.9843 - val_precision_9: 0.9377 - val_recall_9: 0.9377 - lr: 0.0025\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1570 - accuracy: 0.9414 - auc: 0.9853 - precision_9: 0.9414 - recall_9: 0.9414 - val_loss: 0.3669 - val_accuracy: 0.8875 - val_auc: 0.9556 - val_precision_9: 0.8875 - val_recall_9: 0.8875 - lr: 0.0025\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1344 - accuracy: 0.9481 - auc: 0.9883 - precision_9: 0.9481 - recall_9: 0.9481 - val_loss: 0.2032 - val_accuracy: 0.9239 - val_auc: 0.9792 - val_precision_9: 0.9239 - val_recall_9: 0.9239 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1426 - accuracy: 0.9511 - auc: 0.9872 - precision_9: 0.9511 - recall_9: 0.9511 - val_loss: 0.1648 - val_accuracy: 0.9187 - val_auc: 0.9832 - val_precision_9: 0.9187 - val_recall_9: 0.9187 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1339 - accuracy: 0.9474 - auc: 0.9889 - precision_9: 0.9474 - recall_9: 0.9474 - val_loss: 0.2053 - val_accuracy: 0.9360 - val_auc: 0.9752 - val_precision_9: 0.9360 - val_recall_9: 0.9360 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1256 - accuracy: 0.9518 - auc: 0.9900 - precision_9: 0.9518 - recall_9: 0.9518 - val_loss: 0.7725 - val_accuracy: 0.7439 - val_auc: 0.8419 - val_precision_9: 0.7439 - val_recall_9: 0.7439 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1605 - accuracy: 0.9303 - auc: 0.9849 - precision_9: 0.9303 - recall_9: 0.9303 - val_loss: 0.2899 - val_accuracy: 0.9152 - val_auc: 0.9580 - val_precision_9: 0.9152 - val_recall_9: 0.9152 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1273 - accuracy: 0.9463 - auc: 0.9900 - precision_9: 0.9463 - recall_9: 0.9463 - val_loss: 0.4649 - val_accuracy: 0.8581 - val_auc: 0.9383 - val_precision_9: 0.8581 - val_recall_9: 0.8581 - lr: 0.0025\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1152 - accuracy: 0.9566 - auc: 0.9915 - precision_9: 0.9566 - recall_9: 0.9566 - val_loss: 0.1932 - val_accuracy: 0.9308 - val_auc: 0.9823 - val_precision_9: 0.9308 - val_recall_9: 0.9308 - lr: 0.0025\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1177 - accuracy: 0.9537 - auc: 0.9915 - precision_9: 0.9537 - recall_9: 0.9537 - val_loss: 0.2127 - val_accuracy: 0.9170 - val_auc: 0.9760 - val_precision_9: 0.9170 - val_recall_9: 0.9170 - lr: 0.0025\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1242 - accuracy: 0.9503 - auc: 0.9902 - precision_9: 0.9503 - recall_9: 0.9503 - val_loss: 0.1718 - val_accuracy: 0.9360 - val_auc: 0.9832 - val_precision_9: 0.9360 - val_recall_9: 0.9360 - lr: 0.0025\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1170 - accuracy: 0.9589 - auc: 0.9919 - precision_9: 0.9589 - recall_9: 0.9589 - val_loss: 0.6667 - val_accuracy: 0.7682 - val_auc: 0.8795 - val_precision_9: 0.7682 - val_recall_9: 0.7682 - lr: 0.0025\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1044 - accuracy: 0.9574 - auc: 0.9935 - precision_9: 0.9574 - recall_9: 0.9574 - val_loss: 0.5187 - val_accuracy: 0.8339 - val_auc: 0.9326 - val_precision_9: 0.8339 - val_recall_9: 0.8339 - lr: 0.0012\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0847 - accuracy: 0.9640 - auc: 0.9954 - precision_9: 0.9640 - recall_9: 0.9640 - val_loss: 0.1476 - val_accuracy: 0.9516 - val_auc: 0.9873 - val_precision_9: 0.9516 - val_recall_9: 0.9516 - lr: 0.0012\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0971 - accuracy: 0.9633 - auc: 0.9945 - precision_9: 0.9633 - recall_9: 0.9633 - val_loss: 0.3875 - val_accuracy: 0.9118 - val_auc: 0.9607 - val_precision_9: 0.9118 - val_recall_9: 0.9118 - lr: 0.0012\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0982 - accuracy: 0.9507 - auc: 0.9929 - precision_9: 0.9507 - recall_9: 0.9507 - val_loss: 0.2642 - val_accuracy: 0.9256 - val_auc: 0.9750 - val_precision_9: 0.9256 - val_recall_9: 0.9256 - lr: 0.0012\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0847 - accuracy: 0.9644 - auc: 0.9952 - precision_9: 0.9644 - recall_9: 0.9644 - val_loss: 0.2022 - val_accuracy: 0.9412 - val_auc: 0.9826 - val_precision_9: 0.9412 - val_recall_9: 0.9412 - lr: 0.0012\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0786 - accuracy: 0.9618 - auc: 0.9956 - precision_9: 0.9618 - recall_9: 0.9618 - val_loss: 0.4192 - val_accuracy: 0.8910 - val_auc: 0.9539 - val_precision_9: 0.8910 - val_recall_9: 0.8910 - lr: 6.2500e-04\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0919 - accuracy: 0.9600 - auc: 0.9946 - precision_9: 0.9600 - recall_9: 0.9600 - val_loss: 0.3592 - val_accuracy: 0.9048 - val_auc: 0.9547 - val_precision_9: 0.9048 - val_recall_9: 0.9048 - lr: 6.2500e-04\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0664 - accuracy: 0.9689 - auc: 0.9968 - precision_9: 0.9689 - recall_9: 0.9689 - val_loss: 0.3196 - val_accuracy: 0.8945 - val_auc: 0.9666 - val_precision_9: 0.8945 - val_recall_9: 0.8945 - lr: 6.2500e-04\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0886 - accuracy: 0.9592 - auc: 0.9946 - precision_9: 0.9592 - recall_9: 0.9592 - val_loss: 0.2545 - val_accuracy: 0.9031 - val_auc: 0.9725 - val_precision_9: 0.9031 - val_recall_9: 0.9031 - lr: 6.2500e-04\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0736 - accuracy: 0.9637 - auc: 0.9966 - precision_9: 0.9637 - recall_9: 0.9637 - val_loss: 0.2621 - val_accuracy: 0.9412 - val_auc: 0.9764 - val_precision_9: 0.9412 - val_recall_9: 0.9412 - lr: 6.2500e-04\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0679 - accuracy: 0.9681 - auc: 0.9965 - precision_9: 0.9681 - recall_9: 0.9681 - val_loss: 0.2139 - val_accuracy: 0.9516 - val_auc: 0.9810 - val_precision_9: 0.9516 - val_recall_9: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0671 - accuracy: 0.9655 - auc: 0.9969 - precision_9: 0.9655 - recall_9: 0.9655 - val_loss: 0.2078 - val_accuracy: 0.9498 - val_auc: 0.9834 - val_precision_9: 0.9498 - val_recall_9: 0.9498 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0665 - accuracy: 0.9681 - auc: 0.9969 - precision_9: 0.9681 - recall_9: 0.9681 - val_loss: 0.1707 - val_accuracy: 0.9516 - val_auc: 0.9866 - val_precision_9: 0.9516 - val_recall_9: 0.9516 - lr: 3.1250e-04\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0731 - accuracy: 0.9737 - auc: 0.9967 - precision_9: 0.9737 - recall_9: 0.9737 - val_loss: 0.2232 - val_accuracy: 0.9550 - val_auc: 0.9857 - val_precision_9: 0.9550 - val_recall_9: 0.9550 - lr: 3.1250e-04\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0610 - accuracy: 0.9752 - auc: 0.9977 - precision_9: 0.9752 - recall_9: 0.9752 - val_loss: 0.1778 - val_accuracy: 0.9585 - val_auc: 0.9860 - val_precision_9: 0.9585 - val_recall_9: 0.9585 - lr: 1.5625e-04\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0589 - accuracy: 0.9726 - auc: 0.9979 - precision_9: 0.9726 - recall_9: 0.9726 - val_loss: 0.2006 - val_accuracy: 0.9567 - val_auc: 0.9862 - val_precision_9: 0.9567 - val_recall_9: 0.9567 - lr: 1.5625e-04\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0559 - accuracy: 0.9715 - auc: 0.9979 - precision_9: 0.9715 - recall_9: 0.9715 - val_loss: 0.1772 - val_accuracy: 0.9585 - val_auc: 0.9861 - val_precision_9: 0.9585 - val_recall_9: 0.9585 - lr: 1.5625e-04\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.0566 - accuracy: 0.9766 - auc: 0.9980 - precision_9: 0.9766 - recall_9: 0.9766 - val_loss: 0.1825 - val_accuracy: 0.9602 - val_auc: 0.9864 - val_precision_9: 0.9602 - val_recall_9: 0.9602 - lr: 1.5625e-04\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0596 - accuracy: 0.9722 - auc: 0.9979 - precision_9: 0.9722 - recall_9: 0.9722 - val_loss: 0.1963 - val_accuracy: 0.9585 - val_auc: 0.9848 - val_precision_9: 0.9585 - val_recall_9: 0.9585 - lr: 1.5625e-04\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0642 - accuracy: 0.9744 - auc: 0.9976 - precision_9: 0.9744 - recall_9: 0.9744 - val_loss: 0.2201 - val_accuracy: 0.9533 - val_auc: 0.9838 - val_precision_9: 0.9533 - val_recall_9: 0.9533 - lr: 1.5625e-04\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0597 - accuracy: 0.9766 - auc: 0.9977 - precision_9: 0.9766 - recall_9: 0.9766 - val_loss: 0.1968 - val_accuracy: 0.9567 - val_auc: 0.9848 - val_precision_9: 0.9567 - val_recall_9: 0.9567 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0561 - accuracy: 0.9726 - auc: 0.9980 - precision_9: 0.9726 - recall_9: 0.9726 - val_loss: 0.1941 - val_accuracy: 0.9550 - val_auc: 0.9851 - val_precision_9: 0.9550 - val_recall_9: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0527 - accuracy: 0.9744 - auc: 0.9983 - precision_9: 0.9744 - recall_9: 0.9744 - val_loss: 0.2095 - val_accuracy: 0.9567 - val_auc: 0.9852 - val_precision_9: 0.9567 - val_recall_9: 0.9567 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0550 - accuracy: 0.9737 - auc: 0.9981 - precision_9: 0.9737 - recall_9: 0.9737 - val_loss: 0.1904 - val_accuracy: 0.9602 - val_auc: 0.9865 - val_precision_9: 0.9602 - val_recall_9: 0.9602 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0606 - accuracy: 0.9707 - auc: 0.9974 - precision_9: 0.9707 - recall_9: 0.9707 - val_loss: 0.2317 - val_accuracy: 0.9498 - val_auc: 0.9823 - val_precision_9: 0.9498 - val_recall_9: 0.9498 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0569 - accuracy: 0.9759 - auc: 0.9978 - precision_9: 0.9759 - recall_9: 0.9759 - val_loss: 0.2150 - val_accuracy: 0.9533 - val_auc: 0.9846 - val_precision_9: 0.9533 - val_recall_9: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0550 - accuracy: 0.9741 - auc: 0.9982 - precision_9: 0.9741 - recall_9: 0.9741 - val_loss: 0.2206 - val_accuracy: 0.9533 - val_auc: 0.9847 - val_precision_9: 0.9533 - val_recall_9: 0.9533 - lr: 1.0000e-04\n",
      "Start 5th-fold in 5 cross validation\n",
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 94.5600 - accuracy: 0.6168 - auc: 0.6351 - precision_10: 0.6168 - recall_10: 0.6168"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g6/anaconda3/envs/mech/lib/python3.9/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 4s 30ms/step - loss: 94.5600 - accuracy: 0.6168 - auc: 0.6351 - precision_10: 0.6168 - recall_10: 0.6168 - val_loss: 202.3538 - val_accuracy: 0.5969 - val_auc: 0.5969 - val_precision_10: 0.5969 - val_recall_10: 0.5969 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.7720 - accuracy: 0.7105 - auc: 0.7582 - precision_10: 0.7105 - recall_10: 0.7105 - val_loss: 0.9607 - val_accuracy: 0.6073 - val_auc: 0.7056 - val_precision_10: 0.6073 - val_recall_10: 0.6073 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.5436 - accuracy: 0.7498 - auc: 0.8068 - precision_10: 0.7498 - recall_10: 0.7498 - val_loss: 0.7154 - val_accuracy: 0.7249 - val_auc: 0.7526 - val_precision_10: 0.7249 - val_recall_10: 0.7249 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5158 - accuracy: 0.7643 - auc: 0.8239 - precision_10: 0.7643 - recall_10: 0.7643 - val_loss: 0.5610 - val_accuracy: 0.7422 - val_auc: 0.7815 - val_precision_10: 0.7422 - val_recall_10: 0.7422 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.5062 - accuracy: 0.7691 - auc: 0.8311 - precision_10: 0.7691 - recall_10: 0.7691 - val_loss: 0.5693 - val_accuracy: 0.7457 - val_auc: 0.7899 - val_precision_10: 0.7457 - val_recall_10: 0.7457 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4974 - accuracy: 0.7709 - auc: 0.8398 - precision_10: 0.7709 - recall_10: 0.7709 - val_loss: 0.4589 - val_accuracy: 0.7941 - val_auc: 0.8774 - val_precision_10: 0.7941 - val_recall_10: 0.7941 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4866 - accuracy: 0.7813 - auc: 0.8446 - precision_10: 0.7813 - recall_10: 0.7813 - val_loss: 0.4385 - val_accuracy: 0.8131 - val_auc: 0.8902 - val_precision_10: 0.8131 - val_recall_10: 0.8131 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.4548 - accuracy: 0.7932 - auc: 0.8667 - precision_10: 0.7932 - recall_10: 0.7932 - val_loss: 0.4379 - val_accuracy: 0.8166 - val_auc: 0.8856 - val_precision_10: 0.8166 - val_recall_10: 0.8166 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.4773 - accuracy: 0.7910 - auc: 0.8574 - precision_10: 0.7910 - recall_10: 0.7910 - val_loss: 0.6421 - val_accuracy: 0.7007 - val_auc: 0.8228 - val_precision_10: 0.7007 - val_recall_10: 0.7007 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.4662 - accuracy: 0.7843 - auc: 0.8594 - precision_10: 0.7843 - recall_10: 0.7843 - val_loss: 0.3776 - val_accuracy: 0.8391 - val_auc: 0.9211 - val_precision_10: 0.8391 - val_recall_10: 0.8391 - lr: 0.0100\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3888 - accuracy: 0.8239 - auc: 0.9054 - precision_10: 0.8239 - recall_10: 0.8239 - val_loss: 0.5110 - val_accuracy: 0.7145 - val_auc: 0.8306 - val_precision_10: 0.7145 - val_recall_10: 0.7145 - lr: 0.0100\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3407 - accuracy: 0.8495 - auc: 0.9287 - precision_10: 0.8495 - recall_10: 0.8495 - val_loss: 0.2716 - val_accuracy: 0.8616 - val_auc: 0.9562 - val_precision_10: 0.8616 - val_recall_10: 0.8616 - lr: 0.0100\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.3232 - accuracy: 0.8625 - auc: 0.9378 - precision_10: 0.8625 - recall_10: 0.8625 - val_loss: 0.2651 - val_accuracy: 0.9014 - val_auc: 0.9565 - val_precision_10: 0.9014 - val_recall_10: 0.9014 - lr: 0.0100\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3792 - accuracy: 0.8558 - auc: 0.9279 - precision_10: 0.8558 - recall_10: 0.8558 - val_loss: 0.4650 - val_accuracy: 0.8097 - val_auc: 0.8971 - val_precision_10: 0.8097 - val_recall_10: 0.8097 - lr: 0.0100\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3139 - accuracy: 0.8866 - auc: 0.9482 - precision_10: 0.8866 - recall_10: 0.8866 - val_loss: 1.0494 - val_accuracy: 0.5657 - val_auc: 0.7270 - val_precision_10: 0.5657 - val_recall_10: 0.5657 - lr: 0.0100\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2786 - accuracy: 0.8888 - auc: 0.9537 - precision_10: 0.8888 - recall_10: 0.8888 - val_loss: 0.8154 - val_accuracy: 0.6038 - val_auc: 0.7207 - val_precision_10: 0.6038 - val_recall_10: 0.6038 - lr: 0.0100\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2739 - accuracy: 0.8899 - auc: 0.9567 - precision_10: 0.8899 - recall_10: 0.8899 - val_loss: 1.0200 - val_accuracy: 0.5502 - val_auc: 0.6714 - val_precision_10: 0.5502 - val_recall_10: 0.5502 - lr: 0.0100\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.3394 - accuracy: 0.8988 - auc: 0.9540 - precision_10: 0.8988 - recall_10: 0.8988 - val_loss: 0.8770 - val_accuracy: 0.6851 - val_auc: 0.7885 - val_precision_10: 0.6851 - val_recall_10: 0.6851 - lr: 0.0100\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.2248 - accuracy: 0.9118 - auc: 0.9693 - precision_10: 0.9118 - recall_10: 0.9118 - val_loss: 0.7364 - val_accuracy: 0.6298 - val_auc: 0.7472 - val_precision_10: 0.6298 - val_recall_10: 0.6298 - lr: 0.0100\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1948 - accuracy: 0.9270 - auc: 0.9770 - precision_10: 0.9270 - recall_10: 0.9270 - val_loss: 0.2666 - val_accuracy: 0.8806 - val_auc: 0.9588 - val_precision_10: 0.8806 - val_recall_10: 0.8806 - lr: 0.0100\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1667 - accuracy: 0.9362 - auc: 0.9832 - precision_10: 0.9362 - recall_10: 0.9362 - val_loss: 0.2651 - val_accuracy: 0.9239 - val_auc: 0.9654 - val_precision_10: 0.9239 - val_recall_10: 0.9239 - lr: 0.0100\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1903 - accuracy: 0.9296 - auc: 0.9784 - precision_10: 0.9296 - recall_10: 0.9296 - val_loss: 0.3688 - val_accuracy: 0.8564 - val_auc: 0.9349 - val_precision_10: 0.8564 - val_recall_10: 0.8564 - lr: 0.0100\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1705 - accuracy: 0.9411 - auc: 0.9828 - precision_10: 0.9411 - recall_10: 0.9411 - val_loss: 0.9323 - val_accuracy: 0.6955 - val_auc: 0.7632 - val_precision_10: 0.6955 - val_recall_10: 0.6955 - lr: 0.0100\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1591 - accuracy: 0.9481 - auc: 0.9845 - precision_10: 0.9481 - recall_10: 0.9481 - val_loss: 1.0567 - val_accuracy: 0.7145 - val_auc: 0.7828 - val_precision_10: 0.7145 - val_recall_10: 0.7145 - lr: 0.0100\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1695 - accuracy: 0.9374 - auc: 0.9826 - precision_10: 0.9374 - recall_10: 0.9374 - val_loss: 1.1780 - val_accuracy: 0.5433 - val_auc: 0.6774 - val_precision_10: 0.5433 - val_recall_10: 0.5433 - lr: 0.0100\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1841 - accuracy: 0.9285 - auc: 0.9802 - precision_10: 0.9285 - recall_10: 0.9285 - val_loss: 1.3104 - val_accuracy: 0.5467 - val_auc: 0.6739 - val_precision_10: 0.5467 - val_recall_10: 0.5467 - lr: 0.0100\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1709 - accuracy: 0.9274 - auc: 0.9830 - precision_10: 0.9274 - recall_10: 0.9274 - val_loss: 0.6962 - val_accuracy: 0.7336 - val_auc: 0.8389 - val_precision_10: 0.7336 - val_recall_10: 0.7336 - lr: 0.0100\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - 2s 28ms/step - loss: 0.1557 - accuracy: 0.9396 - auc: 0.9854 - precision_10: 0.9396 - recall_10: 0.9396 - val_loss: 0.1482 - val_accuracy: 0.9394 - val_auc: 0.9869 - val_precision_10: 0.9394 - val_recall_10: 0.9394 - lr: 0.0050\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1267 - accuracy: 0.9518 - auc: 0.9899 - precision_10: 0.9518 - recall_10: 0.9518 - val_loss: 0.3513 - val_accuracy: 0.8616 - val_auc: 0.9354 - val_precision_10: 0.8616 - val_recall_10: 0.8616 - lr: 0.0050\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1271 - accuracy: 0.9540 - auc: 0.9904 - precision_10: 0.9540 - recall_10: 0.9540 - val_loss: 0.4588 - val_accuracy: 0.8841 - val_auc: 0.9374 - val_precision_10: 0.8841 - val_recall_10: 0.8841 - lr: 0.0050\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1305 - accuracy: 0.9581 - auc: 0.9895 - precision_10: 0.9581 - recall_10: 0.9581 - val_loss: 0.2336 - val_accuracy: 0.9273 - val_auc: 0.9713 - val_precision_10: 0.9273 - val_recall_10: 0.9273 - lr: 0.0050\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1265 - accuracy: 0.9522 - auc: 0.9903 - precision_10: 0.9522 - recall_10: 0.9522 - val_loss: 0.1600 - val_accuracy: 0.9308 - val_auc: 0.9856 - val_precision_10: 0.9308 - val_recall_10: 0.9308 - lr: 0.0050\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1256 - accuracy: 0.9544 - auc: 0.9904 - precision_10: 0.9544 - recall_10: 0.9544 - val_loss: 0.1585 - val_accuracy: 0.9412 - val_auc: 0.9854 - val_precision_10: 0.9412 - val_recall_10: 0.9412 - lr: 0.0050\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1186 - accuracy: 0.9611 - auc: 0.9911 - precision_10: 0.9611 - recall_10: 0.9611 - val_loss: 0.1762 - val_accuracy: 0.9308 - val_auc: 0.9816 - val_precision_10: 0.9308 - val_recall_10: 0.9308 - lr: 0.0050\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.1397 - accuracy: 0.9518 - auc: 0.9881 - precision_10: 0.9518 - recall_10: 0.9518 - val_loss: 0.1493 - val_accuracy: 0.9498 - val_auc: 0.9872 - val_precision_10: 0.9498 - val_recall_10: 0.9498 - lr: 0.0050\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1413 - accuracy: 0.9463 - auc: 0.9885 - precision_10: 0.9463 - recall_10: 0.9463 - val_loss: 0.1455 - val_accuracy: 0.9412 - val_auc: 0.9881 - val_precision_10: 0.9412 - val_recall_10: 0.9412 - lr: 0.0050\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1496 - accuracy: 0.9440 - auc: 0.9871 - precision_10: 0.9440 - recall_10: 0.9440 - val_loss: 0.4158 - val_accuracy: 0.8547 - val_auc: 0.9449 - val_precision_10: 0.8547 - val_recall_10: 0.8547 - lr: 0.0050\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1286 - accuracy: 0.9559 - auc: 0.9892 - precision_10: 0.9559 - recall_10: 0.9559 - val_loss: 0.1275 - val_accuracy: 0.9446 - val_auc: 0.9893 - val_precision_10: 0.9446 - val_recall_10: 0.9446 - lr: 0.0025\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1024 - accuracy: 0.9600 - auc: 0.9928 - precision_10: 0.9600 - recall_10: 0.9600 - val_loss: 0.4760 - val_accuracy: 0.8391 - val_auc: 0.9268 - val_precision_10: 0.8391 - val_recall_10: 0.8391 - lr: 0.0025\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0998 - accuracy: 0.9637 - auc: 0.9937 - precision_10: 0.9637 - recall_10: 0.9637 - val_loss: 0.1355 - val_accuracy: 0.9446 - val_auc: 0.9895 - val_precision_10: 0.9446 - val_recall_10: 0.9446 - lr: 0.0025\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1003 - accuracy: 0.9592 - auc: 0.9935 - precision_10: 0.9592 - recall_10: 0.9592 - val_loss: 0.1546 - val_accuracy: 0.9377 - val_auc: 0.9866 - val_precision_10: 0.9377 - val_recall_10: 0.9377 - lr: 0.0025\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0960 - accuracy: 0.9622 - auc: 0.9939 - precision_10: 0.9622 - recall_10: 0.9622 - val_loss: 0.1889 - val_accuracy: 0.9377 - val_auc: 0.9795 - val_precision_10: 0.9377 - val_recall_10: 0.9377 - lr: 0.0025\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1075 - accuracy: 0.9600 - auc: 0.9929 - precision_10: 0.9600 - recall_10: 0.9600 - val_loss: 0.2340 - val_accuracy: 0.9187 - val_auc: 0.9739 - val_precision_10: 0.9187 - val_recall_10: 0.9187 - lr: 0.0025\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0944 - accuracy: 0.9563 - auc: 0.9946 - precision_10: 0.9563 - recall_10: 0.9563 - val_loss: 0.1712 - val_accuracy: 0.9429 - val_auc: 0.9862 - val_precision_10: 0.9429 - val_recall_10: 0.9429 - lr: 0.0025\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0948 - accuracy: 0.9629 - auc: 0.9943 - precision_10: 0.9629 - recall_10: 0.9629 - val_loss: 0.4216 - val_accuracy: 0.8979 - val_auc: 0.9439 - val_precision_10: 0.8979 - val_recall_10: 0.8979 - lr: 0.0025\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0828 - accuracy: 0.9670 - auc: 0.9952 - precision_10: 0.9670 - recall_10: 0.9670 - val_loss: 0.1488 - val_accuracy: 0.9498 - val_auc: 0.9860 - val_precision_10: 0.9498 - val_recall_10: 0.9498 - lr: 0.0025\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0855 - accuracy: 0.9674 - auc: 0.9954 - precision_10: 0.9674 - recall_10: 0.9674 - val_loss: 0.3671 - val_accuracy: 0.9100 - val_auc: 0.9541 - val_precision_10: 0.9100 - val_recall_10: 0.9100 - lr: 0.0025\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.1017 - accuracy: 0.9548 - auc: 0.9931 - precision_10: 0.9548 - recall_10: 0.9548 - val_loss: 0.3464 - val_accuracy: 0.9118 - val_auc: 0.9534 - val_precision_10: 0.9118 - val_recall_10: 0.9118 - lr: 0.0025\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0783 - accuracy: 0.9678 - auc: 0.9958 - precision_10: 0.9678 - recall_10: 0.9678 - val_loss: 0.1690 - val_accuracy: 0.9412 - val_auc: 0.9846 - val_precision_10: 0.9412 - val_recall_10: 0.9412 - lr: 0.0025\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0882 - accuracy: 0.9689 - auc: 0.9947 - precision_10: 0.9689 - recall_10: 0.9689 - val_loss: 0.6211 - val_accuracy: 0.8824 - val_auc: 0.9273 - val_precision_10: 0.8824 - val_recall_10: 0.8824 - lr: 0.0025\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - 2s 29ms/step - loss: 0.0899 - accuracy: 0.9644 - auc: 0.9949 - precision_10: 0.9644 - recall_10: 0.9644 - val_loss: 0.1746 - val_accuracy: 0.9516 - val_auc: 0.9837 - val_precision_10: 0.9516 - val_recall_10: 0.9516 - lr: 0.0025\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0730 - accuracy: 0.9692 - auc: 0.9964 - precision_10: 0.9692 - recall_10: 0.9692 - val_loss: 0.2388 - val_accuracy: 0.9377 - val_auc: 0.9724 - val_precision_10: 0.9377 - val_recall_10: 0.9377 - lr: 0.0025\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0879 - accuracy: 0.9640 - auc: 0.9946 - precision_10: 0.9640 - recall_10: 0.9640 - val_loss: 0.7009 - val_accuracy: 0.8564 - val_auc: 0.9199 - val_precision_10: 0.8564 - val_recall_10: 0.8564 - lr: 0.0025\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0916 - accuracy: 0.9640 - auc: 0.9938 - precision_10: 0.9640 - recall_10: 0.9640 - val_loss: 0.2961 - val_accuracy: 0.9221 - val_auc: 0.9664 - val_precision_10: 0.9221 - val_recall_10: 0.9221 - lr: 0.0025\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0770 - accuracy: 0.9663 - auc: 0.9959 - precision_10: 0.9663 - recall_10: 0.9663 - val_loss: 1.4557 - val_accuracy: 0.6678 - val_auc: 0.7164 - val_precision_10: 0.6678 - val_recall_10: 0.6678 - lr: 0.0025\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0653 - accuracy: 0.9666 - auc: 0.9974 - precision_10: 0.9666 - recall_10: 0.9666 - val_loss: 0.1666 - val_accuracy: 0.9446 - val_auc: 0.9870 - val_precision_10: 0.9446 - val_recall_10: 0.9446 - lr: 0.0012\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0642 - accuracy: 0.9759 - auc: 0.9971 - precision_10: 0.9759 - recall_10: 0.9759 - val_loss: 0.2847 - val_accuracy: 0.9100 - val_auc: 0.9663 - val_precision_10: 0.9100 - val_recall_10: 0.9100 - lr: 0.0012\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0644 - accuracy: 0.9774 - auc: 0.9973 - precision_10: 0.9774 - recall_10: 0.9774 - val_loss: 0.2600 - val_accuracy: 0.9256 - val_auc: 0.9701 - val_precision_10: 0.9256 - val_recall_10: 0.9256 - lr: 0.0012\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0571 - accuracy: 0.9752 - auc: 0.9975 - precision_10: 0.9752 - recall_10: 0.9752 - val_loss: 0.1969 - val_accuracy: 0.9429 - val_auc: 0.9813 - val_precision_10: 0.9429 - val_recall_10: 0.9429 - lr: 0.0012\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0507 - accuracy: 0.9789 - auc: 0.9979 - precision_10: 0.9789 - recall_10: 0.9789 - val_loss: 0.2210 - val_accuracy: 0.9464 - val_auc: 0.9764 - val_precision_10: 0.9464 - val_recall_10: 0.9464 - lr: 0.0012\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0602 - accuracy: 0.9748 - auc: 0.9973 - precision_10: 0.9748 - recall_10: 0.9748 - val_loss: 0.2108 - val_accuracy: 0.9394 - val_auc: 0.9782 - val_precision_10: 0.9394 - val_recall_10: 0.9394 - lr: 0.0012\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0531 - accuracy: 0.9759 - auc: 0.9980 - precision_10: 0.9759 - recall_10: 0.9759 - val_loss: 0.3998 - val_accuracy: 0.8668 - val_auc: 0.9459 - val_precision_10: 0.8668 - val_recall_10: 0.8668 - lr: 0.0012\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0496 - accuracy: 0.9774 - auc: 0.9982 - precision_10: 0.9774 - recall_10: 0.9774 - val_loss: 0.3307 - val_accuracy: 0.9325 - val_auc: 0.9708 - val_precision_10: 0.9325 - val_recall_10: 0.9325 - lr: 0.0012\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0780 - accuracy: 0.9637 - auc: 0.9958 - precision_10: 0.9637 - recall_10: 0.9637 - val_loss: 0.1846 - val_accuracy: 0.9429 - val_auc: 0.9874 - val_precision_10: 0.9429 - val_recall_10: 0.9429 - lr: 0.0012\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0646 - accuracy: 0.9696 - auc: 0.9971 - precision_10: 0.9696 - recall_10: 0.9696 - val_loss: 0.1979 - val_accuracy: 0.9429 - val_auc: 0.9812 - val_precision_10: 0.9429 - val_recall_10: 0.9429 - lr: 0.0012\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0619 - accuracy: 0.9755 - auc: 0.9972 - precision_10: 0.9755 - recall_10: 0.9755 - val_loss: 0.5341 - val_accuracy: 0.9066 - val_auc: 0.9502 - val_precision_10: 0.9066 - val_recall_10: 0.9066 - lr: 0.0012\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0619 - accuracy: 0.9733 - auc: 0.9971 - precision_10: 0.9733 - recall_10: 0.9733 - val_loss: 0.1958 - val_accuracy: 0.9464 - val_auc: 0.9834 - val_precision_10: 0.9464 - val_recall_10: 0.9464 - lr: 6.2500e-04\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0495 - accuracy: 0.9741 - auc: 0.9985 - precision_10: 0.9741 - recall_10: 0.9741 - val_loss: 0.2565 - val_accuracy: 0.9394 - val_auc: 0.9722 - val_precision_10: 0.9394 - val_recall_10: 0.9394 - lr: 6.2500e-04\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0459 - accuracy: 0.9789 - auc: 0.9982 - precision_10: 0.9789 - recall_10: 0.9789 - val_loss: 0.2028 - val_accuracy: 0.9498 - val_auc: 0.9855 - val_precision_10: 0.9498 - val_recall_10: 0.9498 - lr: 6.2500e-04\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - 2s 25ms/step - loss: 0.0426 - accuracy: 0.9830 - auc: 0.9989 - precision_10: 0.9830 - recall_10: 0.9830 - val_loss: 0.2030 - val_accuracy: 0.9464 - val_auc: 0.9804 - val_precision_10: 0.9464 - val_recall_10: 0.9464 - lr: 6.2500e-04\n",
      "5-fold cv train loss avg: 0.0347, train acc avg: 0.9881, val loss avg: 0.1881, val acc avg: 0.9526, test loss avg: 0.1812, test acc avg: 0.9551 \n",
      "             train auc avg: 0.9989, val auc avg: 0.9836, test auc avg: 0.9852 \n",
      "                 train precision avg: 0.9881, val precision avg: 0.9526, test precision avg: 0.9551 \n",
      "                     train recall avg: 0.9881, val recall avg: 0.9526, test recall avg: 0.9551\n"
     ]
    }
   ],
   "source": [
    "# perform k-fold cross validation\n",
    "kfold_training(X_stft, y, k_fold, train_size, val_size, test_size, base_model_cnn, base_file_name, base_csv_name, path, learning_rate, epochs, batch_size, num_dense_units, num_classes, kernel_size, max_pool_kernel, conv_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each patient in patients, do k-fold cross validation\n",
    "# patients = [\"a01r\", \"a02r\", \"a03r\", \"a04r\", \"b01r\", \"c02r\"]\n",
    "\n",
    "# for patient in patients:\n",
    "#     print(f\"Start training for patient {patient}\")\n",
    "#     X_stft = np.load(f\"stft_individual/{patient}_stft_features.npy\")\n",
    "#     y = np.load(f\"stft_individual/{patient}_labels.npy\")\n",
    "\n",
    "#     X_stft = process_data_for_conv2D(X_stft)\n",
    "#     print(X_stft.shape)\n",
    "#     print(y.shape)\n",
    "#     path = f\"weights/{patient}/\"\n",
    "#     if not os.path.exists(path):\n",
    "#         print(f\"Create directory {path}\")\n",
    "#         os.makedirs(path)\n",
    "#     kfold_training(X_stft, y, k_fold, train_size, val_size, test_size, base_model_cnn, base_file_name, base_csv_name, path, learning_rate, epochs, batch_size, num_dense_units, num_classes, kernel_size, max_pool_kernel, conv_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model \n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
