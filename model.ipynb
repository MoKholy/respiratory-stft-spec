{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sklearn.metrics as metrics\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_pipeline(dataset_location, lr=0.005, epochs=100):\n",
    "    # create image dataset from directory\n",
    "    def create_dataset(directory, subset):\n",
    "        return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            directory,\n",
    "            seed=123,\n",
    "            image_size=(48, 128),\n",
    "            label_mode='binary',\n",
    "            shuffle=True,\n",
    "            validation_split=0.3,\n",
    "            subset=subset\n",
    "        )\n",
    "\n",
    "    # create a model using simple CNN for binary classification\n",
    "    def create_model(num_channels):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(48, 128, num_channels), name=\"Rescale_input\"),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), activation='relu', name=\"Conv1\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2), name=\"MaxPool1\"),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation='relu', name=\"Conv2\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2), name=\"MaxPool2\"),\n",
    "            tf.keras.layers.Conv2D(128, (3, 3), activation='relu', name=\"Conv3\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2), name=\"MaxPool3\"),\n",
    "            tf.keras.layers.Flatten(name=\"Flatten_features\"),\n",
    "            tf.keras.layers.Dense(128, activation='relu', name=\"FC1\"),\n",
    "            tf.keras.layers.Dense(1, activation='sigmoid', name=\"Output\")\n",
    "        ])\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy', 'AUC']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    # train model\n",
    "    def train_model(model, train, validation):\n",
    "        history = model.fit(\n",
    "            train,\n",
    "            validation_data=validation,\n",
    "            epochs=epochs,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss', min_delta=0.001, patience=10, verbose=1, restore_best_weights=True)]\n",
    "        )\n",
    "        return history\n",
    "\n",
    "    # create image datasets from directory\n",
    "    dataset_train = create_dataset(dataset_location, subset=\"training\")\n",
    "    dataset_val = create_dataset(dataset_location, subset=\"validation\").shuffle(1185)\n",
    "\n",
    "    # # Split val into val and test\n",
    "    # test_size = 0.5\n",
    "    # val_batches = dataset_val.cardinality().numpy()\n",
    "    # test_batches = int(test_size * val_batches)\n",
    "    # dataset_test = dataset_val.take(test_batches)\n",
    "    # dataset_val = dataset_val.skip(test_batches)\n",
    "\n",
    "    # create model\n",
    "    model = create_model(3)\n",
    "\n",
    "    # train model\n",
    "    history = train_model(model, dataset_train, dataset_val)\n",
    "\n",
    "    # Extract true labels from the test set\n",
    "    true_labels = []\n",
    "    for _, labels in dataset_val:\n",
    "        true_labels.append(labels.numpy()[0])\n",
    "\n",
    "    # Predict on the test set\n",
    "    test_pred = model.predict(dataset_val)\n",
    "    test_pred_class = (test_pred > 0.5).astype('int32')\n",
    "\n",
    "    eval_dict = {\n",
    "        \"test_proba\": test_pred,\n",
    "        \"test_pred_class\": test_pred_class,\n",
    "        \"true_labels\": true_labels\n",
    "    }\n",
    "\n",
    "    return model, history, eval_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3951 files belonging to 2 classes.\n",
      "Using 2766 files for training.\n",
      "Found 3951 files belonging to 2 classes.\n",
      "Using 1185 files for validation.\n",
      "Epoch 1/20\n",
      "87/87 [==============================] - 3s 24ms/step - loss: 0.4662 - accuracy: 0.7683 - auc: 0.8232 - val_loss: 0.3206 - val_accuracy: 0.8903 - val_auc: 0.9305\n",
      "Epoch 2/20\n",
      "87/87 [==============================] - 2s 23ms/step - loss: 0.3641 - accuracy: 0.8369 - auc: 0.9032 - val_loss: 0.3639 - val_accuracy: 0.8920 - val_auc: 0.9321\n",
      "Epoch 3/20\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 0.3290 - accuracy: 0.8706 - auc: 0.9255 - val_loss: 0.3861 - val_accuracy: 0.7806 - val_auc: 0.9386\n",
      "Epoch 4/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.2778 - accuracy: 0.8897 - auc: 0.9366 - val_loss: 0.3157 - val_accuracy: 0.8489 - val_auc: 0.9459\n",
      "Epoch 5/20\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 0.2506 - accuracy: 0.8962 - auc: 0.9476 - val_loss: 0.2450 - val_accuracy: 0.8970 - val_auc: 0.9524\n",
      "Epoch 6/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.2311 - accuracy: 0.9064 - auc: 0.9558 - val_loss: 0.2273 - val_accuracy: 0.9080 - val_auc: 0.9569\n",
      "Epoch 7/20\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 0.2238 - accuracy: 0.9118 - auc: 0.9580 - val_loss: 0.2282 - val_accuracy: 0.9055 - val_auc: 0.9575\n",
      "Epoch 8/20\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 0.2214 - accuracy: 0.9082 - auc: 0.9587 - val_loss: 0.2553 - val_accuracy: 0.9046 - val_auc: 0.9551\n",
      "Epoch 9/20\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 0.2447 - accuracy: 0.9129 - auc: 0.9591 - val_loss: 0.2569 - val_accuracy: 0.8869 - val_auc: 0.9581\n",
      "Epoch 10/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.2067 - accuracy: 0.9172 - auc: 0.9649 - val_loss: 0.2218 - val_accuracy: 0.9105 - val_auc: 0.9587\n",
      "Epoch 11/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.2110 - accuracy: 0.9208 - auc: 0.9636 - val_loss: 0.2265 - val_accuracy: 0.9097 - val_auc: 0.9571\n",
      "Epoch 12/20\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 0.2034 - accuracy: 0.9197 - auc: 0.9663 - val_loss: 0.2230 - val_accuracy: 0.9114 - val_auc: 0.9592\n",
      "Epoch 13/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.1977 - accuracy: 0.9223 - auc: 0.9681 - val_loss: 0.2222 - val_accuracy: 0.9105 - val_auc: 0.9605\n",
      "Epoch 14/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.2102 - accuracy: 0.9234 - auc: 0.9697 - val_loss: 0.2207 - val_accuracy: 0.9173 - val_auc: 0.9588\n",
      "Epoch 15/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.2034 - accuracy: 0.9223 - auc: 0.9668 - val_loss: 0.2326 - val_accuracy: 0.9055 - val_auc: 0.9593\n",
      "Epoch 16/20\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 0.1950 - accuracy: 0.9244 - auc: 0.9698 - val_loss: 0.2576 - val_accuracy: 0.8895 - val_auc: 0.9585\n",
      "Epoch 17/20\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 0.1896 - accuracy: 0.9248 - auc: 0.9713 - val_loss: 0.2487 - val_accuracy: 0.8861 - val_auc: 0.9617\n",
      "Epoch 18/20\n",
      "87/87 [==============================] - 2s 21ms/step - loss: 0.1874 - accuracy: 0.9259 - auc: 0.9729 - val_loss: 0.2207 - val_accuracy: 0.9089 - val_auc: 0.9611\n",
      "Epoch 19/20\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 0.1760 - accuracy: 0.9349 - auc: 0.9748 - val_loss: 0.2193 - val_accuracy: 0.9131 - val_auc: 0.9621\n",
      "Epoch 20/20\n",
      "87/87 [==============================] - 2s 22ms/step - loss: 0.1849 - accuracy: 0.9346 - auc: 0.9762 - val_loss: 0.2173 - val_accuracy: 0.9215 - val_auc: 0.9619\n",
      "38/38 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# train using mel\n",
    "stft_model, stft_history, stft_eval_dict = train_model_pipeline('data/organized_spectrograms/STFT', lr=0.005, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduce dims of test_pred_class\n",
    "# stft_eval_dict['test_pred_class'] = stft_eval_dict['test_pred_class'].reshape(-1)\n",
    "np.asarray(stft_eval_dict[\"true_labels\"]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [38, 1185]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hamad\\Desktop\\mech\\model.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(metrics\u001b[39m.\u001b[39;49mclassification_report(np\u001b[39m.\u001b[39;49masarray(stft_eval_dict[\u001b[39m\"\u001b[39;49m\u001b[39mtrue_labels\u001b[39;49m\u001b[39m\"\u001b[39;49m]), stft_eval_dict[\u001b[39m\"\u001b[39;49m\u001b[39mtest_pred_class\u001b[39;49m\u001b[39m\"\u001b[39;49m]))\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2539\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2405\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[0;32m   2406\u001b[0m     {\n\u001b[0;32m   2407\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msparse matrix\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2430\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2431\u001b[0m ):\n\u001b[0;32m   2432\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2433\u001b[0m \n\u001b[0;32m   2434\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2536\u001b[0m \u001b[39m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2537\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2539\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m   2541\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2542\u001b[0m         labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [38, 1185]"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(np.asarray(stft_eval_dict[\"true_labels\"]), stft_eval_dict[\"test_pred_class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stft_eval_dict[\"true_labels\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3951 files belonging to 2 classes.\n",
      "Using 2766 files for training.\n",
      "Found 3951 files belonging to 2 classes.\n",
      "Using 1185 files for validation.\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 4s 41ms/step - loss: 0.4799 - accuracy: 0.7487 - auc: 0.7992 - val_loss: 0.4276 - val_accuracy: 0.7671 - val_auc: 0.8029\n",
      "Epoch 2/100\n",
      "23/87 [======>.......................] - ETA: 1s - loss: 0.4319 - accuracy: 0.7649 - auc: 0.7814"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hamad\\Desktop\\mech\\model.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mel_model, mel_history, mel_eval_dict \u001b[39m=\u001b[39m train_model_pipeline(\u001b[39m'\u001b[39;49m\u001b[39mdata/organized_spectrograms/Mel\u001b[39;49m\u001b[39m'\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.005\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\hamad\\Desktop\\mech\\model.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m model \u001b[39m=\u001b[39m create_model(\u001b[39m3\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# train model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m history \u001b[39m=\u001b[39m train_model(model, dataset_train, dataset_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m# Extract true labels from the test set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m true_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([y \u001b[39mfor\u001b[39;00m _, y \u001b[39min\u001b[39;00m dataset_val], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\hamad\\Desktop\\mech\\model.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(model, train, validation):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         validation_data\u001b[39m=\u001b[39;49mvalidation,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X20sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\keras\\engine\\training.py:1555\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   1552\u001b[0m     data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39m=\u001b[39m data_handler\u001b[39m.\u001b[39m_initial_step \u001b[39mor\u001b[39;00m (\n\u001b[0;32m   1553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_load_initial_step_from_ckpt()\n\u001b[0;32m   1554\u001b[0m     )\n\u001b[1;32m-> 1555\u001b[0m     \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n\u001b[0;32m   1556\u001b[0m         \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m             epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m             _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m         ):\n\u001b[0;32m   1563\u001b[0m             callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\keras\\engine\\data_adapter.py:1374\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1373\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1374\u001b[0m original_spe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution\u001b[39m.\u001b[39;49mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[0;32m   1375\u001b[0m can_run_full_execution \u001b[39m=\u001b[39m (\n\u001b[0;32m   1376\u001b[0m     original_spe \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1377\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1378\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_steps \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m original_spe\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[39mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:637\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnumpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    636\u001b[0m   \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 637\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_value()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    638\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    639\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:725\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \n\u001b[0;32m    718\u001b[0m \u001b[39mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[39m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    724\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\u001b[39m\"\u001b[39m\u001b[39mRead\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 725\u001b[0m   value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_variable_op()\n\u001b[0;32m    726\u001b[0m \u001b[39m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[39mreturn\u001b[39;00m array_ops\u001b[39m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:704\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m       result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    703\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m   result \u001b[39m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    707\u001b[0m   \u001b[39m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    708\u001b[0m   \u001b[39m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m   tape\u001b[39m.\u001b[39mrecord_operation(\n\u001b[0;32m    710\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mReadVariableOp\u001b[39m\u001b[39m\"\u001b[39m, [result], [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle],\n\u001b[0;32m    711\u001b[0m       backward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    712\u001b[0m       forward_function\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:694\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[39mif\u001b[39;00m no_copy \u001b[39mand\u001b[39;00m forward_compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2022\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[0;32m    693\u001b[0m   gen_resource_variable_ops\u001b[39m.\u001b[39mdisable_copy_on_read(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle)\n\u001b[1;32m--> 694\u001b[0m result \u001b[39m=\u001b[39m gen_resource_variable_ops\u001b[39m.\u001b[39;49mread_variable_op(\n\u001b[0;32m    695\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dtype)\n\u001b[0;32m    696\u001b[0m _maybe_set_handle_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle, result)\n\u001b[0;32m    697\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\hamad\\anaconda3\\envs\\mech\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:524\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m    523\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 524\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m    525\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mReadVariableOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, resource, \u001b[39m\"\u001b[39;49m\u001b[39mdtype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype)\n\u001b[0;32m    526\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m    527\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mel_model, mel_history, mel_eval_dict = train_model_pipeline('data/organized_spectrograms/Mel', lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3951 files belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.2482 - accuracy: 0.7162 - auc: 0.8051 - precision_22: 0.7162 - recall_22: 0.7162 - val_loss: 0.5514 - val_accuracy: 0.7005 - val_auc: 0.7749 - val_precision_22: 0.7005 - val_recall_22: 0.7005\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 3s 24ms/step - loss: 0.2087 - accuracy: 0.7664 - auc: 0.8454 - precision_22: 0.7664 - recall_22: 0.7664 - val_loss: 0.4127 - val_accuracy: 0.7734 - val_auc: 0.8624 - val_precision_22: 0.7734 - val_recall_22: 0.7734\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 3s 24ms/step - loss: 0.1988 - accuracy: 0.7737 - auc: 0.8574 - precision_22: 0.7737 - recall_22: 0.7737 - val_loss: 0.4420 - val_accuracy: 0.7734 - val_auc: 0.8524 - val_precision_22: 0.7734 - val_recall_22: 0.7734\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.2017 - accuracy: 0.7711 - auc: 0.8494 - precision_22: 0.7711 - recall_22: 0.7711 - val_loss: 0.4362 - val_accuracy: 0.7656 - val_auc: 0.8607 - val_precision_22: 0.7656 - val_recall_22: 0.7656\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 4s 33ms/step - loss: 0.2046 - accuracy: 0.7697 - auc: 0.8499 - precision_22: 0.7697 - recall_22: 0.7697 - val_loss: 0.4350 - val_accuracy: 0.7669 - val_auc: 0.8416 - val_precision_22: 0.7669 - val_recall_22: 0.7669\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 8s 84ms/step - loss: 0.2072 - accuracy: 0.7525 - auc: 0.8382 - precision_22: 0.7525 - recall_22: 0.7525 - val_loss: 0.4635 - val_accuracy: 0.7474 - val_auc: 0.8306 - val_precision_22: 0.7474 - val_recall_22: 0.7474\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.2094 - accuracy: 0.7613 - auc: 0.8508 - precision_22: 0.7613 - recall_22: 0.7613 - val_loss: 0.4548 - val_accuracy: 0.7552 - val_auc: 0.8448 - val_precision_22: 0.7552 - val_recall_22: 0.7552\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 3s 24ms/step - loss: 0.2005 - accuracy: 0.7664 - auc: 0.8580 - precision_22: 0.7664 - recall_22: 0.7664 - val_loss: 0.3999 - val_accuracy: 0.7816 - val_auc: 0.8995 - val_precision_22: 0.7816 - val_recall_22: 0.7816\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 0.1974 - accuracy: 0.7733 - auc: 0.8662 - precision_22: 0.7733 - recall_22: 0.7733 - val_loss: 0.4162 - val_accuracy: 0.7776 - val_auc: 0.8590 - val_precision_22: 0.7776 - val_recall_22: 0.7776\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 4s 31ms/step - loss: 0.2276 - accuracy: 0.7573 - auc: 0.8374 - precision_22: 0.7573 - recall_22: 0.7573 - val_loss: 0.4323 - val_accuracy: 0.7630 - val_auc: 0.8492 - val_precision_22: 0.7630 - val_recall_22: 0.7630\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.2049 - accuracy: 0.7613 - auc: 0.8441 - precision_22: 0.7613 - recall_22: 0.7613 - val_loss: 0.4383 - val_accuracy: 0.7578 - val_auc: 0.8489 - val_precision_22: 0.7578 - val_recall_22: 0.7578\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.2059 - accuracy: 0.7616 - auc: 0.8467 - precision_22: 0.7616 - recall_22: 0.7616 - val_loss: 0.4738 - val_accuracy: 0.7370 - val_auc: 0.8324 - val_precision_22: 0.7370 - val_recall_22: 0.7370\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.2096 - accuracy: 0.7631 - auc: 0.8438 - precision_22: 0.7631 - recall_22: 0.7631 - val_loss: 0.3945 - val_accuracy: 0.8047 - val_auc: 0.8764 - val_precision_22: 0.8047 - val_recall_22: 0.8047\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 4s 31ms/step - loss: 0.2023 - accuracy: 0.7682 - auc: 0.8470 - precision_22: 0.7682 - recall_22: 0.7682 - val_loss: 0.4565 - val_accuracy: 0.7526 - val_auc: 0.8344 - val_precision_22: 0.7526 - val_recall_22: 0.7526\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 5s 41ms/step - loss: 0.2005 - accuracy: 0.7707 - auc: 0.8513 - precision_22: 0.7707 - recall_22: 0.7707 - val_loss: 0.4444 - val_accuracy: 0.7669 - val_auc: 0.8528 - val_precision_22: 0.7669 - val_recall_22: 0.7669\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 5s 42ms/step - loss: 0.2048 - accuracy: 0.7656 - auc: 0.8436 - precision_22: 0.7656 - recall_22: 0.7656 - val_loss: 0.4375 - val_accuracy: 0.7682 - val_auc: 0.8491 - val_precision_22: 0.7682 - val_recall_22: 0.7682\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 4s 29ms/step - loss: 0.2044 - accuracy: 0.7627 - auc: 0.8431 - precision_22: 0.7627 - recall_22: 0.7627 - val_loss: 0.4141 - val_accuracy: 0.7747 - val_auc: 0.8613 - val_precision_22: 0.7747 - val_recall_22: 0.7747\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.2012 - accuracy: 0.7642 - auc: 0.8494 - precision_22: 0.7642 - recall_22: 0.7642 - val_loss: 0.4215 - val_accuracy: 0.7721 - val_auc: 0.8568 - val_precision_22: 0.7721 - val_recall_22: 0.7721\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 4s 33ms/step - loss: 0.2017 - accuracy: 0.7656 - auc: 0.8452 - precision_22: 0.7656 - recall_22: 0.7656 - val_loss: 0.4249 - val_accuracy: 0.7760 - val_auc: 0.8542 - val_precision_22: 0.7760 - val_recall_22: 0.7760\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.2002 - accuracy: 0.7649 - auc: 0.8511 - precision_22: 0.7649 - recall_22: 0.7649 - val_loss: 0.4430 - val_accuracy: 0.7539 - val_auc: 0.8400 - val_precision_22: 0.7539 - val_recall_22: 0.7539\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 4s 31ms/step - loss: 0.1949 - accuracy: 0.7736 - auc: 0.8688 - precision_22: 0.7736 - recall_22: 0.7736 - val_loss: 0.3433 - val_accuracy: 0.8509 - val_auc: 0.9225 - val_precision_22: 0.8509 - val_recall_22: 0.8509\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.1285 - accuracy: 0.8841 - auc: 0.9544 - precision_22: 0.8841 - recall_22: 0.8841 - val_loss: 0.2223 - val_accuracy: 0.9076 - val_auc: 0.9689 - val_precision_22: 0.9076 - val_recall_22: 0.9076\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.0982 - accuracy: 0.9174 - auc: 0.9720 - precision_22: 0.9174 - recall_22: 0.9174 - val_loss: 0.1912 - val_accuracy: 0.9349 - val_auc: 0.9767 - val_precision_22: 0.9349 - val_recall_22: 0.9349\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.0904 - accuracy: 0.9269 - auc: 0.9765 - precision_22: 0.9269 - recall_22: 0.9269 - val_loss: 0.1794 - val_accuracy: 0.9375 - val_auc: 0.9814 - val_precision_22: 0.9375 - val_recall_22: 0.9375\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0856 - accuracy: 0.9269 - auc: 0.9794 - precision_22: 0.9269 - recall_22: 0.9269 - val_loss: 0.1749 - val_accuracy: 0.9388 - val_auc: 0.9810 - val_precision_22: 0.9388 - val_recall_22: 0.9388\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0935 - accuracy: 0.9199 - auc: 0.9754 - precision_22: 0.9199 - recall_22: 0.9199 - val_loss: 0.1661 - val_accuracy: 0.9388 - val_auc: 0.9820 - val_precision_22: 0.9388 - val_recall_22: 0.9388\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.0833 - accuracy: 0.9291 - auc: 0.9798 - precision_22: 0.9291 - recall_22: 0.9291 - val_loss: 0.1723 - val_accuracy: 0.9294 - val_auc: 0.9830 - val_precision_22: 0.9294 - val_recall_22: 0.9294\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.0868 - accuracy: 0.9243 - auc: 0.9782 - precision_22: 0.9243 - recall_22: 0.9243 - val_loss: 0.1535 - val_accuracy: 0.9349 - val_auc: 0.9858 - val_precision_22: 0.9349 - val_recall_22: 0.9349\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 10s 110ms/step - loss: 0.0793 - accuracy: 0.9331 - auc: 0.9815 - precision_22: 0.9331 - recall_22: 0.9331 - val_loss: 0.1527 - val_accuracy: 0.9336 - val_auc: 0.9858 - val_precision_22: 0.9336 - val_recall_22: 0.9336\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 5s 44ms/step - loss: 0.0818 - accuracy: 0.9302 - auc: 0.9809 - precision_22: 0.9302 - recall_22: 0.9302 - val_loss: 0.1681 - val_accuracy: 0.9349 - val_auc: 0.9813 - val_precision_22: 0.9349 - val_recall_22: 0.9349\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 11s 112ms/step - loss: 0.0790 - accuracy: 0.9338 - auc: 0.9823 - precision_22: 0.9338 - recall_22: 0.9338 - val_loss: 0.1571 - val_accuracy: 0.9401 - val_auc: 0.9843 - val_precision_22: 0.9401 - val_recall_22: 0.9401\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.0816 - accuracy: 0.9331 - auc: 0.9806 - precision_22: 0.9331 - recall_22: 0.9331 - val_loss: 0.1705 - val_accuracy: 0.9245 - val_auc: 0.9826 - val_precision_22: 0.9245 - val_recall_22: 0.9245\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 4s 35ms/step - loss: 0.0769 - accuracy: 0.9353 - auc: 0.9831 - precision_22: 0.9353 - recall_22: 0.9353 - val_loss: 0.1662 - val_accuracy: 0.9375 - val_auc: 0.9839 - val_precision_22: 0.9375 - val_recall_22: 0.9375\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0658 - accuracy: 0.9444 - auc: 0.9866 - precision_22: 0.9444 - recall_22: 0.9444 - val_loss: 0.1590 - val_accuracy: 0.9427 - val_auc: 0.9842 - val_precision_22: 0.9427 - val_recall_22: 0.9427\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0738 - accuracy: 0.9353 - auc: 0.9841 - precision_22: 0.9353 - recall_22: 0.9353 - val_loss: 0.1562 - val_accuracy: 0.9401 - val_auc: 0.9862 - val_precision_22: 0.9401 - val_recall_22: 0.9401\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0785 - accuracy: 0.9294 - auc: 0.9824 - precision_22: 0.9294 - recall_22: 0.9294 - val_loss: 0.1676 - val_accuracy: 0.9348 - val_auc: 0.9836 - val_precision_22: 0.9348 - val_recall_22: 0.9348\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 4s 33ms/step - loss: 0.0779 - accuracy: 0.9298 - auc: 0.9822 - precision_22: 0.9298 - recall_22: 0.9298 - val_loss: 0.1508 - val_accuracy: 0.9388 - val_auc: 0.9856 - val_precision_22: 0.9388 - val_recall_22: 0.9388\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 4s 38ms/step - loss: 0.0729 - accuracy: 0.9400 - auc: 0.9840 - precision_22: 0.9400 - recall_22: 0.9400 - val_loss: 0.1398 - val_accuracy: 0.9348 - val_auc: 0.9883 - val_precision_22: 0.9348 - val_recall_22: 0.9348\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 4s 37ms/step - loss: 0.0716 - accuracy: 0.9353 - auc: 0.9851 - precision_22: 0.9353 - recall_22: 0.9353 - val_loss: 0.1393 - val_accuracy: 0.9427 - val_auc: 0.9881 - val_precision_22: 0.9427 - val_recall_22: 0.9427\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 6s 52ms/step - loss: 0.0623 - accuracy: 0.9437 - auc: 0.9887 - precision_22: 0.9437 - recall_22: 0.9437 - val_loss: 0.1494 - val_accuracy: 0.9362 - val_auc: 0.9871 - val_precision_22: 0.9362 - val_recall_22: 0.9362\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 7s 64ms/step - loss: 0.0719 - accuracy: 0.9390 - auc: 0.9850 - precision_22: 0.9390 - recall_22: 0.9390 - val_loss: 0.1737 - val_accuracy: 0.9294 - val_auc: 0.9819 - val_precision_22: 0.9294 - val_recall_22: 0.9294\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 6s 54ms/step - loss: 0.0650 - accuracy: 0.9426 - auc: 0.9881 - precision_22: 0.9426 - recall_22: 0.9426 - val_loss: 0.1535 - val_accuracy: 0.9414 - val_auc: 0.9855 - val_precision_22: 0.9414 - val_recall_22: 0.9414\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 4s 28ms/step - loss: 0.0704 - accuracy: 0.9367 - auc: 0.9860 - precision_22: 0.9367 - recall_22: 0.9367 - val_loss: 0.1777 - val_accuracy: 0.9362 - val_auc: 0.9839 - val_precision_22: 0.9362 - val_recall_22: 0.9362\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 0.0646 - accuracy: 0.9448 - auc: 0.9872 - precision_22: 0.9448 - recall_22: 0.9448 - val_loss: 0.1509 - val_accuracy: 0.9375 - val_auc: 0.9868 - val_precision_22: 0.9375 - val_recall_22: 0.9375\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0658 - accuracy: 0.9480 - auc: 0.9876 - precision_22: 0.9480 - recall_22: 0.9480 - val_loss: 0.1386 - val_accuracy: 0.9427 - val_auc: 0.9884 - val_precision_22: 0.9427 - val_recall_22: 0.9427\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0650 - accuracy: 0.9437 - auc: 0.9882 - precision_22: 0.9437 - recall_22: 0.9437 - val_loss: 0.1598 - val_accuracy: 0.9349 - val_auc: 0.9846 - val_precision_22: 0.9349 - val_recall_22: 0.9349\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0665 - accuracy: 0.9426 - auc: 0.9873 - precision_22: 0.9426 - recall_22: 0.9426 - val_loss: 0.1350 - val_accuracy: 0.9453 - val_auc: 0.9888 - val_precision_22: 0.9453 - val_recall_22: 0.9453\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0694 - accuracy: 0.9404 - auc: 0.9862 - precision_22: 0.9404 - recall_22: 0.9404 - val_loss: 0.1005 - val_accuracy: 0.9601 - val_auc: 0.9928 - val_precision_22: 0.9601 - val_recall_22: 0.9601\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.0611 - accuracy: 0.9506 - auc: 0.9890 - precision_22: 0.9506 - recall_22: 0.9506 - val_loss: 0.1383 - val_accuracy: 0.9441 - val_auc: 0.9884 - val_precision_22: 0.9441 - val_recall_22: 0.9441\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 4s 33ms/step - loss: 0.0648 - accuracy: 0.9452 - auc: 0.9882 - precision_22: 0.9452 - recall_22: 0.9452 - val_loss: 0.1574 - val_accuracy: 0.9414 - val_auc: 0.9858 - val_precision_22: 0.9414 - val_recall_22: 0.9414\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0696 - accuracy: 0.9415 - auc: 0.9861 - precision_22: 0.9415 - recall_22: 0.9415 - val_loss: 0.1169 - val_accuracy: 0.9557 - val_auc: 0.9916 - val_precision_22: 0.9557 - val_recall_22: 0.9557\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.0589 - accuracy: 0.9473 - auc: 0.9901 - precision_22: 0.9473 - recall_22: 0.9473 - val_loss: 0.1282 - val_accuracy: 0.9466 - val_auc: 0.9895 - val_precision_22: 0.9466 - val_recall_22: 0.9466\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 6s 53ms/step - loss: 0.0569 - accuracy: 0.9513 - auc: 0.9907 - precision_22: 0.9513 - recall_22: 0.9513 - val_loss: 0.1241 - val_accuracy: 0.9544 - val_auc: 0.9905 - val_precision_22: 0.9544 - val_recall_22: 0.9544\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0528 - accuracy: 0.9561 - auc: 0.9918 - precision_22: 0.9561 - recall_22: 0.9561 - val_loss: 0.1069 - val_accuracy: 0.9531 - val_auc: 0.9932 - val_precision_22: 0.9531 - val_recall_22: 0.9531\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.0585 - accuracy: 0.9502 - auc: 0.9903 - precision_22: 0.9502 - recall_22: 0.9502 - val_loss: 0.1319 - val_accuracy: 0.9466 - val_auc: 0.9899 - val_precision_22: 0.9466 - val_recall_22: 0.9466\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 0.0527 - accuracy: 0.9558 - auc: 0.9918 - precision_22: 0.9558 - recall_22: 0.9558 - val_loss: 0.0876 - val_accuracy: 0.9701 - val_auc: 0.9951 - val_precision_22: 0.9701 - val_recall_22: 0.9701\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 4s 32ms/step - loss: 0.0532 - accuracy: 0.9543 - auc: 0.9917 - precision_22: 0.9543 - recall_22: 0.9543 - val_loss: 0.1164 - val_accuracy: 0.9557 - val_auc: 0.9918 - val_precision_22: 0.9557 - val_recall_22: 0.9557\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 6s 52ms/step - loss: 0.0529 - accuracy: 0.9539 - auc: 0.9917 - precision_22: 0.9539 - recall_22: 0.9539 - val_loss: 0.0902 - val_accuracy: 0.9648 - val_auc: 0.9951 - val_precision_22: 0.9648 - val_recall_22: 0.9648\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 5s 45ms/step - loss: 0.0517 - accuracy: 0.9565 - auc: 0.9918 - precision_22: 0.9565 - recall_22: 0.9565 - val_loss: 0.0868 - val_accuracy: 0.9688 - val_auc: 0.9955 - val_precision_22: 0.9688 - val_recall_22: 0.9688\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 4s 31ms/step - loss: 0.0556 - accuracy: 0.9565 - auc: 0.9913 - precision_22: 0.9565 - recall_22: 0.9565 - val_loss: 0.1137 - val_accuracy: 0.9635 - val_auc: 0.9920 - val_precision_22: 0.9635 - val_recall_22: 0.9635\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 5s 48ms/step - loss: 0.0488 - accuracy: 0.9572 - auc: 0.9925 - precision_22: 0.9572 - recall_22: 0.9572 - val_loss: 0.0845 - val_accuracy: 0.9635 - val_auc: 0.9957 - val_precision_22: 0.9635 - val_recall_22: 0.9635\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 6s 60ms/step - loss: 0.0691 - accuracy: 0.9492 - auc: 0.9894 - precision_22: 0.9492 - recall_22: 0.9492 - val_loss: 0.1220 - val_accuracy: 0.9492 - val_auc: 0.9909 - val_precision_22: 0.9492 - val_recall_22: 0.9492\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0523 - accuracy: 0.9583 - auc: 0.9917 - precision_22: 0.9583 - recall_22: 0.9583 - val_loss: 0.0945 - val_accuracy: 0.9714 - val_auc: 0.9945 - val_precision_22: 0.9714 - val_recall_22: 0.9714\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 0.0441 - accuracy: 0.9622 - auc: 0.9947 - precision_22: 0.9622 - recall_22: 0.9622 - val_loss: 0.0926 - val_accuracy: 0.9688 - val_auc: 0.9943 - val_precision_22: 0.9688 - val_recall_22: 0.9688\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 3s 28ms/step - loss: 0.0464 - accuracy: 0.9620 - auc: 0.9931 - precision_22: 0.9620 - recall_22: 0.9620 - val_loss: 0.0894 - val_accuracy: 0.9701 - val_auc: 0.9942 - val_precision_22: 0.9701 - val_recall_22: 0.9701\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 4s 31ms/step - loss: 0.0421 - accuracy: 0.9667 - auc: 0.9945 - precision_22: 0.9667 - recall_22: 0.9667 - val_loss: 0.0981 - val_accuracy: 0.9557 - val_auc: 0.9946 - val_precision_22: 0.9557 - val_recall_22: 0.9557\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 4s 29ms/step - loss: 0.0404 - accuracy: 0.9711 - auc: 0.9940 - precision_22: 0.9711 - recall_22: 0.9711 - val_loss: 0.0623 - val_accuracy: 0.9779 - val_auc: 0.9982 - val_precision_22: 0.9779 - val_recall_22: 0.9779\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 4s 29ms/step - loss: 0.0365 - accuracy: 0.9682 - auc: 0.9957 - precision_22: 0.9682 - recall_22: 0.9682 - val_loss: 0.0906 - val_accuracy: 0.9674 - val_auc: 0.9951 - val_precision_22: 0.9674 - val_recall_22: 0.9674\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 4s 34ms/step - loss: 0.0331 - accuracy: 0.9744 - auc: 0.9968 - precision_22: 0.9744 - recall_22: 0.9744 - val_loss: 0.0590 - val_accuracy: 0.9766 - val_auc: 0.9978 - val_precision_22: 0.9766 - val_recall_22: 0.9766\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0374 - accuracy: 0.9700 - auc: 0.9956 - precision_22: 0.9700 - recall_22: 0.9700 - val_loss: 0.0811 - val_accuracy: 0.9753 - val_auc: 0.9959 - val_precision_22: 0.9753 - val_recall_22: 0.9753\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0338 - accuracy: 0.9688 - auc: 0.9966 - precision_22: 0.9688 - recall_22: 0.9688 - val_loss: 0.0548 - val_accuracy: 0.9805 - val_auc: 0.9983 - val_precision_22: 0.9805 - val_recall_22: 0.9805\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0366 - accuracy: 0.9704 - auc: 0.9959 - precision_22: 0.9704 - recall_22: 0.9704 - val_loss: 0.0783 - val_accuracy: 0.9674 - val_auc: 0.9954 - val_precision_22: 0.9674 - val_recall_22: 0.9674\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 0.0358 - accuracy: 0.9686 - auc: 0.9957 - precision_22: 0.9686 - recall_22: 0.9686 - val_loss: 0.0956 - val_accuracy: 0.9648 - val_auc: 0.9937 - val_precision_22: 0.9648 - val_recall_22: 0.9648\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 0.0276 - accuracy: 0.9770 - auc: 0.9980 - precision_22: 0.9770 - recall_22: 0.9770 - val_loss: 0.0548 - val_accuracy: 0.9766 - val_auc: 0.9982 - val_precision_22: 0.9766 - val_recall_22: 0.9766\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0313 - accuracy: 0.9722 - auc: 0.9965 - precision_22: 0.9722 - recall_22: 0.9722 - val_loss: 0.0650 - val_accuracy: 0.9747 - val_auc: 0.9974 - val_precision_22: 0.9747 - val_recall_22: 0.9747\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 3s 25ms/step - loss: 0.0308 - accuracy: 0.9766 - auc: 0.9963 - precision_22: 0.9766 - recall_22: 0.9766 - val_loss: 0.0559 - val_accuracy: 0.9740 - val_auc: 0.9982 - val_precision_22: 0.9740 - val_recall_22: 0.9740\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0245 - accuracy: 0.9800 - auc: 0.9978 - precision_22: 0.9800 - recall_22: 0.9800 - val_loss: 0.0478 - val_accuracy: 0.9867 - val_auc: 0.9975 - val_precision_22: 0.9867 - val_recall_22: 0.9867\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0310 - accuracy: 0.9722 - auc: 0.9967 - precision_22: 0.9722 - recall_22: 0.9722 - val_loss: 0.0381 - val_accuracy: 0.9907 - val_auc: 0.9990 - val_precision_22: 0.9907 - val_recall_22: 0.9907\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0244 - accuracy: 0.9836 - auc: 0.9983 - precision_22: 0.9836 - recall_22: 0.9836 - val_loss: 0.0557 - val_accuracy: 0.9805 - val_auc: 0.9971 - val_precision_22: 0.9805 - val_recall_22: 0.9805\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0204 - accuracy: 0.9839 - auc: 0.9986 - precision_22: 0.9839 - recall_22: 0.9839 - val_loss: 0.0378 - val_accuracy: 0.9857 - val_auc: 0.9991 - val_precision_22: 0.9857 - val_recall_22: 0.9857\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 3s 24ms/step - loss: 0.0280 - accuracy: 0.9781 - auc: 0.9972 - precision_22: 0.9781 - recall_22: 0.9781 - val_loss: 0.0405 - val_accuracy: 0.9880 - val_auc: 0.9978 - val_precision_22: 0.9880 - val_recall_22: 0.9880\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0238 - accuracy: 0.9788 - auc: 0.9982 - precision_22: 0.9788 - recall_22: 0.9788 - val_loss: 0.0531 - val_accuracy: 0.9774 - val_auc: 0.9982 - val_precision_22: 0.9774 - val_recall_22: 0.9774\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 3s 23ms/step - loss: 0.0186 - accuracy: 0.9869 - auc: 0.9986 - precision_22: 0.9869 - recall_22: 0.9869 - val_loss: 0.0203 - val_accuracy: 0.9947 - val_auc: 0.9999 - val_precision_22: 0.9947 - val_recall_22: 0.9947\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.0158 - accuracy: 0.9898 - auc: 0.9993 - precision_22: 0.9898 - recall_22: 0.9898 - val_loss: 0.0239 - val_accuracy: 0.9935 - val_auc: 0.9997 - val_precision_22: 0.9935 - val_recall_22: 0.9935\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 4s 34ms/step - loss: 0.0295 - accuracy: 0.9762 - auc: 0.9975 - precision_22: 0.9762 - recall_22: 0.9762 - val_loss: 0.0534 - val_accuracy: 0.9854 - val_auc: 0.9981 - val_precision_22: 0.9854 - val_recall_22: 0.9854\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 4s 35ms/step - loss: 0.0178 - accuracy: 0.9869 - auc: 0.9988 - precision_22: 0.9869 - recall_22: 0.9869 - val_loss: 0.0259 - val_accuracy: 0.9960 - val_auc: 0.9995 - val_precision_22: 0.9960 - val_recall_22: 0.9960\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 0.0180 - accuracy: 0.9876 - auc: 0.9985 - precision_22: 0.9876 - recall_22: 0.9876 - val_loss: 0.0349 - val_accuracy: 0.9933 - val_auc: 0.9978 - val_precision_22: 0.9933 - val_recall_22: 0.9933\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 6s 58ms/step - loss: 0.0146 - accuracy: 0.9894 - auc: 0.9991 - precision_22: 0.9894 - recall_22: 0.9894 - val_loss: 0.0233 - val_accuracy: 0.9909 - val_auc: 0.9998 - val_precision_22: 0.9909 - val_recall_22: 0.9909\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 3s 29ms/step - loss: 0.0183 - accuracy: 0.9879 - auc: 0.9987 - precision_22: 0.9879 - recall_22: 0.9879 - val_loss: 0.0374 - val_accuracy: 0.9883 - val_auc: 0.9992 - val_precision_22: 0.9883 - val_recall_22: 0.9883\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 4s 30ms/step - loss: 0.0169 - accuracy: 0.9884 - auc: 0.9989 - precision_22: 0.9884 - recall_22: 0.9884 - val_loss: 0.0205 - val_accuracy: 0.9948 - val_auc: 0.9999 - val_precision_22: 0.9948 - val_recall_22: 0.9948\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 4s 29ms/step - loss: 0.0870 - accuracy: 0.9642 - auc: 0.9902 - precision_22: 0.9642 - recall_22: 0.9642 - val_loss: 0.1008 - val_accuracy: 0.9680 - val_auc: 0.9951 - val_precision_22: 0.9680 - val_recall_22: 0.9680\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 3s 24ms/step - loss: 0.0320 - accuracy: 0.9729 - auc: 0.9972 - precision_22: 0.9729 - recall_22: 0.9729 - val_loss: 0.0217 - val_accuracy: 0.9935 - val_auc: 0.9999 - val_precision_22: 0.9935 - val_recall_22: 0.9935\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 3s 26ms/step - loss: 0.0155 - accuracy: 0.9898 - auc: 0.9987 - precision_22: 0.9898 - recall_22: 0.9898 - val_loss: 0.0170 - val_accuracy: 0.9948 - val_auc: 0.9999 - val_precision_22: 0.9948 - val_recall_22: 0.9948\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 4s 36ms/step - loss: 0.0139 - accuracy: 0.9890 - auc: 0.9995 - precision_22: 0.9890 - recall_22: 0.9890 - val_loss: 0.0270 - val_accuracy: 0.9947 - val_auc: 0.9996 - val_precision_22: 0.9947 - val_recall_22: 0.9947\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 3s 27ms/step - loss: 0.0125 - accuracy: 0.9898 - auc: 0.9996 - precision_22: 0.9898 - recall_22: 0.9898 - val_loss: 0.0155 - val_accuracy: 0.9974 - val_auc: 0.9998 - val_precision_22: 0.9974 - val_recall_22: 0.9974\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 4s 31ms/step - loss: 0.0102 - accuracy: 0.9931 - auc: 0.9997 - precision_22: 0.9931 - recall_22: 0.9931 - val_loss: 0.0170 - val_accuracy: 0.9922 - val_auc: 0.9999 - val_precision_22: 0.9922 - val_recall_22: 0.9922\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 5s 41ms/step - loss: 0.0083 - accuracy: 0.9942 - auc: 0.9999 - precision_22: 0.9942 - recall_22: 0.9942 - val_loss: 0.0125 - val_accuracy: 0.9961 - val_auc: 1.0000 - val_precision_22: 0.9961 - val_recall_22: 0.9961\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 4s 37ms/step - loss: 0.0067 - accuracy: 0.9952 - auc: 0.9999 - precision_22: 0.9952 - recall_22: 0.9952 - val_loss: 0.0175 - val_accuracy: 0.9948 - val_auc: 0.9998 - val_precision_22: 0.9948 - val_recall_22: 0.9948\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 5s 40ms/step - loss: 0.0060 - accuracy: 0.9953 - auc: 0.9999 - precision_22: 0.9953 - recall_22: 0.9953 - val_loss: 0.0093 - val_accuracy: 0.9973 - val_auc: 1.0000 - val_precision_22: 0.9973 - val_recall_22: 0.9973\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 4s 37ms/step - loss: 0.0073 - accuracy: 0.9963 - auc: 0.9999 - precision_22: 0.9963 - recall_22: 0.9963 - val_loss: 0.0131 - val_accuracy: 0.9961 - val_auc: 1.0000 - val_precision_22: 0.9961 - val_recall_22: 0.9961\n",
      "14/14 [==============================] - 1s 5ms/step\n",
      "14/14 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "logmel_model, logmel_history, logmel_eval_dict = train_model_pipeline('data/organized_spectrograms/LogMel', lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_proba 448\n",
      "test_preds 431\n",
      "true_labels 448\n"
     ]
    }
   ],
   "source": [
    "stft_eval_dict.keys()\n",
    "# print len of each key\n",
    "for key in stft_eval_dict.keys():\n",
    "    print(key, len(stft_eval_dict[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hamad\\Desktop\\mech\\model.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m  \u001b[39mlen\u001b[39m(stft_eval_dict[\u001b[39m\"\u001b[39m\u001b[39mtest_preds\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(stft_eval_dict[\u001b[39m\"\u001b[39m\u001b[39mtrue_labels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hamad/Desktop/mech/model.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m metrics\u001b[39m.\u001b[39mclassification_report(stft_eval_dict[\u001b[39m\"\u001b[39m\u001b[39mtrue_labels\u001b[39m\u001b[39m\"\u001b[39m], stft_eval_dict[\u001b[39m\"\u001b[39m\u001b[39mtest_preds\u001b[39m\u001b[39m\"\u001b[39m], output_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(stft_eval_dict[\"test_proba\"]) == len(stft_eval_dict[\"test_preds\"]) == len(stft_eval_dict[\"true_labels\"])\n",
    "metrics.classification_report(stft_eval_dict[\"true_labels\"], stft_eval_dict[\"test_preds\"], output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
